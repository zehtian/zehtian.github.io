{"posts":[{"title":"java基础（一）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的基本语法，包括java的数据类型，变量，运算符，语句，数组等。 java语言的特点：面向对象，健壮性，跨平台性 java语言三大特性：封装，继承，多态 java数据类型 类型 存储空间 数据范围 byte 1字节=8bit位 -128~127 short 2字节 -2^15~2^15-1 int 4字节 -2^31~2^31-1 long 8字节 float 4字节 double 8字节 char 2字节 Java 的整型常量默认为 int 型，声明 long 型变量，必须以 ‘l’ 或 ‘L’ 结尾。long a=124548784L Java 的浮点型常量默认为 double 型，声明 float 型常量，变量要以 ‘f’ 或 ‘F’ 结尾。通常定义浮点变量时，使用 double。 char 型数据用来表示通常意义上“字符”。Java 中的所有字符都使用 Unicode 编码，故一个字符可以存储一个字母，一个汉字，或其他书面语的一个字符。 字符串类型String：String不是基本数据类型，属于引用数据类型。使用方式与基本数据类型一致。如： String str = “abcd”; String s2 = “a”; String s3 = “”。 String可以和8种基本数据类型变量做运算，且运算只能是连接运算 ‘+’ 。运算结果还是String类型。 判断+是加法还是连接：+前后两个要运算的有一个是字符串就是连接，没有就是加法。如： char c = ‘a’; //a:97 A:65 int number = 10; String str = “hello”; System.out.printIn(c + num + str); //107hello java的变量语法（声明并赋值，二者可分开）： &lt;数据类型&gt; &lt;变量名&gt; = &lt;初始化值&gt; 如：int var = 10; 变量的作用：用于在内存中保存数据 使用变量注意： Java中每个变量必须先声明(定义且赋值)，后使用 使用变量名来访问这块区域的数据 变量的作用域：其定义所在的一对{ }内 变量只有在其作用域内才有效 同一个作用域内，不能定义重名的变量 java运算符算数运算符： b=++a：先运算后取值；b=a++：先取值后运算 /：除法：整数之间做除法时，只保留整数部分而舍弃小数部分。如：12/5=2 (double)12/5=2.4 %：取模：对负数取模，可以把模数负号忽略不记， 与被模数符号相同。如：12%5=2; (-12)%5=-2; (-12)%(-5)=-2 赋值运算符： 符号：=；当“=”两侧数据类型不一致时，可以使用自动类型转换或使用强制类型转换原则进行处理。支持连续赋值。 扩展赋值运算符：+=, -=,*=, /=, %=。两者区别：扩展赋值运算符不会改变本身变量的数据类型，如: short s=10; s=s+10; //编译失败，但是s+=10编译成功 逻辑运算符：&amp;逻辑与 &amp;&amp;短路与 |逻辑或 ||短路或 !逻辑非 ^逻辑异或 在Java中不可以写成3&lt;x&lt;6，应该写成x&gt;3 &amp; x&lt;6 。 位运算符：&amp; | ^ ~ &lt;&lt; &gt;&gt; 三元运算符：(条件表达式)?表达式1: 表达式2； 可嵌套 java循环语句while循环的语法如下： 先判断再循环 while(布尔表达式){ 循环体;} do-while循环的语法如下： 先循环再判断 do{ 循环体; }while(布尔表达式); for循环的语法结构： for(表达式1; 表达式2; 表达式3){ 循环体; } 其中：表达式1的作用是给循环变量初始化；表达式2的作用是给出循环条件；表达式3的作用是改变循环变量的值；循环体可以是一条或多条语句。 for循环的执行过程是：执行表达式1，计算表达式2，如果表达式2的值为true，执行循环体，执行表达式3，改变循环变量的值，再计算表达式2的值，如果是true，再进入循环体，形成循环，直到表达式2的值为false，结束循环，执行for后面的语句。 java数组一维数组的声明与创建： 元素类型[] 数组名 = new 元素类型[元素个数或数组长度]; –动态 元素类型[] 数组名 = new 元素类型[]{元素，元素，……}; –静态 元素类型[] 数组名 = {元素，元素，……}; –静态 示例： int[] arr = new int[5]; //此时初始值为0，初始化方式如: arr[0]=1 int[] arr = new int[]{3,5,1,7}; //创建并初始化 int[] arr = {3,5,1,7}; //创建并初始化 注意：1.给数组分配空间时，必须指定数组能够存储的元素个数来确定数组大小。创建数组之后不能修改数组的大小。可以使用length 属性获取数组的大小。 2.元素类型为String时，初始化的值为null 3.元素类型后面的[]可以放在数组名后面 4.若要复制数组arr1，需要new一个新数组arr2=new int[arr1.length]，而不能 直接arr2=arr1，直接相等会导致arr1和arr2是同一个地址，改变arr2也会改变arr1的值，而new一个新的arr说明arr1和arr2地址不同。 Arrays的使用： 遍 历： Arrays.toString(array) 将数组的元素以字符串的形式返回，如”[1, 2, 3]” 排序： Arrays.sort(array) 将数组按照升序排列 查找： binarySearch()在指定数组中查找指定元素，返回元素的索引，如果没有找到返回（-插入点-1） 注意：使用查找的功能的时候，数组一定要先排序 二维数组定义： 动态定义： 数组类型[][] 数组名 = new 数组类型[一维数组的个数][每一个一维数组中元素的个数]; 数组类型[][] 数组名 = new 数组类型[一维数组的个数][]; 此方法需要再定义一次一维数组，用于元素个数不确定的情况 或者直接进行静态定义 注意：1.二维数组不要求每个一维数组的元素个数相等","link":"/2023/01/11/java%E5%9F%BA%E7%A1%80%E4%B8%80/"},{"title":"html入门","text":"本篇文章讲解了html的入门知识。首先讲解了html的基本元素和格式，之后讲解了一个html文档的基本结构，其中具体介绍了head内容和body内容的拓展。 HTML元素：一个HTML元素包括： 基本格式： &lt;元素 属性&gt;内容&lt;/元素&gt; &lt;&gt;中可以添加属性，用引号进行表示，它们不会显示出来 &lt;!–我是注释–&gt;间可以添加注释 &lt;p&gt;&lt;/p&gt;：封装为段落。元素的属性有： · class 赋予名字(id)，这个名字此后可以被用来识别此元素的样式信息和其他信息 &lt;em&gt;&lt;/em&gt;：斜体 &lt;strong&gt;&lt;/strong&gt;：加粗 &lt;h&gt;&lt;/h&gt;：标题 有h1，h2… &lt;img&gt;：插入指定图片 · src 图片地址 &lt;a&gt;：是被包裹的内容成为一个链接。&lt;a&gt;元素的属性有： &lt;input&gt;：输入数据 · type 数据格式 · disabled 禁止输入 HTML文档：一个HTML文档由多个HTML元素构成。 1.&lt;!DOCTYPE html&gt;: 声明文档类型 2.&lt;html&gt;&lt;/html&gt;：根元素，包裹了整个界面 3.&lt;head&gt;&lt;/head&gt;: &lt;head&gt;元素. 这个元素是一个容器，它包含了所有你想包含在HTML页面中但不想在HTML页面中显示的内容。这些内容包括你想在搜索结果中出现的关键字和页面描述，CSS样式，字符集声明等等。 4.&lt;meta charset=”utf-8”&gt;: 这个元素设置文档使用utf-8字符集编码，utf-8字符集包含了人类大部分的文字。基本上他能识别你放上去的所有文本内容。毫无疑问要使用它，并且它能在以后避免很多其他问题。 5.&lt;title&gt;&lt;/title&gt;: 设置页面标题，出现在浏览器标签上，当你标记/收藏页面时它可用来描述页面。 6.&lt;body&gt;&lt;/body&gt;: &lt;body&gt;元素。 包含了你访问页面时所有显示在页面上的内容，文本，图片，音频，游戏等等。 Head内容拓展：1.添加作者和描述 2.其它类型源数据 3.添加自定义图标 4.在HTML中应用CSS和Javascript Body内容拓展：1.标题和段落： 2.列表： 每份无序的清单从&lt;ul&gt;元素开始——需要包裹清单上所有被列出的项目； 然后用 &lt;li&gt;元素把每个列出的项目单独包裹起来： 有序列表的结构和无序列表一样，除了需要用&lt;ol&gt;元素将所有项目包裹, 而不是&lt;ul&gt;。 3.斜体、粗体、下划线 其它：实体引用（转义字符）： 代码格式：通常每一个嵌套的元素以两个空格缩进。","link":"/2022/12/22/html%E5%85%A5%E9%97%A8/"},{"title":"java基础（三）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的面向对象部分（下），包括多态性，Object类和包装类，代码块，抽象类(abstract)，接口(interface)等，此外介绍了关键字static的使用和异常的处理等。 java多态性多态性的理解：一个事物的多种形态 对象的多态性：父类的引用指向子类的对象 如：Person p1 = new Women() 举例：可将new Women()或者new Men()作为方法func(Person person)的person参数，即func(new Women())，并在func中实际调用Women或Men类重写的方法。 多态的使用：虚拟方法调用（原父类被重写的方法叫虚拟方法） 有了对象的多态性以后，我们在编译期，只能调用父类中声明的方法，但在运行期，我们实际执行的是子类重写父类的方法。总结：编译，看左边；运行，看右边。 多态性的使用前提：1.类的继承关系 2.要有方法的重写 不然这样用就没有意义，不如直接调用父类的对象 注意：1. 对象的多态性，只适用于方法，不适用于属性（编译和运行都看左边） ​ 2. 多态是运行时行为 向下转型：将父类的对象转换成子类对象，以使用子类独有的属性和方法（多态实际上是向上转型） 如 Woman p2 = (Woman)p1，这样p2就变成了Woman类的对象 instanceof的使用：a instanceof A 判断对象a是否是类A的实例，如果是，返回true，如果不是，返回false 使用情境：为了避免在向下转型时出现ClasscastException的异常，我们在向下转型之前，先进行instanceof的判断，一旦返回true，就进行向下转型。如果返回false，不进行向下转型。如上述向下转型需判断 p1 instanceof Woman为true 如果a instanceof A返回true,则a instanceof B也返回true.其中,类B是类A的父类。 Object类和包装类运算符==的使用： 可以使用在基本数据类型变量和引用数据类型变量中 如果比较的是基本数据类型变量：比较两个变量保存的数据是否相等(不一定类型要相同) 如果比较的是引用数据类型变量，比较两个对象的地址值是否相同，即两个引用是否指向同一个对象实体 方法equals()的使用： object类中equals()的定义: public booiean equals(object obj) { ​ return (this==obj); } 说明: equals()是一个方法，只能应用于引用数据类型 object类中定义的equals()和==的作用是相同的。比较两个对象的地址值是否相同.即两个引用是否指向同一个对象实体。 像String、 Date、File、包装类等都重写了Object类中的equals()方法。重写以后，比较的不是两个引用的地址是否相同，而是比较两个对象的实体内容是否相同。 方法toString()的使用： 当我们输出一个对象的引用时（ 即System.out.println() 时），实际上就是调用当前对象的toString()方法 object类中toString()的定义: public string toString(){ ​ return getclass().getName()+”@” + Integer.toHexString(hashcode()); } 像String、Date、File、包装类等都重写了object类中的toString()方法，使得在调用对象的toString()时,返回”实体内容”信息。 包装类：针对八种基本数据类型定义相应的引用类型——包装类（封装类）。 具体的，一般是将首字母的小写变大写，如byte-&gt;Byte，此外有一些特殊：int-&gt;Integer；char-&gt;Character 基本数据类型，包装类，String之间的相互转化： static关键字1.static:静态的 2.static可以用来修饰: 属性、方法、代码块、内部类 3.使用static修饰属性: 静态变量（或类变量) 3.1. 属性：按是否使用static修饰，又分为: 静态属性Vs 非静态属性(实例变量) 实例变量: 我们创建了类的多个对象，每个对象都独立的拥有一套类中的非静态属性。当修改其中一个对象中的非静态属性时,不会导致其他对象中同样的属性值的修改。 静态变量: 我们创建了类的多个对象，多个对象共享同一个静态变量。当通过某一个对象修改静态变量时，会导致其他对象调用此静态变量时，是修改过了的。 3.2. static修饰属性的其他说明: 静态变量随着类的加载而加载。可以通过”类.静态变量”的方式进行调用静态变量的加载要早于对象的创建。 由于类只会加载一次，则静态变量在内存中也只会存在一份:存在方法区的静态域中。 类可以调用其类变量，但不能调用实例变量；对象可以调用类变量，也可以调用实例变量 3.3. 静态属性举例：System.out Math.PI 4.使用static修饰方法：静态方法 随着类的加载而加载，可以通过”类.静态方法”的方式进行调用 静态方法中，只能调用静态的方法或属性；非静态方法中，既可以调用非静态的方法或属性,也可以调用静态的方法或属性 类可以调用其静态方法，但不能调用非静态方法；对象都可以调用 在静态的方法内,不能使用this关键字、super关键字 关于静态属性和静态方法的使用，可以从生命周期的角度去理解。静态的是随着类的创建就创建，随着类的消失而消失；非静态的是随着对象的创建而开始，对象的消失而终止。 5.1 开发中，如何确定一个属性是否要声明为static的? ​ 属性是可以被多个对象所共享的，不会随着对象的不同而不同的。 5.2 开发中，如何确定一个方法是否要声明为static的? ​ 操作静态属性的方法，通常设置为static的； ​ 工具类中的方法，习惯上声明为static的 代码块格式： { ​ //代码块中内容 ​ } 1.代码块的作用:用来初始化类、对象 2.代码块如果有修饰的话，只能使用static 3.分类：静态代码块Vs非静态代码块 4.静态代码块 （加了static） 内部可以有输出语句 随着类的加线而执行,而且只执行一次 作用:初始化类的信息 静态代码块要优于非静态代码块执行 5.非静态代码块 内部可以有输出语句 随着对象的创建而执行，每创建一个对象，就执行一次非静态代码块 作用:可以在创建对象时，对对象的属性等进行初始化 final关键字的使用final：最终的 1.final可以用来修饰的结构：类、方法、变量 2.final用来修饰一个类：此类不能被其他类所继承。 比如：String类、System类、StringBuffer类 3.final用来修饰方法：表明此方法不可以被重写。 比如，Object类中getClass(); 4.final修饰变量，此时变量变常量，即不能改变 abstract关键字的使用1.abstract修饰类：抽象类 抽象类不能被实例化；抽象类中一定有构造器，便于子类实例化时调用；开发中，都会提供抽象类的子类，让子类对象实例化 2.abstract修饰方法：抽象方法 抽象方法中只有方法的声明，没有方法体；包含抽象方法的类一定是抽象类，而抽象类中可以没有抽象方法 若子类重写了父类中的所有抽象方法，则此子类可以被实例化；若子类没有重写父类的所有抽象方法，则该子类也是一个抽象类，需要用abstract修饰。 3.abstract不能用来修饰：属性、构造器等结构，不能修饰私有方法、静态方法、final修饰的方法和类 interface：接口的使用Java中，接口和类是并列的两个结构 如何定义接口：定义接口中的成员 JDK7及以前，只能定义全局常量和抽象方法 ​ &gt;全局常量：public static final的，但是书写时，可以省略不写 ​ &gt;抽象方法：public abstract的，但是书写时，可以省略不写 JDK8:除了定义全局常量和抽象方法之外，还可以定义静态方法、默认方法（略) 接口中不能定义构造器的！意味着接口不可以实例化 Java开发中，接口通过让类去实现(implements)的方式来使用。 如果实现类覆盖了接口中的所有抽象方法，则此实现类就可以实例化如果实现类没有覆盖接口中所有的抽象方法，则此实现类仍为一个抽象类 JAVA类可以定义多个接口，class AA extends BB implements CC,DD,EE；接口课可以继承接口，甚至可以继承多个接口","link":"/2023/01/12/java%E5%9F%BA%E7%A1%80%E4%B8%89/"},{"title":"java基础（五）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的高级特性——集合。java集合可分为Collection和Map两种体系。Collection接口：单列集合，存储一个一个的对象。其中包括List接口和Set接口；Map接口：双列集合，用来存储一对（key-value）一对的数据。 java集合可分为Collection和Map两种体系。 1.Collection接口：单列集合，存储一个一个的对象 ​ 1.1 List接口，存储有序的、可重复的数据； ​ 如：ArrrayList、LinkedList、Vector ​ 1.2 Set接口，存储无序的、不可重复的数据； ​ 如：HashSet、 LinkedHashSet、TreeSet 2.Map接口：双列集合，用来存储一对（key-value）一对的数据。 ​ 如：HashMap、LinkedHashMap、TreeMap Collection接口Collection接口中的常用方法新建一个Collection接口对象。如：Collection coll1 = new ArrayList() add(Object e)：将元素e添加到集合中； addAll(Collection coll)：将集合coll中的元素添加到该集合中； size()：获取添加元素的个数； clear()：清空集合元素； isEmpty()：判断当前集合是否为空； contains(Object e)：判断集合中是否存在元素e；–containsAll同理 remove(Object e)：删除一个元素e，并返回是否删除成功；–removeAll同理 retrainAll(Collection coll)：求集合交集，并将结果返回在原集合中； equals(Object e)：返回与e是否相等，要想返回true，e首先得是Collection； toArray(Collection coll)：集合转化为数组。 注意：向Collection接口的实现类的对象中添加数据obj时，要求obj所在类重写equals()。 集合Collection的遍历使用Iterator迭代器遍历集合Collection[主要是List]：使用hasNext()和next() 例子： 1234Collection coll = new ArrayList();Iterator iter = coll.interator();while(iter.hasNext()): System.out.println(iter.next()); //打印当前集合中的对应元素 注意：1. 可以想象有一个指针，iter最先指向空，hasNext()判断下一个元素有没有值，如果有，则使用next()先将指针移动到下一个元素，然后返回指向元素的值。 Iterator仅用于遍历集合，本身没有承装对象的能力。如果需要创建Iterator对象，则必须有一个被迭代的集合； 集合对象每次调用iterator()方法都得到一个全新的迭代器对象，默认指针都在第一个元素之前（即空）； iter.remove()：可以在遍历的时候，对集合的元素进行移除操作。 foreach遍历集合和数组：（jdk5.0新增） 格式：for(集合中元素类型 局部变量 : 集合对象){ … } 如：for(Object obj : coll){ ​ System.out.println(obj); //其实obj内部调用的还是迭代器 ​ } List接口List接口：存储有序的、可重复的数组–&gt;”动态”数组，可替换原有数组 ArrayList：List接口的主要实现类；线程不安全的，效率高；底层使用Object[] elementData存储； LinkedList：底层使用双向链表存储；对于频繁的插入和删除操作，此类效率更高； Vector：List接口的远古实现类；线程安全的，效率低；底层使用Object[] elementData存储 ArrayList类ArrayList源码分析： 1.jdk 7情况下： ArrayList list = new ArrayList(); //底层创建了长度是10的object[]数组elementData list.add(123); //elementData[e] = new Integer(123); … list.add(11); //如果此次的添加导致底层elementData数组容量不够，则扩容。 默认情况下，扩容为原来的容量的1.5倍，同时需要将原有数组中的数据复制到新的数组中。 结论：建议开发中使用带参的构造器：ArrayList list = new ArrayList(int capacity) 2.jdk 8中ArrayList的变化: ArrayList list = new ArrayList(); //底层object[] elementData初始化为{}，并没有创建长度为10的数组 list.add(123); //第一次调用add()时，底层才创建了长度10的数组，并将数据123添加到elementData中 后续的添加和扩容操作与jdk 7无异。 3.小结：jdk7中的ArrayList的对象的创建类似于单例的饿汉式，而jdk8中的ArrayList的对象的创建类似于单例的懒汉式,延迟了数组的创建，节省内存。 LinkedList类LinkedList源码分析： LinkedList list = new LinkedList(); // 内部声明了Node类型的first和last属性，默认值null list.add(123);//将123封装到Node中，创建了Node对象。 其中，Node的定义体现了LinkedList的双向链表的说法： 123456789private static class Node&lt;E&gt; { E item; Node&lt;E&gt;next; Node&lt;E&gt;prev; Node(Node&lt;E&gt; prev, E eLement, Node&lt;E&gt; next) { this.item = element; this.next = next; this.prev = prev;}} List接口中常用方法： Set接口Set接口：存储无序的、不可重复的数组–&gt;高中讲的”集合” HashSet：Set接口的主要实现类；线程不安全的；可以存储null值； LinkedHashSet：作为HashSet的子类；遍历其内部数据时，可以按照添加的顺序遍历；在添加数据的同时，每个数据还维护了两个引用，记录此数据的前一个数据和后一个数据；（类似于添加了链表的功能） TreeSet：可以按照添加对象的指定属性，进行排序。 Set接口没有单独定义方法，均是Collection中定义过的方法； 向Set中添加的数据，其所在的类一定要重写hashCode()和equals()方法； hashCode()和equals()还需要保持一致性。 以HashSet为例说明: 无序性：不等于随机性。存储的数据在底层数组中并非按照数组索引的顺序添加，而是根据数据的哈希值进行添加； 不可重复性：保证添加的元素按照equals()判断时，不能返回true。即：相同的元素只能添加一个。 添加元素的过程：（以HashSet为例说明） 我们向HashSet中添加元素a，首先调用元素a所在类的hashcode()方法，计算元素a的哈希值，此哈希值接着通过某种算法计算出在HashSet底层数据中的存放位置（即为索引位置），判断数组此位置上是否有元素： ​ 如果此位置上没有其他元素，则a添加成功； —&gt; 情况一 ​ 如果此位置上有其它元素b（或以链表形式存在的多个元素），则比较元素a与元素b的hash值： ​ 如果hash值不同，则元素a添加成功； —&gt;情况二 ​ 如果hash值相同，进而需要调用元素a所在类的equals()方法： ​ equals() 返回true，元素a添加失败； ​ equals() 返回false，元素a添加成功。 —&gt;情况三 对于添加成功的情况二和情况三而言，元素a与已经存在指定索引位置上的数据以链表的方式存储。 Jdk7：元素a放到数组中，指向原来的元素 Jdk8：原来的元素在数组中，指向元素a HashSet底层：数组+链表 TreeSet：可以按照添加对象的指定属性，进行排序 向TreeSet中添加数据，需要保证是相同类的对象； 两种排序方式：自然排序（实现comparable接口）和定制排序（Comparator类）； 自然排序时，比较两个对象相同的标准为：compareTo()返回0，而不是equals()； 定制排序时，比较两个对象相同的标准为：compare()返回0，而不是equals() Map接口Map接口：双列数据，用来存储一对（key-value）一对的数据。 HashMap：作为Map的主要实现类；线程不安全的，效率高；可以存储null的key和value；LinkedHashMap：保证遍历map元素时，可以按照添加的顺序实现遍历；在原有的HashMap底层结构的基础上，添加了一对指针，指向前一个和后一个元素；对于频繁的遍历操作，执行效率要高于HashMap；底层使用红黑树； TreeMap：可以按照添加的key-value对进行排序，实现排序遍历，此时考虑key的自然排序或定制排序； Hashtable：Map的古老实现类；线程安全的，效率低；不可以存储null的key和value； Properties：常用来处理配置文件，key和value都为String类型。 Map结构的理解： key是无序的、不可重复的，使用Set存储所有的key； —&gt;key所在的类要重写equals()和hashCode() value是无序的、可重复的，使用Collection存储所有的value； —&gt;value所在的类要重写equals() 一个键值对：key-value构成了一个Entry对象，使用Set存储所有的Entry HashMap类HashMap的底层结构：数组+链表（jdk7之前） 数组+链表+红黑树（jdk8之后） HashMap原理：jdk7 HashMap map = new HashMap()： 在实例化以后，底层了创建了一个长度是16的一维数组Entry[] table …可能执行了多个put… map.put(key1, value1)： 首先调用key1所在类的hashcode()计算key1的哈希值，此哈希值接着通过某种算法计算以后，得到在Entry数组中的存放位置。判断数组此位置上是否有元素： ​ 如果此位置上的数据为空，则key1-value1添加成功； —&gt; 情况一 ​ 如果此位置上的数据不为空（意味着存在一个或多个数据（以链表形式存在）），则比较key1与已经存在元素的hash值： ​ 如果hash值都不同，则key1-value1添加成功； —&gt;情况二 ​ 如果key1的hash值与已经存在的某一个元素key2-value2相同，则比较equals()方法： ​ equals() 返回true，使用value1替换value2； ​ equals() 返回false，元素a添加成功。 —&gt;情况三 对于添加成功的情况二和情况三，此时key1-value1与已经存在指定索引位置上的数据以链表的方式存储。 在不断的添加过程中，会存在扩容问题，默认的扩容方式：扩容为原来的两倍，并将数据复制。 HashMap原理：jdk8 jdk8相较于jdk7在底层实现方面的不同: new HashMap()：底层没有创建一个长度为16的数组； jdk 8底层的数组是：Node[]，而非Entry[]； 首次调用put()方法时，底层创建长度为16的数组； jdk7底层结构只有：数组+链表。jdk8中底层结构：数组+链表+红黑树； 当数组的某一个索引上的元素以链表形式存在的个数&gt;8，且当前数组的长度&gt;64时，此时此索引位置上的数据改为红黑树存储。 Map的常用方法 遍历所有的key集：keySet Map map = new HashMap(); …..多次put…. Set set = map.keySet(); Iterator iter = set.iterator(); while(iter.hasNext()): System.out.println(iter.next());} 遍历所有的value集：values() Collection values = map.values(); for(Object obj : values): System.out.println(obj);} Collections工具类Collections工具类：可以操作Collection和Map的工具类 使用方法：如 List list = new Arraylist(); ​ ….多次add….. ​ Collections.reverse(list);","link":"/2023/01/14/java%E5%9F%BA%E7%A1%80%E4%BA%94/"},{"title":"java基础（二）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的面向对象部分（上），包括类和对象的介绍，封装性、继承性的体现等，此外介绍了关键字this、package、import、super的使用。 java类和对象类是抽象的一类事物，对象是具体的一个实例。 类的定义： class Person{ ​ //属性 String name; int age = 10; //方法 public void speak(String language) { system.out.println(‘说的语言是:’, language) }} 类的实例化: Person zhangsan = new Person() 调用属性和方法：zhangsan.name; zhangsan.speak(‘Chinese’) 方法的声明：权限修饰符 返回值类型 方法名(形参列表) { ​ 方法体 ​ } 四种权限修饰符：private、public、缺省、protected 返回值类型： 若没有返回值 则为void，在方法中不写return或就写一个return; 若有返回值 则需要在声明时写返回值的类型，并在方法中写 return+返回值 关于变量的赋值： 如果变量是基本数据类型，则此时赋值的是变量所保存的数据 如果变量是引用数据类型，则此时赋值的是变量所保存数据的地址值 方法形参的传递机制：值传递 形参：方法定义时，声明的小括号的参数 实参：方法调用时，实际传递给形参的数据 值传递机制： 如果参数是基本数据类型，此时实参赋给形参的是实参真实存储的数据值 如果参数是引用数据类型，此时实参赋给形参的是实参存储数据的地址值 构造器（构造方法，constructor）：任何类中都有，用于1.创建对象 2.属性初始化 使用位置：Person zhangsan = new Person() 其中Person()就是构造器 如果没有显式的定义类的构造器的话，则系统默认提供一个空的构造器 构造器的表示为 类名()，可以理解为名称与类名相同的方法，类似于python的__init__ 一个类中可以定义多个构造器，彼此构成重载 一旦定义了显式构造器，则系统不再提供空的构造器 属性赋值的先后顺序：默认初始化(系统默认值)-显式初始化(类中定义时手动的赋值)/代码块中赋值(取决于先后顺序)-构造器中赋值-通过’对象.属性’或’对象.方法’赋值 java类的封装性封装性的设计思想：隐藏对象内部的复杂性，只对外公开简单的接口，便于外界调用，从而提升系统的可扩展性、可维护性。通俗的说，把该隐藏的隐藏起来，该暴露的暴露起来。 封装性的体现：我们将类的属性xxx私有化(private)，同时提供公共的(public)方法来获取(getXxx)和设置(setXxx)此属性的值。 这只是一个体现，还有很多体现，如设置不对外暴露的私有化方法，只在类中可见；单例模式，即构造器的私有化等。 封装性的体现，需要权限修饰符的配合。从小到大排列：private、缺省、protected、public 修饰符 类内部 同一个包 不同包的子类 同一个工程 private Yes default(缺省) Yes Yes protected Yes Yes Yes public Yes Yes Yes Yes 注：1. 对于类的权限修饰只能是public和缺省。其中public可以在任意地方被访问，缺省类只可以被同一个包的内部访问。 ​ 2. 四种权限都可以用来修饰类的内部结构：属性，方法，构造器，内部类 this的使用： this可以用来修饰、调用：属性、方法、构造器 this修饰属性和方法：this理解为：当前对象 ​ 2.1. 在类的方法中，我们可以使用’this.属性’或’this.方法’的方式，调用当前对象的属性或方法，但是，通常情况下，我们都选择省略’this.’。特殊情况下，如果方法的形参与类的属性同名时，我们必须显示的使用’this.变量’的方式，表明此变量是属性，而不是形参。 ​ 2.2. 在类的构造器中，我们可以使用’this.属性’或’this.方法’的方式，调用当前正在创建的对象属性或方法，但是，通常情况下，我们都选择省略’this.’。特殊情况下，如果构造器的形参与类的属性同名时，我们必须显示的使用’this.变量’的方式，表明此变量是属性，而不是形参。 this调用构造器 ​ 3.1 我们在类的构造器中，可以显示的使用’this(形参列表)’方式，调用本类中指定的其它构造器 ​ 3.2 构造器不能通过’this(形参列表)’自己调用自己；如果类中有n个构造器，最多有n-1个构造器使用’this(形参列表)’调用其它构造器 ​ 3.3 规定’this(形参列表)’必须声明在当前构造器的首行，构造器内部最多只能声明一个’this(形参列表)’来调用其他的构造器 package: 包 便于实现项目中类的管理 同一个包下，不能命名同名的类、接口 不同的包下，可以命名同名的类、接口 import: 导入 1．在源文件中显式的使用import结构导入指定包下的类、接口 2．声明在包的声明和类的声明之间 3．如果需要导入多个结构,则并列写出即可 4．可以使用”XXX.*”的方式,表示可以导入XXX包下的所有结构 5．如果使用的类或接口是java.lang包下定义的，则可以省略import结构 6．如果使用的类或接口是本包下定义的，则可以省略import结构 7．如果在源文件中，使用了不同包下的同名的类，则必须至少有一个类需要以全类名的方式显示。 8．使用”xxx.*”方式表明可以调用xxx包下的所有结构。但是如果使用的是xxx子包下的结构，则仍需要显式导入: 9．import static:导入指定类或接口中的静态结构。 java类的继承性继承性的好处： 减少了代码的冗余，提高了代码的复用性 便于功能的扩展 为之后的多态性的使用，提供了前提 继承性的格式： class A extends B{} A：子类、派生类、subclass B：父类、超类、基类、superclass 一旦子类A继承了父类B，子类A中就获取了父类B中的声明的所有属性和方法。 特别的，父类中声明为private的属性或方法，子类继承父类以后，仍然认为获取了父类中私有的结构。只有因为封装性的影响,使得子类不能直接调用父类的结构而已。 子类继承了父类后，还可以声明自己的属性或方法，实现功能的拓展。 注意： 子父类是相对的概念；子类直接继承的父类，称为:直接父类。间接继承的父类称为:间接父类 子类继承父类以后，就获取了直接父类以及所有间接父类中声明的属性和方法 如果没有显式声明父类的话，则此类继承于java.lang.Object类 方法的重写： 在子类中可以根据需要对从父类中继承来的方法进行改造，也称为方法的重置、覆盖。在程序执行时，子类的方法将覆盖父类的方法。 子类重写的方法必须和父类被重写的方法具有相同的方法名称、参数列表 子类重写的方法的返回值类型不能大于父类被重写的方法的返回值类型3.子类重写的方法使用的访间权限不能小于父类被重写的方法的访问权限 子类不能重写父类中声明为private权限的方法 子类方法抛出的异常不能大于父类被重写方法的异常注意: 注意：子类与父类中同名同参数的方法必须同时声明为非static的(即为重写)，或者同时声明为static的（不是重写)。因为static方法是属于类的，子类无法覆盖父类的方法。 super的使用： 对于this，是先在自己类中找属性或方法，如果没找到，然后再去对应父类找 对于super，则是直接在父类中找，如果直接父类没有，再继续往上找 （this就是理解为自己类，super理解为父类） super调用属性或方法： 1．我们可以在子类的方法或构造器中。通过使用”super.属性”或”super.方法”的方式，显式的调用父类中声明的属性或方法。但是,通常情况下,我们习惯省略”super. “ 2．特殊情况：当子类和父类中定义了同名的属性时，我们要想在子类中调用父类中声明的属性，则必须显式的使用”super.属性”的方式，表明调用的是父类中声明的属性。 3．特殊情况：当子类重写了父类中的方法以后，我们想在子类的方法中调用父类中被重写的方法时，则必须显式的使用”super.方法”的方式,表明调用的是父类中被重写的方法。 super调用构造器 1． 我们可以在子类的构造器中显式的使用”super(形参列表)”的方式，调用父类中声明的指定的构造器 2．”super(形参列表)”的使用,必须声明在子类构造器的首行! 3．我们在类的构造器中，针对于”this(形参列表)”或”super(形参列表)”只能二选一，不能同时出现 4．在构造器的首行，没有显式的声明”this(形参列表)”或”super(形参列表)”，则默认调用的是父类中空参的构造器 5．在类的多个构造器中，至少有一个构造器使用了”super(形参列表)”(显式或隐式)，调用父类的构造器 子类对象实例化的全过程 1．从结果上来看:（继承化） 子类继承父类以后，就获取了父类中声明的属性或方法。 创建子类的对象,在堆空间中,就会加载所有父类中声明的属性。 2．从过程上来看: 当我们通过子类的构造器创建子类对象时，我们一定会直接或间接的调用其父类的构造器，进而调用父类的父类的构造器.直到调用了java.lang.Object类中空参的构造器为止。正因为加载过所有的父类的结构，所以才可以看到内存中有父类中的结构,子类对象才可以考虑进行调用。 明确：虽然创建子类对象时调用了父类的构造器，但是自始至终就创建过一个对象，即为new的子类对象。","link":"/2023/01/12/java%E5%9F%BA%E7%A1%80%E4%BA%8C/"},{"title":"java基础（六）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的高级特性——泛型和IO流。在IO流中，会介绍File类、文件流和处理流（缓冲流、转换流、对象流等）的使用。 java泛型在集合中使用泛型： 集合接口或集合类在jdk5.0时都修改为带泛型的结构。在实例化集合类时，可以指明具体的泛型类型； 指明完以后，在集合类或接口中凡是定义类或接口时，内部结构（比如：方法、构造器、属性等）使用到类的泛型的位置，都指定为实例化时的反向类型； 比如: add(E e) —&gt;实例化以后: add(Integer e) 注意点：泛型的类型必须是类，不能是基本数据类型。需要用到基本数据类型的位置，拿对应的包装类作为泛型的类型； 如果实例化时，没有指明泛型的类型。默认类型为java.lang.object类型。 IO流File类File类的使用 File类的一个对象，代表一个文件或一个文件目录（文件夹）； 来自于java.io包下； 实例化方法1：File file1 = new File(“hello.txt”); //相对路径，相对于当前module 实例化方法2：File file2 = new File(“D:\\study\\java\\hello.txt”); //绝对路径 实例化方法3：File file3 = new File(“study”, “java”); //父路径+子路径 实例化方法4：File file4 = new File(file3, “hello.txt”); //之前的file路径+新增路径 File类中只涉及到关于文件和文件目录的创建、删除、重命名等方法，并未设计到写入或读取文件内容的操作。如果需要写入或读取内容，必须使用IO流实现； 后续File类的对象常会作为参数传递到流的构造器中，指明读取或写入的“终点”。 File的创建和删除123456789101112131415//创建和删除文件File file1 = new File(&quot;hello.txt&quot;);//如果file1在硬盘中不存在，则创建file1if(!file1.exists()){ file1.createNewFile();}else{ //文件存在，就删除文件 file1.delete() }//创建文件目录File file2 = new File(&quot;D:\\\\io\\\\io1&quot;);Boolean mkdir1 = file2.mkdir(); //只创建当前目录，前提是其父目录一定存在，否则返回false创建失败Boolean mkdir2 = file2.mkdirs(); //会创建上层没有的目录，不管父目录是否存在都会创建成功if(mkdir1): System.out.println(&quot;创建成功&quot;) 文件流IO流原理和分类： IO是Input/Output的缩写，用于处理设备之间的数据传输，如读/写文件，网络通讯等； java程序中，对于数据的输入/输出操作以“流stream”的方式进行； IO流的相关类和接口来自于java.io包中，通过标准的方法输入和输出数据； 我们是站在内存（即程序）的角度理解输入（读取外部数据到内存）和输出（将程序的数据输出到外部）； 按操作数据单位分为字节流（8 bit）和字符流（16 bit）；按流向分为输入流和输出流；按流的角色分为节点流和处理流。 基础类有：字节输入流InputStream，字节输出流OutputStream；字符输入流Reader，字符输出流Writer。这些都是抽象类，派生的子类才能被实例化，对应的子类的名称都是以其父类名称作为后缀。 文件内容的读入：FileReader例子：将hello.txt内容读入到程序中，并输出 read()的理解：返回读入的第一个字符，如果达到文件末尾，则返回-1； 异常的处理：为保证流资源一定可以执行关闭操作，需要使用try-catch-finally处理异常; 读入的文件一定要存在，否则会报异常。 1234567891011121314151617181920212223242526272829303132333435363738FileReader fr = null;try{//1.实例化File对象，指明需要操作的文件File file = new File(&quot;hello.txt&quot;); //2.提供具体的流fr = new FileReader(file); //3.读入操作//3.1 方法一：一次读一个//int data;//while(data = fr.read() != -1):{//System.out.print((char)data);//}//3.2 方法二：一次读指定个char[] cbuf = new char[5]; // 一次五个int len;while((len = fr.read(cbuf)) != -1){ //3.2.1用for循环读 for(int i = 0; i &lt; len; i++){ System.out.print(char[i]); } //3.2.2 还可以用String读取char[]内容 String str = new String(cbuf, 0, len); System.out.print(str); }} catch (IOException e){ e.printStackTrace();} finally{//4.流的关闭if(fr != null){ try{ fr.close();} catch (IOException e){ e.printStackTrace(); } }} 从内存中写出数据到硬盘的文件里：FileWriter例子：将hello.txt内容读入到程序中，并写入到hello1.txt中。 输出操作时，对应的File可以不存在。如果不存在，会自动创建文件；如果存在，调整构造器FileWriter(file, true/false)，决定是否向原文件中追加内容，即false为覆盖原文件； FileInputStream和FileOutputStream实现原理与FileReader和FileWriter同理； 字符流不能处理图片这种字节数据；字节流处理文本文件有时候会出现乱码。因此，通常，对于文本文件（.txt, .java, .c, …），使用字符流处理，对于非文本文件（.jpg, .mp3, .avi, .doc, …），使用字节流处理； 12345678910111213141516171819202122232425262728293031323334//由于会有异常，finally中一定会运行，因此需要先定义FileReader和FileWriter的对象FileReader fr = null;FileWriter fw = nulltry{//1.实例化File对象，指明读入和写出到的文件File srcfile = new File(&quot;hello.txt&quot;);File destfile = new File(&quot;hello1.txt&quot;);//2.提供具体的流fr = new FileReader(file) ;fw = new FileWriter(file) ;//3.读入和写出操作char[] cbuf = new char[5]; // 一次五个int len;while((len = fr.read(cbuf)) != -1){ //每次写多个字符 fw.write(cbuf, 0, len) }}catch (IOException e){ e.printStackTrace();} finally{//4.流的关闭if(fr != null){try{ fr.close();} catch (IOException e){ e.printStackTrace();}}if(fw != null){try{ fw.close();} catch (IOException e){ e.printStackTrace();}}} 处理流之一：缓冲流处理流均为 在节点流之外包裹的一个流，用于对节点流进行优化操作。 缓冲流的作用：提高流的读取、写入的速度。 主要包括：BufferedInputStream; BufferedOutputStream; BufferedReader; BufferedWriter 任务：添加缓冲层后实现非文本文件的复制 1234567891011121314151617181920212223242526272829303132333435363738394041424344BufferedInputStream bis = null;BufferedOutputStream bos = null;try{//1.实例化File对象，指明读入和写出到的文件File srcfile = new File(&quot;爱情与友情.jpg&quot;);File destfile = new File(&quot;爱情与友情1.txt&quot;);//2.提供具体的流//2.1 造节点流（文件流）FileInputStream fis = new FileInputStream(srcfile);FileOutputStream fos = new FileOutputStream(destfile);//2.2 造缓冲流bis = new BufferedInputStream(fis) ;bos = new BufferedOutputStream(fos) ;//3.读入和写出操作byte[] buffer = new byte[5]; // 一次五个int len;while((len = bis.read(buffer)) != -1){//每次写多个字符bis.write(buffer, 0, len);}}catch (IOException e){ e.printStackTrace();} finally{//4.流的关闭 关闭缓冲流即可，因为会自动关闭内层的文件流if(bis != null){try{ bis.close();} catch (IOException e){ e.printStackTrace();}}if(bos != null){try{ bos.close();} catch (IOException e){ e.printStackTrace();}}}//注意：对于BufferedReader，有一个新的方法：readLine，用于读取数据，就不用定义char[]数组了。//使用方法：String data;while(data = br.readLine() != null){ //每次写一行文本 bw.write(data); // data中不包含换行符 bw.newLine(); //新建一行} 处理流之二：转换流转换流：属于字符流。包含： InputStreamReader：将一个字节的输入流转换为字符的输入流； OutputStreamWriter ：将一个字符的输出流转换为字节的输出流 作用：提供字符流和字节流之间的转换。 解码：字节、字节数组 –&gt; 字符数组、字符串； 编码：字符数组、字符串 –&gt; 字节、字节数组。 例子： 解决任务：如将UTF-8格式的txt文件复制，并转换为jbc格式的新的txt文件输出。（将字节转换成字符流的方式，读取和写入txt文件，最终又以字节流保存）（因为之前提到过，字节流读取文本数据会出现乱码） 解决方法：1.实例化File；2.造节点流（字符节点流）；3.造转换流：读为InputStreamReader，写为OutputStreamWriter；4.关闭流，关闭外层即可。 处理流之三：对象流对象流用于存储和读取基本数据类型数据或对象的处理流。它的强大之处就是可以把java中的对象写入到数据源中，也能把对象从数据源中还原出来。 主要包括的类有：ObjectInputStream和ObjectOutputStream 序列化：用ObjectOutputStream类保存基本类型数据或对象的机制； 反序列化：用ObjectInputStream类读取基本类型数据或对象的机制； ObjectInputStream和ObjectOutputStream不能序列化static和transient修饰的成员变量。 对象的序列化： 对象序列化机制允许把内存中的Java对象转换成平台无关的二进制流，从而允许把这种二进制流持久地保存在磁盘上，或通过网络将这种二进制流传输到另一个网络节点。当其它程序获取了这种二进制流，就可以恢复成原来的Java对象； 序列化的好处在于可将任何实现了Serializable接口的对象转化为字节数据，使其在保存和传输时可被还原； 序列化是RMI (Remote Method Invoke-远程方法调用）过程的参数和返回值都必须实现的机制，而RM是JavaEE的基础。因此序列化机制是JavaEE平台的基础； 如果需要让某个对象支持序列化机制，则必须让对象所属的类及其属性是可序列化的，为了让某个类是可序列化的，该类必须实现如下两个接口之一（Serializable，Externalizable）。否则，会抛出NotSerializableException异常。","link":"/2023/01/14/java%E5%9F%BA%E7%A1%80%E5%85%AD/"},{"title":"java基础（四）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的高级特性（上），包括java多线程，java常用类，枚举类与注解等，java的常用类中主要介绍String类。 java多线程创建多线程方式一：继承于Thread类 创建一个继承于Thread类的子类； 重写Thread类的run() –&gt;将此线程执行的操作声明在run()中； 创建Thread类的子类的对象；（可创建多个） 通过此对象调用start()：①启动当前线程；②调用当前线程的run()方法 则start后面的程序为主线程，run中运行的程序为子线程，二者同时运行。 Thread中的常用方法: start()：启动当前线程；调用当前线程的run()； run()：通常需要重写Thread类中的此方法，将创建的线程要执行的操作声明在此方法； currentThread()：静态方法，返回执行当前代码的线程； getName()：获取当前线程的名字； setName()：设置当前线程的名字； yield()：释放当前cpu的执行权； join()：在线程a中调用线程b的join()，此时线程a就进入阻塞状态，直到线程b完全执行完以后，线程a才结束阻塞状态； stop()：已过时。当执行此方法时，强制结束当前线程； sleep(long millitime)：让当前线程”睡眠”指定的millitime毫秒。在指定的millitime毫秒时间内，当前线程是阻塞状态； isALive()：判断当前线程是否存活。 getPriority()：获取线程的优先级 setPriority()：设置线程的优先级 注意：高优先级的线程会抢占低优先级的线程的cpu，但不是高优先级的线程先执行，再执行低优先级的线程；而只是一个概率问题。 方式二：实现Runnable接口 创建一个实现了Runnable接口的类； class Windows implements Runnable 实现类去实现Runnable中的抽象方法: run()； 创建实现类的对象； Windows w= new Windows() 将此对象作为参数传递到Thread类的构造器中，创建Thread类的对象；（可创建多个） 如：Thread t1 = new Thread(w); Thread t2 = new Thread(w)… 通过Thread类的对象调用start()：①启动线程；②调用当前线程的run()–&gt;调用了Runnable类型的target的run()，也就是自己写的run() 。 t1.start(); t2.start()… 优先使用方式二，原因： 实现的方式没有类的单继承的局限性； 实现的方式更适合来处理多个线程共享数据的情况。使用方法一需要使用static 方法三：采用Callable接口（jdk5新增方法） 创建一个实现Callable接口的实现类； 实现call方法，将此线程需要执行的操作声明在call()中；—可以有返回值 创建Callable接口实现类的对象； NumThread numThread = new NumThread() 将此Callable接口实现类的对象作为参数传递到FutureTask构造器中，创建FutureTask的对象； FutureTask futureTask = new FutureTask(numThread) 将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象，并调用start()，启动线程； new Thread(futureTask).start() 获取Callable中call方法的返回值，采用get获取。 Object sum = futureTask.get() 方法四：采用线程池（jdk5新增方法）提前创建好多个线程，放入线程池中，使用时直接获取。 线程的生命周期： 线程的安全问题当一个线程未操作完时，其它线程参与进来，进行相同的操作。如：一个线程操作车票过程中，还没有操作完成，票没有卖出去，其它线程参与了进来，也操作了车票，会出现重票、错票的情况。 解决方法：一个线程a操作时，其它线程不能参与进来，直至其操作完成。这种情况即使线程a出现了阻塞，也不能被改变。java中，通过同步机制，来解决线程的安全问题。 方法一：同步代码块synchronized(同步监视器){ ​ //需要被同步的代码 } 说明：1. 操作共享数据的代码，即为需要被同步的代码； ​ 2. 共享数据：多个线程共同操作的变量。比如：票ticket就是共享数据； ​ 3. 同步监视器，俗称：锁。任何一个类的对象，都可以充当锁。其中，方法一(Thread)中可用类，方法二(Runnable)中可用this。也都可以自己创建。 要求：多个线程必须要共用同一把锁。 方法二：同步方法 使用方法：方法声明前加一个synchronized，如public synchronized void show() 同步方法也需要同步监视器，只是不需要显示声明； 非静态的同步方法，其同步监视器是this； 静态的同步方法，其同步监视器是其类本身 同步的方式，解决了线程的安全问题。但同步的代码块运行时，只能有一个线程参与，其余线程等待，因此效率低。 方法三：Lock锁需要手动启动锁（启动同步 lock()）和手动关闭锁（关闭同步unlock()） java常用类String类的介绍 代表字符串，使用一对””引起来表示，代表不可变的字符序列； ​ 体现：1.当对字符串重新赋值时，需要重写指定内存区域赋值，不能使用原有的value进行赋值；2.对字符串进行拼接或字符替换时，也会重新指定内存区域赋值，不能使用原有区域添加； String对象的字符内容是存储在一个字符数组value[]中的； final char[] value 可以比大小，支持序列化； 通过字面量的方式（区别于new）给一个字符串赋值，此时的字符串声明在字符串常量池中，字符串常量池不会存储相同的字符串； String s1 = “javaEE” 若采用new+构造器的方式给字符串赋值，则字符串声明在堆中，地址就会有区别了。 String s2 = new String(“javaEE”) 注意：常量和常量的拼接在常量池，但凡有一个是变量，则拼接结果在堆中。 字符串的常用方法： 注意：1. 原字符串不可变，只是添加了新的字符串 ​ 2. char值序列就可以理解为字符串 String字符串转化为基本数据类型/包装类：调用包装类的静态方法：parseXxx(str) 如：String str1 = “123” int num = Integer.parseInt(str1) //123 基本数据类型/包装类转化为String字符串：调用String重载的valueOf(xxx) 如：int num = 123 String str2 = String.valueOf(num2) //“123” String字符串转化为char[]：采用toCharArray()；反过来，调用直接调用String的构造器即可 如： String str3 = “abc123” Char[] charArray = str3.toCharArray(); // {‘a’, ‘b’, ‘c’, ‘1’, ‘2’, ‘3’} String str4 = new String(charArray) // “abc123” StringBuffer与StringBuilderStringBuffer：可变的字符序列；线程安全的，效率低；底层使用char[]存储 StringBuilder：可变的字符序列；线程不安全的，效率高；底层使用char[]存储 注意：可变和不可变只的是空间中是否创建新的地址存放变化后的字符串。可变表示不用重新创建，在原来地址处进行修改即可。主要体现为：char[]是否用final修饰 源码分析： String str = new String(); //char[] value = new char[0]; String str1 = new String(“abc”); //char[] value = new char[]{‘a’, ‘b’, ‘c’}; StringBuffer sb1 = new StringBuffer(); //char value = new char[16]; 底层创建了一个长度为16的char型数组 StringBuffer sb1 = new StringBuffer(“abc”); //char value = new char[“abc”.length()+16] StringBuffer的常用方法： 开发中建议使用StringBuffer和 StringBuilder，采用new StringBuffer(capacity)进行定义 此外常用类还有System类、Math类等等。 枚举类与注解 类的对象只有有限个、确定的，这样的类叫做枚举类。 当需要定义一组常量时，强烈建议使用枚举类。 使用enum定义枚举类： enum Season() 提供当前枚举类的对象，多个对象之间用”,”隔开，末尾对象用”;”结束； SPRING(“春天”), SUMMER(“夏天”); 声明对象的属性，用private final 修饰； private final String seasonName; 私有化类的构造器，并给对象属性赋值； private Season(String seasonName){…} 测试类调用时，直接采用类名.对象名调用。 Season summer = Season.SUMMER 注意：1.定义类：enum+类名，没有class； ​ 2.enum定义的枚举类自动继承了java.lang.enum类，如重写了toString方法，直接打印对象名 注解：Annotation Annotation其实就是代码里的特殊标记，这些标记可以在编译，类加载，运行时被读取，并执行相应的处理； Annotation可以像修饰符一样被使用，可用于修饰包，类，构造器，方法，成员变量，参数，局部变量的声明，这些信息保存在Annotation的”name=value”对中。 如@Override","link":"/2023/01/14/java%E5%9F%BA%E7%A1%80%E5%9B%9B/"},{"title":"元学习","text":"本篇文章讲解了机器学习中的元学习相关内容。首先讲解了元学习的概念和大致的算法流程，之后具体介绍了三种不同的元学习方法，包括MAML，Reptile，FOMAML。 元学习概念Meta Learning: Meta Learning 被称作元学习，不同于Machine Learning，Machine Learning的目标是让机器能够学习，Meta Learning则是要让机器学会如何去学习。 对于一般的机器学习流程，首先将原始数据分为两类(train_test_spilt)，为训练数据和测试数据，通过将训练数据代入到此学习算法F中，得到一个生成的函数f，之后利用测试数据来对此函数进行测试，并得到相应的损失值l。如果效果达标就证明机器学到了该特定任务的实现函数。 其中，传统的机器学习算法是由人来人为制定学习算法F，而Meta Learning则是机器自己生成。得到的L(F)为损失函数，为各个任务通过测试得到的损失值的和，通过损失函数可以判断此F的好坏。 具体算法首先有一个初始参数parameter，随训练数据一起代入到梯度计算中，得到此参数的更新值，循环往复，得到最后的数据θ。 损失函数定义完毕后，我们该如何降低F的损失呢？由于Meta Learning的求解是非常复杂的过程，我们先以MAML算法为例讲解一个Meta Learning的简单情况的求解。 MAML算法想要解决的问题是，对于F在每一个任务中学习到的f，规定f只负责决定参数的赋值方式，而不设计模型的架构，也不改变参数更新的方式。也就是说，MAML中的f的网络结构和更新方式都是提前固定的，MAML要解决的是如何针对不同任务为网络赋不同的初始值。 MAML在意的是用Ф训练出的θn的表现如何；而Model-training则是在意在所有task中均有最佳loss的初始值Ф。 此外对于Reptile，对应生成初始参数Ф的方向为，由初始值到多次训练得到最后的θn的方向。 实例一(MAML)概念通过大量的学习任务来得到一个模型，当出现一小批新任务时，能够对模型进行微调，并快速学习。基本思想：训练模型的初始参数，以便在通过一个或多个梯度步骤更新参数后，该模型在新任务上具有最佳性能，而该梯度步骤是根据该新任务中的少量数据计算得出的。 从此图可以看出，MAML的目标是找到对任务(task)的变化敏感的模型参数(model parameters)，这样，当损失梯度(loss gradient)的方向改变时，参数的微小变化将对从所有任务分布 p(T) 提取的任何一个任务(task)的损失函数(loss function)产生较大的改善。即可以使用新任务(new task)上少量的样本fine tune模型后得到新的模型参数(model parameters, θ)对新任务检测的性能有很大的提升。 算法过程 1、第一个Require的 p(T) 指的是meta-train中tasks的分布；第二个Require中的 α 和 β 指的是步长(step size)，也可以理解为学习率(learning rate). MAML的模型训练过程是gradient by gradient，即MAML是基于二级梯度的，每次迭代包含两次的参数更新的过程，分别对应两个学习率 α 和 β。2、步骤1：随机初始化模型的参数。3、步骤2：是一个外循坏。每次迭代可以理解为一个epoch，每个epoch训练多个任务中的若干个任务。预训练过程有多个任务，也就对应多个epoch。（循环变量：时期（mata batch）。存在这多个时期，每一个时期中有多个任务。）4、步骤3：随机对若干个(meta size)任务进行采样，形成一个meta batch训练数据。5、步骤4：这是一个内循环。利用meta batch中的每一个任务Ti，分别对模型的参数进行更新（比如4个任务更新4次参数）。（循环变量：任务(Ti)。在某一个具体时期中，有多个任务，分别对这些任务进行参数更新）6、步骤5：在N-way K-shot（N-way指训练数据中有N个类别class，K-shot指每个类别下有K个被标记数据）的设置下，利用meta batch中的某个task中的support set（任务中少量中有标签的数据，可以理解为训练集training set）的N*K个样本计算每个参数的梯度。7、步骤6：第一次梯度的更新的过程。针对Meta batch的每个任务Ti更新一次参数得到新的模型参数θi，这些新模型参数会被临时保存，用来接下的第二次梯度计算，但其并不是真正用来更来更新模型。8、步骤7：内循环结束。9、步骤8：第二次梯度更新的过程。这个是计算一个query set（另一部分有标签的数据，可以理解为验证集validation set，用来验证模型的泛化能力）中的5-wayV（V是一个变量，一般等于K，也可以自定义为其他参数比如15）个样本的损失loss，然后更新meta模型的参数，这次模型参数更新是一个真正的更新，更新后的模型参数在该次meta batch结束后回到步骤3用来进行下一次mata batch的计算。10、步骤9：外循环结束。 两个种类：（1）Regression：小样本监督学习（2）RL：强化学习区别：RL需要从任务对应的环境中采样 实例二(Reptile)一阶的基于梯度的元学习算法。 基本思想：通过重复采样任务，对其进行训练并将初始化朝着该任务的训练权重进行工作。 对应参数的更新方向：由初始值到多次训练得到最后的θn的方向。 具体算法步骤： 1、初始化参数 2、开始循环迭代i =0,1,2… 3、采样一个meta batch,每个batch内有多个任务task 4、对于每一个task，根据迭代次数k采样出含k个batch的minibatch, 5、对minibatch内的每一个batch使用梯度下降法更新初始化参数，得到Ψ’ 6、将每个task更新后的参数Ψ’与初始参数Ψ相减，将这个相减的结果经过某个映射（将这个差值看做某个梯度，加入到某种自适应的算法中）。在我们的实现中一般是（Ψ’-Ψ）/a，这个a我们一般设置为一个可以变的值。 这一步可以理解为： （Ψi~表示第i个任务上对Ti的更新操作。） 7、回到2，继续，直到循环结束。 当k=1时，算法对应于期望损失的随机梯度下降（SGD） 当k&gt;1时，算法包含了LT更高阶的微分项 Reptile的核心代码： Reptile有效的原因： 1、通过用泰勒级数近似表示更新过程，发现SGD自动给出了与MAML计算的二阶项相同的项。这一项调整初始权重，以最大限度地增加同一任务中不同小批量梯度之间的点积，从而增大模型的泛化能力。 2、Reptile通过利用多次梯度更新，找到了一个接近所有最优解流形的点。 当执行SGD更新时，MAML形式的更新过程就已经被自动包含在其中了，通过最大化模型在不同批次数据之间的泛化能力，从而使得模型在微调（fine-tune）时能取得显著的效果。 实例三(FOMAML)忽略了MAML中的二阶微分项，节省了计算开销，但损失了部分梯度信息 具体步骤： 将梯度向量视为常量，即可将雅可比矩阵转化为恒等操作，所以可以简化外循环优化过程中所使用的梯度公式。 具体流程如下： 1、采样任务T； 2、对初始化参数执行更新操作，得到ϕ~; 3、利用ϕ~计算对ϕ的梯度，得到gFOMAML; 4、将gFOMAML应用到外部循环优化中。 Reptile和FOMAML在内循环过程中都是使用的SGD进行的优化，在这个优化过程中任何微小的变化都将导致最终模型性能的巨大变化，两者对于内循环中的超参数都有很强的敏感性，FOMAML在minibatch以错误的方式选取时会出现显著的性能下降情况。","link":"/2022/12/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"title":"python常用方法","text":"本篇文章讲解了python中各个数据结构的常用方法与实现。包括：列表list，字符串，链表，队列，栈，树，堆等。 list的常用方法1.对List进行翻转：list(reverse(List))；# reversed也行，reversed是python自带，reverse是List特有，不过返回的都是迭代器 2.对List进行排序：List.sort(reverse = True)，reverse = True代表降序，默认为升序 3.插入元素：List.append() 4.插入列表：List.extend() 5.获取指定元素m的下标：List.index(m) 6.List的切割：list无法直接切割，如List[a:b][c:d]是不行的，只有numpy数组可以 但一维list可以直接切割，如List[: a] 7.读取List某一行：List[a]，不是List[a, :] 读取List某一列：[x[a] for x in List]，而不是List[:, a] 8.定义一个a*b的全零列表: s = [[0 for j in range(b)] for i in range(a)] 定义二维空列表: s=[][] 要先插入后赋值 9.list元素的删除：①list.remove(a) 删除第一个a；②list.pop(index) 删除并返回序列为index的元素，常用于栈、队列中；③切片 实际上上面说的List都是数组，数组和列表的最大区别是：数组具有索引，且数组中的数据是连续存储的。 字符串的常用方法1.字符串遍历：for i in range(Str): Str[i] // for eachstr in Str: eachstr 2.返回字符串中某一字符s的索引值：Str.index(s) 3.字符串中字符的替换：Str.replace(old, new, count)，count表示替换次数，若没有则表示全部替换 4.字符串的分割：Str.split(s). 将字符串Str沿字符s进行切割，并返回各部分组成的数组 5.字符串的拼接：Str = Str1 + Str2 + Str3 6.字符串的翻转：’’.join(reversed(Str)); 列表合并为字符串’’.join(Str) 7.计算一个字符串中间某个字符出现的次数: Str1.count(s) 8.大小写转化：.lower()；.upper() 9.字符串的查找：Str.find(s, begin, end) (从Str中查找s，begin end为开始和结束的下标) 10.字符串的删除：①Str.strip(s）从str中删除s的所有符号； ②删除固定位置字符：切片操作s’=Str[0:3]+Str[4:] 删除Str中第三个位置 ③删除字符串中的某一种字符：替换操作Str.replace(s, ‘’) 链表的常用方法1.单链表插入新节点： class Node: # constructor def init(self, data, next=None): ​ self.data = data；self.next = next # 插在开头 dummy = Node(0)；dummy.next = head；head = dumy；return head # 插在中间 dummy = Node(0)；dummy.next = prev.next；prev.next = dummy # 插在末尾 dummy = Node(0) while head.next: head = head.next head.next = dummy；dummy.next = None 2.单链表删除结点时，可以先找到要删除结点的上一个结点node，node.next = node.next.next，同时还不用考虑删除最后一个结点的情况，因为右边为None 3.双链表基本方法：查找、插入、删除，见Leetcode707.设计链表 https://leetcode.cn/problems/design-linked-list/ 记住，链表可以直接用头结点来表示，返回头结点就等于返回了整个链表； 记住，一旦一个节点的next指向了None，就不能直接对这个None赋值了，而是要让该节点的next指向一个新的值 队列的常用方法队列(先进先出FIFO) python实现队列： import collections q = collections.deque()// q=list() 一般情况下用list就行了，deque是双端队列 q.append(element); q.popleft() // q.pop(0) 一定要加上0，因为list的地址是固定的 注：list没有empty()方法 栈的常用方法栈(后进先出LIFO) python实现栈： import collections q = collections.deque() // q=list() 一般情况下用list就行了 q.append(element); q.pop() # pop会返回取出元素 树的常用方法树的遍历 前序遍历[https://leetcode.cn/leetbook/read/data-structure-binary-tree/xeywh5/]： 递归： 非递归： 中序遍历：[https://leetcode.cn/leetbook/read/data-structure-binary-tree/xecaj6/] 后序遍历：[https://leetcode.cn/leetbook/read/data-structure-binary-tree/xebrb2/] 总结一下：三种遍历的中心思想是一致的，若采取非递归的方法，都需要创建一个栈。然后都是先按左子树找到最左边的叶子结点，并依次入栈，之后进行出栈并遍历右子树。对于后序遍历，出栈需要进行条件判定：右子树为空或已经遍历，才能出栈，因此需要设定标志位。 层序遍历：[https://leetcode.cn/leetbook/read/data-structure-binary-tree/xefh1i/] 注意，与链表相似，树的根节点可以代表整棵树，对根节点采用left和right属性就可以调用各个节点。在leetcode中，返回根节点等于返回了整棵树，但是不要忘了，它本质上还是一个节点。 堆的常用方法python中的优先队列都是从小到大排列的（即最小根堆），主要方法有： q = list() 1.heapq.heapify(q) 列表转化为堆 2.heapq.heappush(q, (value,key)) 将m放入堆中—O(logn) 3.heapq.heappop(q) 弹出并返回堆顶元素，即最小值 排序方法：按value大小排序","link":"/2022/12/22/python%E6%96%B9%E6%B3%95/"},{"title":"机器学习优化方法讲解","text":"本篇文章讲解了机器学习中的优化方法。包括梯度下降算法及其优化算法等。 1）梯度下降算法： ①BGD(Batch gradient descent)： 采用整个训练集的数据来进行梯度的计算，对于凸函数可以收敛到全局最小值，非凸函数可以收敛到局部最小值。 优点：梯度是在全部数据集上计算出的，因此每次迭代都是向着整体的最优化方向 缺点：计算量大，速度慢； ​ 容易陷入极小值点，因为在极小值点（鞍点）梯度为0，所以参数不会更新。 ②SGD(Stochastic gradient descent)： 和BGD 的一次用所有数据计算梯度相比，SGD 每次更新时随机选择一个样本进行梯度更新，一次只进行一次更新。 优点：速度快，并且可以新增样本； ​ SGD 可能会跳到更好的局部极小值处，因为极小值时，梯度是随机选择的一个样本，这个梯度未必是0。 缺点：SGD不是每次迭代都向着整体最优化方向，准确度下降，不是全局最优； ​ SGD 因为更新比较频繁，会造成 cost function 有严重的震荡。 ③Mini-batch gradient descent： 将二者综合，每一次参数更新时使用样本中的一小部分（使用一小批数据进行更新）。 缺点：不能保证很好的收敛性。学习率太小收敛慢，太大会在极小值附近震荡。 ​ batch-size大小难以选择。 2）梯度下降算法的优化：①动量梯度下降算法(Momentum)： 梯度不仅与当前梯度有关，还与之前的梯度有关，这样参数更新的方向会朝向更加有利于收敛的方向（有利于减小震荡），收敛速度更快。对于动量梯度下降算法，当前时刻的梯度是 从开始时刻到当前时刻的梯度指数加权平均。 其中动量参数通常取0.9左右。 优点：增加收敛稳定性，减小震荡，收敛速度更快 缺点：所有特征用同一种学习率，无法进行学习率自适应调节，如对于稀疏特征更希望大一点的学习率； ②自适应梯度算法Adagrad(Adaptive gradient algorithm): Adagrad可以对低频的参数做较大的更新，对高频的做较小的更新，对于稀疏的数据它的表现很好，很好地提高了 SGD 的鲁棒性。Adagrad优化算法就是在每次使用一个 batch size 的数据进行参数更新的时候，算法计算所有参数的梯度，那么其想法就是对于每个参数，初始化一个变量 s 为 0，然后每次将该参数的梯度平方求和累加到这个变量 s 上，然后在更新这个参数的时候，学习率就变为： Adagrad 的核心想法是：如果一个参数的梯度一直都非常大，那么其对应的学习率就变小一点，防止震荡，而一个参数的梯度一直都非常小，那么这个参数的学习率就变大一点，使得其能够更快地更新，这就是Adagrad算法加快深层神经网络的训练速度的核心。 ③均方根传递算法RMSProp(Root Mean Square Prop)： RMSprop 是为了解决 Adagrad 学习率急剧下降的问题。RMS使用的是指数加权平均，旨在消除梯度下降中的摆动，与Momentum的效果一样，某一维度的导数比较大，则指数加权平均就大，某一维度的导数比较小，则其指数加权平均就小，这样就保证了各维度导数都在一个量级，进而减少了摆动。 建议η=0.001，β=0.9. ④ADAM(Adaptive Moment Estimation)： Adam不仅存储了过去梯度的平方的指数衰减平均值，还像Momentum一样保持了过去提取的指数衰减平均值。 如果 mt 和 vt 被初始化为 0 向量，那它们就会向 0 偏置，所以做了偏差校正，通过计算偏差校正后的 mt 和 vt 来抵消这些偏差： 梯度更新规则: 超参数设定：建议β1 ＝ 0.9，β2 ＝ 0.999，ϵ ＝ 10e−8。","link":"/2022/12/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/"},{"title":"机器学习-成员推断攻击","text":"本篇文章讲解了机器学习中的成员推断攻击（Membership Inference Attack, MIA），成员推断攻击是指：给定一个数据记录，攻击者需要判断该数据记录是否存在于目标模型的训练数据集中。本文将依次讲解：成员推断攻击的分类，白盒成员推断攻击，黑盒成员推断攻击，以及数据模型泄露的结论。 成员推断攻击的分类1.按攻击者的观察方式分为白盒和黑盒攻击： ​ 其中，黑盒攻击者无法访问参数和计算过程，但给定输入可以观测到输出值；白盒攻击时，这些中间结果对于攻击者来说是可得的。除此之外，模型的参数和结构对于攻击者来说也是可见的。 2.按攻击者的目标分，目标可以是独立学习和联邦学习： ​ 其中，独立学习时，攻击者可以观测到微调前后的模型情况；联邦学习时，攻击者可以作为中心服务器或者参与者进行观测。 3.按攻击者的攻击模式分为主动攻击和被动攻击： ​ 推理攻击大多数为被动攻击，即对手在不改变学习过程的情况下进行观察；而主动攻击中，参与训练过程的对手可以主动影响目标模型，以提取有关其训练集的更多信息。 4.按先验知识分为监督和非监督学习攻击： ​ 若对手的数据集D’与目标数据集D重叠。给定该数据集，他可以以监督的方式训练攻击模型，并用其攻击其余的训练数据集。而非监督攻击时，攻击者可以访问与目标训练集D部分重叠的数据集D’，但是，对手不知道D’∩D中的数据点。 白盒成员推断攻击这里白盒成员推断攻击的讲解以《Comprehensive Privacy Analysis of Deep Learning》论文为例，并应用于了联邦学习的环境中。其白盒攻击结构为： ​ 其中，攻击者知道目标模型的训练数据(x,y)和模型的参数信息W，模型f，并可以计算得到隐藏层h、模型输出f(x)和损失值L。将这些信息作为攻击模型的输入，经过卷积神经网络和全连接网络等形式，计算得出相应的攻击输出值，并获得成员信息。若为非监督模式，则还需要结合译码过程，得到最终的模型。 ​ 成员推理攻击的目的：判断某个数据记录是否属于目标的训练集。 ​ 联邦学习的详细解释：拥有不同训练集Di的N个参与者就单个深度学习任务和模型架构达成共识，以训练全局模型。 中央服务器为全局模型保留参数W的最新版本。 每个参与者具有局部模型，因此具有局部参数Wi。 在培训的每个时期，每个参与者都下载全局参数，使用SGD算法在其本地培训数据上对其进行本地更新，然后将其上传回服务器。参数服务器使用所有参与者上载的参数来计算每个参数的平均值。这种协作式培训一直持续到全局模型收敛为止。 黑盒成员推断攻击对于黑盒成员推断攻击，攻击者不知道目标模型的结构。这里以论文《Membership Inference Attacks Against Machine Learning Models》为例，这是第一篇有关成员推断攻击的文章，主要思想是借助一个与目标模型类似的模型（影子模型），来实现成员推断攻击。 攻击条件与判定：给予攻击者数据记录和对目标模型的黑匣子查询访问权限。如果攻击者可以正确确定此数据记录是否属于模型的训练数据集，则攻击成功。攻击准确性的标准度量标准是精度（由成员推断出的记录的确确实是训练数据集的成员）和召回率（由攻击者正确推断出训练数据集的成员的几率）。 黑盒设置中的成员资格推断攻击。攻击者使用数据记录查询目标模型并获得对该记录的模型预测。预测是记录属于某个类的概率向量(每类一个)。该预测向量与目标记录的标签一起传递到攻击模型，攻击模型会推断记录是在目标模型的训练数据集中还是不在目标模型的训练数据集中。 攻击者的目的：构建一个攻击模型，该模型可以识别目标模型行为中的此类差异，并仅根据目标模型的输出，使用它们来区分目标模型训练数据集的成员与非成员。 需要通过影子模型来构建攻击模型： ​ 借助影子模型来生成攻击模型的训练数据集(下图中的Attack Training Set)，进而生成攻击模型。推断影子模型的训练数据集中的成员资格，会生成一个攻击模型，该攻击模型也可以成功地推断目标模型的训练数据集中的成员资格。 ​ 使用与用于训练目标模型相同的机器学习平台来训练影子模型。目标模型和阴影模型的训练数据集具有相同的格式，但不相交。阴影模型的训练数据集可能会重叠。所有模型的内部参数均经过独立训练。 ​ 虽然目标模型的类型和结构是未知的，但是攻击者知道训练目标模型相关的服务信息，可以使用与用于训练目标模型的服务完全相同的服务，例如GooglePrediction API来训练影子模型，来做到二者模型平台类似，训练数据集格式类似。 影子模型的数据从何而来(上图中的Training Set and Test Set)： ​ ①如果攻击者没有真实的训练数据，也没有关于其分布的任何统计信息，他可以使用目标模型本身为阴影模型生成合成训练数据(借助具体算法，详见论文Ⅴ.C) ​ ②攻击者具有一些有关从中提取目标模型的训练数据的统计信息(如不同特征的边际分布的先验知识)。 在我们的实验中，我们通过从每个特征的边际分布中独立采样每个值的值来生成阴影模型的综合训练记录。 ​ ③攻击者可能会访问一些与目标模型的训练数据相似的数据，并被视为“嘈杂”版本。 在我们使用位置数据集的实验中，我们通过翻转10％或20％随机选择的特征的（二进制）值，然后在产生的噪声数据集上训练阴影模型，来模拟此情况。 模型数据泄露的结论①模型的类越多，任务越多，泄露的信息就越多。 ②每个类的训练数据量与成员推断准确性之间的关系：这种关系更加复杂，通常，训练数据集中与给定类别关联的数据越多，该类别的攻击精度越低。 ③较早的训练时期包含数据集的一般特征的信息，不会泄漏重要的隶属信息，但是，随着模型开始学习此类时期中的离群值，较晚的时期包含更多的隶属信息，因此使用训练了一段时间后的模型攻击效率更高。 ④与层输出相比，梯度泄漏的训练集成员信息更多。","link":"/2022/12/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%88%90%E5%91%98%E6%8E%A8%E6%96%AD%E6%94%BB%E5%87%BB/"},{"title":"编程注意事项","text":"本篇文章讲解了python中的一些编程注意事项，主要涉及到python的一些基本语法和机器学习有关知识的实现，还在更新中。 1.x为torch.tensor，M为模型，M(x)为模型输出，假设模型输出标签为m： y1=M(x).argmax(-1)，则y1=tensor([m])，y1.shape=torch.size([1]); y2=torch.argmax(M(x), -1)，则y2=tensor([m])，y2.shape=torch.size([1]); y3=torch.argmax(M(x))，则y3=tensor(m)，y3.shape=torch.size([])。 2.各个数据类型的相互转化： torch.tensor转numpy：a.numpy() numpy转torch.tensor：torch.from_numpy (a) numpy转tf.tensor：tf.convert_to_tensor(a) tf.tensor转numpy：a.eval() 3.模型和学习率的保存： ①先建立一个字典，保存四个参数：（有scheduler动态变化才需要保存scheduler） state = {‘net’:model.state_dict(), ‘optimizer’:optimizer.state_dict(), ‘epoch’:epoch, ‘scheduler’:scheduler.state_dict()} ②调用torch.save(): torch.save(state, dir) 其中dir表示保存文件的绝对路径+保存文件名，如’/home/qinying/Desktop/modelpara.pth’ ③当你想恢复某一阶段的训练（或者进行测试）时，那么就可以读取之前保存的网络模型参数等。 checkpoint = torch.load(dir) model.load_state_dict(checkpoint[‘net’]) optimizer.load_state_dict(checkpoint[‘optimizer’]) start_epoch = checkpoint[‘epoch’] + 1 scheduler.load_state_dict(checkpoint[‘scheduler’]) 4.随机数种子设置，保证每次运行结果相同： random.seed(args.seed) np.random.seed(args.seed) torch.manual_seed(args.seed)","link":"/2022/12/25/%E7%BC%96%E7%A8%8B%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"title":"联邦学习（三）","text":"本篇文章为联邦学习系列的第三篇。主要讲解机器学习中的一个新型方向——联邦学习（Federated Learning, FL）。联邦学习是一种新的机器学习框架，在满足隐私保护和数据安全的同时，使数据拥有方能够共同拥有和交换数据，搭建一个更加稳定、高效的系统。本文继续介绍纵向联邦学习（Vertical Federated Learning, VFL）的相关知识，继续讲解隐私保护问题，本文章以分析论文的方式进行介绍。 论文5：真实场景的VFL隐私泄露论文“Privacy Leakage of Real-World Vertical Federated Learning” CoRR 2021 针对真实场景（真实安全计算框架），提出了两种不同的攻击方式，评估了VFL的隐私泄露。 In this paper, we provide the first systematic study on the potential privacy risk of practical learning protocols in vertical federated learning. Specially, our work seeks to answer the crucial research question: How much is the privacy risks of the practical learning protocols for computing participates whose data is used as part of the training set? In other words, how much is the privacy leakage of the learning protocol about the participants’ training data? 提出的攻击方法：reverse multiplication attack（反向乘法攻击）and reverse sum attack（反向和攻击）。 场景：在论文3的基础上，加了一些真实的隐私保护措施和协议限制，大致还是相同，两个用户和一个中央服务器（也叫第三方协调器 third-party coordinator）。主要挑战：加密的中间输出和异质的训练数据。一方面，加密的中间输出使得参与者无法通过梯度更新直接推断私有数据，导致任何基于学习的攻击都不能工作。另一方面，由于参与者的训练数据是异质的，他们中没有人可以通过恶意查询推断其它用户的私有数据。 攻击者信息：其中的一个参与者被攻击者控制，攻击者可以发送或接收该参与者训练数据的静态结果（如梯度信息或梯度与数据的乘法结果…）对应的加密信息，通常攻击者可以恶意控制该用户的局部训练过程。攻击者不会破坏协议规则，但希望从协议中收集尽可能多的私人信息。如在reverse multiplication attack中，攻击者可以构造特定的字符串，并将它们插入到梯度的最低有效位，同时保持学习协议不变；在reverse sum attack，攻击方还可能破坏第三方服务器，以从协议中获取更多隐私。 攻击者的目标：尽可能多地推断参与者的私人训练数据集。在reverse multiplication attack中，攻击者旨在推断目标参与者的原始训练数据；在reverse sum attack中，攻击者试图推断目标参与者训练数据的部分顺序。 具体实现内容好复杂，涉及到编码、解密这些，这里不多阐述。 论文6：第一个VFL对成员信息保密的框架 论文“Vertical Federated Learning without Revealing Intersection Membership” CORR2021 提出了VFL中第一个对成员信息保密的框架。 场景：与[2]中场景相同，但多强调了一点：VFL各个用户在开始训练本地模型之前，需要先进行样本ID的对齐，也就是确定各方共享的相同实体(定义为交集)。通常，这是通过私有集交集(PSI)协议实现的。然而，这个过程中会产生成员隐私的泄露，具体的，各参与方都能够看到相互重叠的数据ID。因此，这篇文章提出了PSU协议，并基于这一协议提出了新的VFL框架，来在保持模型肖泳的同时保护交集成员的隐私。这里主要拓展视野并了解威胁模型。 威胁模型：假设用户一个为active party Pa，数据集Da=(Ia, Xa, ya)一个为passive party Pp，数据集Dp=(Ip, Xp)，攻击者为其中之一，且honest-but-curious，攻击者的目标是找到交集ID。分为两种情况：①Pa为攻击者，Pa通过yid和Pp传递的特征值z进行攻击，找到id∈Ia∩Ip；②Pp为攻击者，Pp通过xid和Pa回传的梯度值g进行攻击，找到id∈Ia∩Ip。 原文参考：We assume malicious parties are honest-but-curious, i.e. Pa and Pp faithfully run the VFL protocol, but they may infer important information including raw sample data and intersection membership from the exchanged information. In particular, we consider two privacy leakage scenarios: 1) for id∈Ia, Pa finds out if id∈Ia∩Ip by checking yid and the embedding forwarded by Pp, and 2) for id∈Ip, Pp finds out if id∈Ia∩Ip by checking xid and the gradient sent back by Pa. 论文7：第一个VFL的数据恢复工作 论文“CAFE: Catastrophic data leakage in vertical federated learning” NeurPIS 2021 提出了一种VFL下的数据泄露攻击，能够有效的从共享梯度中恢复批数据，可用于大批量数据。(参与标准FL的私人数据，特别是VFL情况下，有很高的风险从训练梯度中泄露) 场景：作用于通用VFL场景，与论文3相同，一个active party(server)和多个passive party，server拥有标签信息，可以选定每一轮更新哪些id的数据。攻击者为server，通过全局模型的梯度泄露，控制id，恢复出每轮训练的数据。 攻击者信息：1) 全局模型的梯度信息(分为很多梯度信息，包括每一个批次损失函数的梯度、每一层损失函数的梯度、总损失函数的梯度，这个是server本身就能得到的)，2) 批次身份，即每轮全局训练指定每位用户参与训练的一个批次的数据量。(public shared gradients and batch identities)。注：θ 为全局模型的参数，θ­1 为全局模型第一个FC Layer的参数，b1 为第一个FC Layer的bias，D 为目标batch的全部训练数据。 攻击者的目标：分为三个步骤：1) 恢复第一个FC Layer输出的损失和梯度信息(借助)；2) 恢复第一个FC Layer的输入数据；3) 获取所有输入数据。具体如下图所示。左边为VFL的框架，右边为CAFE的框架。 CAFE的具体实现功能这里不再阐述，有很多复杂的推导。 CAFÉ的related works：即一些有关联邦学习中从客户端上传的梯度信息中恢复出原始数据的方法，大致思想都是优化目标函数，通过修改目标函数和优化思想，作用于不同的场景下。这种方法需要大量理论的分析。每种方法的优缺点和比较CAFÉ文章中都有。 CAFÉ的后续工作：没有直接follow CAFE的文章，但有一些其它数据恢复的文章。VFL下的数据恢复，就CAFÉ一篇。 再读CAFÉ，看看改进点：1. 采用更新的优化方式，实现更好的性能（不会）；2. 限制条件，不用梯度。去做属性推断攻击。（但又能用什么呢？z、x、y、θ和用梯度也没什么区别好像）；3. 更强的场景，攻击者为被动方（即参与VFL的任意一个用户），去恢复数据，这样条件就只有zp、xp、θp了。","link":"/2023/01/06/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%B8%89/"},{"title":"联邦学习（一）","text":"本篇文章为联邦学习系列的第一篇。主要讲解机器学习中的一个新型方向——联邦学习（Federated Learning, FL）。联邦学习是一种新的机器学习框架，在满足隐私保护和数据安全的同时，使数据拥有方能够共同拥有和交换数据，搭建一个更加稳定、高效的系统。本文主要对联邦学习进行一个概述，同时进行横向联邦学习的讲解。 联邦学习概述随着互联网的发展，人工智能（Artificial Intelligence, AI）得到了越来越广泛的应用，为人们的生活提供了很大的便利。但是，数据分布与隐私保护的问题也随之而来，一些大型的AI项目需要融合各个公司的数据，但在现实中想要将分散在各地、各个机构的数据进行整合几乎是不可能的。同时，随着通用数据保护条例（General Data Protection Regulation，GDPR）的出台，数据之间的交流越来越困难，用户的隐私保护和安全管理更加严格。 要解决上述数据交流的困境，传统的机器学习算法已经很难满足要求，在目前的法规和GDPR下，各个公司在用户没有批准的情况下无法直接进行数据交流。因此，需要设计一个新的机器学习框架，在满足隐私保护和数据安全的同时，使数据拥有方能够共同拥有和交换数据，搭建一个更加稳定、高效的系统，这就是联邦学习。 联邦学习最近已成为传统机器学习的一种替代方法，它允许两个或更多参与者（每个人都有自己的训练数据集）构建联合模型。各参与者使用自己的数据，在本地训练自己的模型，服务器进行参数的汇总并更新联合模型。联邦学习的各个步骤均为加密操作，在模型的构建过程中，各个用户的数据均在本地保留，没有进行数据共享，一定程度上保证了机器学习过程中的安全问题。因此，联邦学习系统有望在有效的保护数据隐私的同时扩大机器学习的规模。 联邦学习框架联邦机器学习（Federated machine learning），又名联邦学习，是一个机器学习框架，能在有效帮助多个机构在满足用户隐私保护、数据安全的前提下，进行数据使用和机器学习建模。联邦学习系统构架如下图所示。 上图主要介绍了两个数据持有方的情况。联邦学习系统主要由两部分组成，数据持有方（用户）和第三方协作者（服务器），用户分别在各自本地训练模型，且用户之间的数据不共享；服务器用来进行加密模型训练，保护用户数据隐私的同时进行模型参数汇总。训练过程可分为以下几个步骤： （1）协作者对训练过程中需要使用的数据信息进行加密，并将公钥传递给参与联邦学习的用户； （2）各用户接受公钥，并交互用于训练本地模型的中间参数信息，开始准备本地模型的训练； （3）各用户在本地各自计算梯度值和损失，进行加密模型训练，并把结果和参数传递给服务器。服务器进行参数的汇总，更新全局模型，得到全局参数信息（总梯度值）； （4）服务器将梯度加密回传给各个用户，用户继续在本地各自模型的参数。 重复上述过程，根据具体情况设置合适的损失函数和优化方式，当损失函数收敛时结束整个训练过程。在模型训练过程中，用户各自的数据仍然保留在本地，没有进行数据共享，数据的交互和模型的训练均为加密操作，不会造成隐私泄露。借助联邦学习系统，各用户合作实现了整个全局模型的训练，达到隐私保护的效果。 横向联邦学习的实现本地模型训练在联邦学习中，各个用户需要在本地进行模型的训练，本地模型的训练与大部分机器学习模型类似，即为由一组参数θ进行参数化的函数 f(θ): X-&gt;Y，其中X表示输入（或特征）空间，Y表示输出空间。 本文专注于用于分类任务的监督学习。其训练数据是一组标记有其正确类别的数据点，测试数据则没有类别标签，使用将输入图像或文本作为输入并输出类标签的模型。为了找到适合训练数据的最佳参数集，训练算法优化了目标（损失）函数，当模型在数据点上输出错误的标签时，该函数会对模型进行惩罚。我们使用 表示在给定模型参数的情况下在数据点 上计算出的损失，而 表示在批次b的数据点上计算出的平均损失。 有许多方法可以优化目标函数，如随机梯度下降（Stochastic Gradient Descent, SGD），Adam优化、Adagrad优化等，SGD优化在目前的机器学习和神经网络中的使用最为普遍，SGD是一种迭代方法，其中，优化器在每个步骤中都会接收一小批训练数据，并根据模型的方向更新模型参数。目标函数相对于学习速率的负梯度并由其缩放。当模型收敛到局部最小值（梯度接近零）时训练结束，使用保留的数据测试训练后的模型，该数据在训练期间未使用。标准度量标准是测试准确性，即正确分类的保留的数据点的百分比，常用的优化器还有Adam优化器等。对于梯度下降算法，当要找到损失函数的最小值时，任取一个初始点，找到给定点的梯度，朝着梯度相反的方向，就能让函数值下降的最快，因为梯度的方向就是函数之变化最快的方向。因此，通过梯度下降算法，反复求取梯度，就能到达局部的最小值。 全局模型更新各用户进行了本地模型训练后，将模型参数传递给服务器，由服务器进行全局模型更新。全局模型更新的方法有很多种，如同步梯度更新、模型平均等。 对于同步梯度更新的协作学习，在每次迭代中，每个参与者都从中央服务器得到全局模型，并根据他的一批训练数据进行更新，将更新发送到服务器。服务器等待所有参与者的梯度更新，然后使用随机梯度下降汇总的更新应用于全局模型。 对于模型平均的联合学习，在每个回合中，第k个参与者使用其整个大小为nk的训练数据集（即全局可见的更新不是基于批次，而是基于参与者的整个数据集），在当前模型上本地执行SGD步骤。每个参与者将结果模型提交给服务器，该服务器计算加权平均值。服务器在保留的数据集上评估生成的各个模型，并在性能停止改善时停止训练。 两种全局模型更新方法的收敛速度在很大程度上取决于学习任务和超参数（如参与者的数量和数据批次的大小），同时，二者都能达到较高的效率，其中同步梯度更新的协作学习只能共享用户的小部分梯度信息，故基于模型平均的联合学习更为常见。","link":"/2023/01/06/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%B8%80/"},{"title":"联邦学习（二）","text":"本篇文章为联邦学习系列的第二篇。主要讲解机器学习中的一个新型方向——联邦学习（Federated Learning, FL）。联邦学习是一种新的机器学习框架，在满足隐私保护和数据安全的同时，使数据拥有方能够共同拥有和交换数据，搭建一个更加稳定、高效的系统。本文主要介绍纵向联邦学习（Vertical Federated Learning, VFL）以及一部分纵向联邦学习的隐私保护问题，本文章以分析论文的方式进行介绍。 论文1：VFL综述论文**“Vertical Federated Learning: Challenges, Methodologies and Experiments” ** IEEE Network 2022: VFL的具体步骤： Step1: 私有集交集(Private set intersection)。在模型训练之前，框架需要找到所有参与者(即来宾组织和宿主组织)服务的公共标识符(id)来对齐训练数据样本，称为私有集交集(private set intersection, PSI)或安全实体对齐。PSI是一个安全的多方协议，它允许多个参与者在他们的数据中找出可用的公共id。广泛采用的PSI技术包括哈希、多项式求值和转移. Step2: 底层模型正向传播(Bottom model forward propagation)。在确定了所有参与者的对齐样本之后，每一个参与者将使用基于其底层(本地)模型的本地数据完成一个向前传播过程。这种正向传播过程除了没有计算损失值外，与传统训练类似。 Step3: 正向输出传输(Forward output transmission.)。每个参与者将其底层模型的输出传输到标签所有者。直观地说，正向输出包含局部神经网络的中间结果，能够将原始属性转换为特征。这样的传输过程可能会泄露参与者的隐私信息。因此，应该利用先进的隐私保护方法，如差分隐私(DP)，以解决潜在的隐私风险，但可能会产生额外的通信成本和计算复杂性。 Step4: 顶部模型正向传播(Top model forward propagation)。标签所有者根据收集到的所有参与者的输出，根据顶层模型和标签计算损失函数值。 Step5: 顶部模型反向传播(Top model backward propagation)。标签所有者进行反向传播，计算两个梯度: 1)顶层模型的模型参数; 2)转发每个参与者的输出。使用顶级模型的梯度，标签所有者可以计算每批样品的平均梯度，并更新其模型。 Step6: 反向输出传输(Backward output transmission)。正向输出的梯度被发送回每个来宾参与者。可以注意到，所需的通信成本(传输比特)通常比Step2中的要小得多，因为它们是梯度而不是中间输出。 Step7: 底部模型向后传播(Bottom model backward propagation)。每个参与者根据本地数据和来自标签所有者的正向输出的梯度计算其底部模型参数的梯度，然后更新其底部模型。 VFL的安全隐私问题：现有VFL模型的隐私和安全风险研究不足。在VFL中，参与者需要获得一致的样本空间，来自其他参与者的成员推断攻击可能是多余的。在VFL中，对抗参与者只控制联邦模型的一部分，该联邦模型不能独立运行，并且只能访问自己的底层模型的梯度。然而，通过分析交换的消息，即中间输出和梯度，参与者可以从其他参与者推断客户端的属性，如标签推断攻击和私有数据泄漏。 ​ 保护每个参与者所拥有的标签的隐私应该是VFL的基本要求，因为标签可能是高度敏感的，例如，一个人是否患有某种类型的疾病。在某些特殊情况下，来自宿主组织的梯度也可以直接泄漏标签信息。此外，还证明了从共享梯度恢复批处理数据是可用的。我们还可以注意到攻击方法在不同的数据类型中是不同的。例如，表格数据在学习之前通常需要进行嵌入，从嵌入的属性中获取私有信息很困难。然而，对手能否利用VFL中交换的消息恢复原始属性值仍是一个有待研究的问题。 可能的防御措施： 安全框架：Differential privacy(DP)、Secure multi-party computing(SMC)、Homomorphic encryption(HE) 论文2：VFL的隐私保护——标签推断攻击（Label Inference Attack）论文 “Label Inference Attacks Against Vertical Federated Learning” Security 2022 第一个VFL下的标签推断攻击。 场景：在VFL中，有n≥2个用户参与训练，且有一个用户拥有数据的真实标签，一个用户为攻击者。每个用户都有各自数据的部分特征（可以理解为，样本集相同但特征集不同），用户都有自己的bottom model。共采用了两种不同场景：①VFL without model splitting：中央服务器不进行模型的训练，而是简单的将各个用户的输出结果进行汇总，并得到最终的输出；②VFL with model splitting：中央服务器有特定的模型top model（也就是我们说的全局模型），同时也拥有标签信息，服务器进行模型的训练，并聚合各个用户的特征输出，并回传梯度信息。其实我们通常将第二种情况看作，中央服务器的训练就在带标签的用户上进行，或者说就是指该用户，因为该用户控制着中央服务器。 攻击者为不具有标签数据的某一用户，被攻击者为具有标签的用户，攻击者试图获取标签信息。 攻击者信息：①由于攻击者为参与者，攻击者拥有自己的数据信息（只有x没有y）和本地模型，还有模型每轮训练后中央模型传递的梯度信息。②部分少量辅助数据信息i.e. a few dozens of auxiliary labeled samples，在实际情况中，这部分数据是可以获取的。③攻击者感兴趣的样本x，用于最后推断x的标签，x可以是任何能够得到的样本，不仅仅是原始拥有的训练数据。 攻击者目标：推断出给定数据的标签值（包括训练数据和感兴趣的数据）。摘自原文： Note that the adversary’s goal is to infer the labels of any interested samples, not just the ones in the training dataset. 于是这篇文章根据不同情况，设计了三种不同的标签推断方法。 \\1) 被动微调训练好的底层模型作为攻击模型，输入待测样本实现推断； \\2) 主动参与训练，提出一种恶意优化方案，得到攻击模型，输入待测样本实现推断； \\3) 进行直接标签推断，通过理论推导，全局训练的每一轮中，攻击者通过收到的梯度符号来直接判断标签是否正确，实现推断。可实现100%成功率。 论文3：VFL的隐私保护——属性推断攻击（Feature Inference Attack）论文 “Feature Inference Attack on Model Predictions in Vertical Federated Learning” ICDE 2021 第一个VFL下的属性推断攻击。 场景：VFL，用户个数n≥2，其中一个为active party，拥有真实标签，其余的为passive party，联邦学习的全局模型训练在active party上完成，并将参数回传给各个用户，与label inference②相同。 攻击者为active party，被攻击者为target passive party（没有标签的用户中的一个用户），攻击者甚至可以拉拢其它所有passive party对target passive party进行属性推断。 攻击者信息：①攻击者拥有自己的数据信息，即特征值xadv，②由于攻击者为主动方，故还拥有标签信息y、VFL各用户的模型参数θ = (θadv, θtar)、全局模型的输出v，③关于其它用户的粗略信息（如数据分布，数据类型，属性名称等），这个也是正常的，因为主动方会经常需要这些信息来证明训练模型的有效性，④攻击者不知道其它用户的具体数据值。 攻击者目标：推断目标用户的属性值。摘自原文： The adversary Padv is given the VFL model parameters θ, the prediction output v, and the feature values xadv that belongs to himself. Padv’s goal is to infer the feature values of Ptarget, i.e., ​ xtarget = A(xadv; v; θ) (1) 于是这篇文章设计了攻击模型A，在只知道上述信息的情况下，实现了VFL的属性推断。 简单学习一下实现过程：提出了三种攻击方式，分别作用于两种常用模型和通用模型解法 1) Equality Solving Attack 针对逻辑回归模型LR 攻击方通过收集VFL预测结果和Active party和Passive Party的半边模型参数聚合更新结果和feature推断估计Passive party的feature信息。推导了相应的公式，见论文Equ.(7)(8)。 2) Path Restriction Attack 针对决策树模型DT 攻击方可以根据自己的部分特征信息(蓝色方框) 限制树模型中可能的路径(灰色-蓝色箭头)，结合预测类别结果1进一步限制决策路径(蓝色-红色箭头)，可以推测目标方的属性(绿色方框)，见论文图Fig.2。 3) GRN(generative regression network) Attack 针对通用模型，包括复杂模型NN、RF等 攻击方在进行VFL模型训练时进行对GRN的训练，在前向传播阶段，单独训练VFL模型，进行loss反向传播阶段，更新VFL model参数时共同训练生成模型GRN。对于GRN模型，攻击者收集目标方的属性信息生成伪造的目标样本，具体的，攻击者根据自己的已有特征集和部分随机变量，估计出目标用户的未知特征集。 论文4：论文3的升级版论文**“Comprehensive Analysis of Privacy Leakage in Vertical Federated Learning During Prediction“ **Proceedings on Privacy Enhancing Technologies 2022 对论文3进行了更严格的要求，并提升了性能。 场景：与论文3相同，攻击者信息有较大差别。这里主要学习了解论文说的黑盒和白盒情况。 VFL的框架如下图所示，通常情况下，各个本地的模型采用LR模型，模型参数为θact和θpas，z为输出特征向量，全局模型输出为 c = ξ (z) = ξ (f (xact, θact) + f (xpas, θpas))，最后 c 会返回到active party中。 攻击者信息：论文3中为白盒情况：由于攻击者为active party，攻击者能够拥有全部模型的模型参数，包括 θact和θpas，因此公式(1)可以写作： ​ xpas = Awb (xadv; v; θact; θpas) (2) 论文4设计了黑盒情况：攻击者不知道其余用户本地模型的参数信息，但拥有少量其余用户的输入数据(即辅助数据auxiliary data)，因此公式(1)改为： ​ xpas = Abb (xadv; v; θact; xaux; vaux) (3)","link":"/2023/01/06/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%BA%8C/"},{"title":"论文常用句式","text":"本篇文章讲解了英文论文写作的常用句式，包括常用词语，常用句式和常用细节等，主要涉及到机器学习和隐私保护方向论文的写作。 常用词语1. exploit：运用、利用 Our EncoderMI exploits the overfitting of the image encoder towards its training data. 2. overfitting：过拟合 n. the overfitting of … adj. an overfitted image … 3. pre-training of model：模型预训练 v. uses the public data to pre-train the model. 4. private/sensitive：隐私的/敏感的 to determine if the data is private/sensitive. 5. confidence score vector：置信向量 posteriority：后验 feature vector：特征向量 construct a vector 6. scenario：情况、条件 ~ case We assume an inferrer has a black-box access to a pre-trained image encoder, which is the most difficult and general scenario. 7. module：模块、部分 ~ part An important module in contrastive learning is data augmentation. 8. state-of-the-art：最先进的 we generalize early stopping, which is a state-of-the-art overfitting-preventionbased countermeasure against membership inference to classifiers. 9. binary classifier：二分类器 multiple classifier：多分类器 10. extract：提取、获取 extract membership features and construct an inference training dataset. 11. ground truth：真实情况、理想情况、标准答案 for each target encoder, we have 10,000 ground truth members and 10,000 ground truth non-members. 12. model architecture：模型结构 We adopt the same architecture (i.e., ResNet18) for a shadow encoder. 13. otherwise****：否则，表示对立面 ~ while We adopt ResNet18 for a shadow encoder if the inferrer knows the architecture of the target encoder and use VGG-11 with batch normalization otherwise. 14. metrics：评价指标 We set accuracy, precision, and recall as our evaluation metrics. 15. ratio：比率 The accuracy of a method is the ratio of the ground truth members/non-members correctly predicted by the method. 16. cosine similarity：余弦相似度 All contrastive learning algorithms use cosine similarity to measure similarity between two feature vectors. 17. curves：曲线 The curves are obtained via tuning the classification thresholds in the three inference classifiers to produce different precisions and recalls. 常用句式1. 成员推断攻击定义： 1）given an input and a black-box access to an image encoder, EncoderMI aims to infer whether the input is in the training dataset. 2. 我们的方法有着很好的效果： 1）Our results show that EncoderMI can achieve high accuracy, precision, and recall. 2） 3. 之前的研究主要集中于做…： 1）Existing studies on contrastive learning mainly focus on how to train a better image encoder such that it can achieve better performance on the downstream tasks. 2）Existing membership inference methods are mainly designed for classifiers. For example, … 3）Existing membership inference methods are insufficient. 4. …的应用是…： 1）Membership inference in contrastive learning has two important applications. The first application of membership inference is that a data owner can use a membership inference method to audit whether his/her (public) data was used to pre-train image encoders. 2）The first step of our EncoderMI is to train a shadow encoder whose ground truth members/nonmembers are known to the inferrer. 5. 有着相同的数据集分布： 1）the shadow dataset has the same (a different) distribution from the pre-training dataset. 6. 我们将在后面的一节进行讨论： 1）we will discuss in Section 4； 7. 我们用 … 来表示 … ： 1）We use a triplet B = (P, E, T) to denote the three dimensions of the inferrer’s background knowledge. 我们用一个三维元组来表示推断者拥有的背景知识 8. 数据集分割： 1）We randomly split a shadow dataset into two disjoint sets, i.e., shadow member dataset and shadow non-member dataset, each of which contains 10,000 images. [each of which：其中的每一个] 9. 网络的描述： 1）We use a fully connected neural network with two hidden layers as our vector-based classifier. 2）We adopt the following default parameters for our method. 10. baseline 对比句式： 1）We compare our methods with the following five baseline methods … In this baseline method, we … 11. 表格内容描述： 1）Table 2, 5 (in Appendix), and 6 (in Appendix) show the accuracy, precision, and recall of our methods under the 8 different types of background knowledge for CIFAR10, STL-10, and Tiny-ImageNet datasets, 12. 图像内容描述 1）Figure 1b shows the impact of the number of augmented inputs 𝑛 on the accuracy of our methods for CIFAR10. 13. 曲线趋势描述： 1）Our results show that precision drops slightly as recall increases up to around 0.9, and then drops sharply as recall further increases. 14. 具体指标粗略描述 1）EncoderMI-V achieves higher accuracy as the inferrer has access to more background knowledge, and we have the same observation for EncoderMI-S and EncoderMI-T in most cases. 15. 具体指标细致描述 1）For instance, EncoderMI-V achieves 96.5% accuracy when the inferrer knows all the three dimensions of background knowledge while achieving 88.7% accuracy when the inferrer does not know any of them for Tiny-ImageNet dataset. 常用细节1. 在这项工作中：in this work；in our work；in our method 2. 常用动词（we为主语）： [判断]：decide；determine；judge；infer；consider；predict； **[证明]**：confirm； **[发现]**：find；perform；observe；note； **[提出]**：propose； **[展示]**：show； **[假设]**：assume； **[生成、得到]**：get；create **[进行、实施]**：do；conduct；process；implement **[作用、应用]**：apply；operate **[看待]**：treat；think；suspect(猜想) **[构建、构造]**：construct、build **[选择、选取]**：select、choose **[设置、设计]**：set、design **[对比、比较]**：compare、contrast **[表示、代表]**：denote、represent （attacker为主语）： **[查询、访问]**：query **[了解]**：know **[欺骗]**：cheat；deceive 3. 常用形容词： **[有效的]**：effective；efficient；valid **[足够的]**：sufficient；enough **[脆弱的]**：vulnerable 4. 常用连接词： **[粗略的说]**：roughly speaking；for simplicity **[通常来说]**：generally speaking **[特别地]**：in particular；particularly；specially **[例如]**：for example；for instance **[此外]**：moreover；in addition；besides **[因此]**：as a result；therefore **[默认情况下]**：by default 5. 测试常用词： close to：接近；around：接近；increases up：上升；drop：下降 the reason is that：理由是 be viewed as：被看作 to some extent：在一定程度下 respectively.：分别地 6. 一些简写 i.e. ：也就是、即； e.g. ：例如；s.t. ：使得","link":"/2022/12/23/%E8%AE%BA%E6%96%87%E5%B8%B8%E7%94%A8%E5%8F%A5%E5%BC%8F/"},{"title":"论文阅读笔记(Surfree)","text":"本篇文章为《Surfree: a fast surrogate-free black-box attack》(CVPR 2021) 阅读笔记。 该论文提出了一种新的对抗样本生成方法。与梯度无关，也不需要估计梯度，全靠理论推导，利用了决策边界的几何属性，在更少的查询量的条件下得到较好的对抗样本。 Surfree: a fast surrogate-free black-box attack (CVPR 2021) 该论文提出了一种新的对抗样本生成方法。与梯度无关，也不需要估计梯度，全靠理论推导，利用了决策边界的几何属性，在更少的查询量的条件下得到较好的对抗样本。 基本流程：首先构建超平面，通过旋转角度搜索更近的对抗样本，再通过二分法细化角度。如果第二步找不到更近的对抗样本，则重新采样方向构建另一个超平面去寻找。（见算法1） ①初始化：该算法需要一个初始化的点，通过目标攻击或非目标攻击生成对抗样本点。方法与我们的类似：nontarget：加噪，target：取对应数据集中的点，再二分法。 ②搜索新方向：第k次迭代中，原始样本和当前对抗样本连线向量u­k，使用DCT基产生一个伪随机向量tk，将tk与和uk前k-1次产生的方向做施密特正交化，正交后的方向向量为vk，即本次产生的新方向。（见算法2） ③搜索：在当前方向v**k和u­k所构成的平面内，由当前给定的最大角度θmax，乘以系数，来试探点Z*(θmax*T)是否为对抗样本（点Z*(θ)就是指与向量的角度为θ的处于该圆弧上的点，具体含义和内容见本论文，参考图2），一旦发现对抗样本图片搜索立即停止。否则缩小θmax重新生成一个vk进行上述搜索。（由于决策边界的法向量未知，则需要从大幅震荡使用+和-进行交替测试，碰到对抗性的样本就停止）；也可以0、θ*/2、θ*为节点，采用插值的方法估计最优θ；（参考图3） ④二分法搜索：找到角度θ以及符号后，用二分法搜索θ再细化t步，最后增大θmax。","link":"/2022/12/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-surfree/"},{"title":"论文阅读笔记(Dataset Inference)","text":"本篇文章为《DATASET INFERENCE: OWNERSHIP RESOLUTION IN MACHINE LEARNING 》(ICLR 2021) 阅读笔记。该论文提出了数据集推断的思想，通过训练数据集与测试数据集到决策边界距离的差异性，获取特征值，实现数据集推断。 《DATASET INFERENCE: OWNERSHIP RESOLUTION IN MACHINE LEARNING 》(ICLR 2021) 该论文提供了一种能与我们方法完全匹配的场景。需要通过计算点到决策边界的距离，进而进行特征值获取，实现数据集推断。因此需要生成离原始样本最近的对抗样本。而且此文章采用的黑盒方法过于简单，我们可以进行优化。 该文章主要思想：提出了数据集推断，用来进行模型的窃取攻击的防御，具体地，判断某一可疑模型是否使用了目标模型的部分隐私数据，来进行模型训练。 该文章具体步骤：（其中Embedding特征值的计算就是点到决策边界的距离计算） 1.将受害者的私有数据集和公有数据集进行标记：Sv-&gt;b=0; S-&gt;b=1 2.任取部分受害者的私有数据和公有数据，进行fv下Embedding特征值的计算。并将特征值作为输入x，对应的成员标签(b)作为y，训练回归模型gv(类似于成员推断攻击的二分类模型，只不过加了一个评分，同时修改了损失函数使得成员数据对应的评分小)。该回归模型gv的作用：给定一个样本在可疑模型 F 计算的特征值，模型输出一个概率(认为该条数据包含fv隐私信息的置信度) \\3. 进行假设检验HypothesisTesting。取m条受害者的私有数据和公有数据，计算可疑模型fA*下的Embedding特征值，并传入gv计算置信度，将m个数据的置信度构成向量c=(c0…cm)和cv。检验无效假设H0:μ&lt;μv，计算p值，通过设定阈值α，若p＜α，则H0被拒绝，模型被盗。 一些笔记： 一、模型窃取攻击的主要类型： 1.模型提取。对手利用对模型： (1.a)预测向量的访问(如API)，来重现模型的副本； (1.b)使用受害者模型作为标记预言，从初始未标记数据集上训练他们的模型。 2.访问用于训练受害者模型的数据集本身。并通过： (2.a)提取受害者模型； (2.b)从头训练来训练自己的模型。 3.对受害者模型的完全访问权，但不能访问数据集。 (3.a)对受害者模型进行微调， (3.b)采用受害者模型进行无数据蒸馏。","link":"/2022/12/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-dataset-inference/"},{"title":"论文阅读笔记(数据所有权系列)","text":"本篇文章为数据所有权相关的论文笔记。包括数据集的IP认证(Dataset Inference)，DL模型的IP认证(IPGuard)和DL模型的知识蒸馏(Knowledge Distillation)。我们系统的介绍了这三种方法，同时在理论基础、实现方法、实验环境、实验内容和实验结果等方面进行了对比。 Dataset Inference主要思想：提出了数据集推断，用来进行模型窃取攻击的防御，具体地，判断某一可疑模型是否使用了目标模型的部分隐私数据，来进行模型的训练。 具体步骤：（其中Embedding特征值的计算就是点到决策边界的距离计算） 1.将受害者的私有数据集和公有数据集进行标记：Sv-&gt;b=0; S-&gt;b=1 2.任取部分受害者的私有数据和公有数据，进行fv下Embedding特征值的计算。并将特征值作为输入x，对应的成员标签(b)作为y，训练回归模型gv(类似于成员推断攻击的二分类模型，只不过加了一个评分，同时修改了损失函数使得成员数据对应的评分小)。该回归模型gv的作用：给定一个样本在可疑模型 F 计算的特征值，模型输出一个概率(认为该条数据包含fv隐私信息的置信度) （Embedding特征值的计算：提出了白盒和黑盒两种，但不够精细化） 3.进行假设检验HypothesisTesting。取m条受害者的私有数据和公有数据，计算可疑模型fA*下的Embedding特征值，并传入gv计算置信度，将m个数据的置信度构成向量c=(c0…cm)和cv。检验无效假设H0:μ&lt;μv，计算p值，通过设定阈值α，若p＜α，则H0被拒绝，模型被盗。 实验环境： Datasets - Target Models CIFAR10 – WRD-28-10 CIFAR100 – WRD-28-10 攻击方式： ①模型提取，预测向量的访问；(Model exaction using unlabeled data and victim confidence) ②模型提取，仅使用标签；(Model exaction using unlabeled data and victim labels) ③访问数据集，提取受害者模型；(Data distillation) ④访问数据集，重新训练自己的模型；(Different model) ⑤对受害者模型进行微调；(Fine tuning) ⑥对受害者模型进行无数据蒸馏；(Data-free distillation/Zero shot learning) ⑦独立模型（对比实验）。(Train a teacher model on a separate dataset) 生成对抗样本的方式： ①White ②Black 评价指标： ①Δμ = μ – μv：置信度均值之差 ②p-value：无效假设H发生概率； 实验内容：（1 2为正文, 3 4 5为附录） 1.数据集推断整体性能评估：固定m，计算每种攻击下的Δμ和p-value值。 （攻击①-⑦; CIFAR10/CIFAR100; Black/White; m=10） 2.检验所需样本个数m对数据集推断的影响：改变m，计算p-value的变化。 （攻击①-⑥; CIFAR10/CIFAR100; Black/White; m=0-50） 3.生成距离特征size大小（也就是计算该点到几条决策边界的距离）对数据集推断的影响：改变Embedding Size，计算p-value的变化。（攻击①-⑥; CIFAR10/CIFAR100; Black; m=15/30/45/60/75/90） 4.补充了另外两个数据集（SVHN/Imagenet）的实验整体性能表：固定m，计算每种攻击下的Δμ和p-value值。（SVHN:攻击①-⑦; Imagenet:攻击③-④; Black; m=10） 5.双方私有数据集重叠对性能影响（作为一种新的攻击方式）：改变fraction overlap，计算p-value的变化。（SVHN; Black; m=10; fraction overlap=0.0/0.3/0.5/0.7/1.0） 整体性能： (实验1) CIFAR10-WRD-28-10 CIFAR100 – WRD-28-10 (实验4) ImageNet IPGuard主要思想：提出了IPGuard，用来保护深度网络的知识产权。具体地，判断某一可疑模型是否是目标模型的后处理版本（盗版）。 具体步骤：（其中footprint的生成就需要使用对抗样本技术） 1.取n个点，随机/就近取一条决策边界作为target label，采用优化方式生成对抗样本，将这些对抗样本（nearest samples）和他们对应的标签（target label）作为footprint； （优化方法为： ，需要白盒条件且不够精细化） 2.生成多种可疑模型，包括阳性（盗版）和阴性（正常）模型，将模型对nearest samples进行预测，与target label进行比较，计算匹配率。 实验环境： Datasets - Target Models CIFAR10 – ResNet20 CIFAR100 – WRN-22-4 Imagenet – ResNet50 攻击方式： 1.阳性模型 ①微调最后一层全连接层；(Fine-tune last layer) ②微调所有层；(Fine-tune all layer) ③重新训练最后一层；(Retrain last layer) ④重新训练所有层；(Retrain all layer) ⑤权重修剪；(Weight pruning) ⑥过滤器修剪；(Filter pruning) 2.阴性模型 ⑦同结构模型；（同结构不同初始化） ⑧不同结构模型； ⑨随机森林模型。 生成对抗样本的方式： ①初始化样本：随机/选训练集数据 ②找target label：随机/取最近的 ③对抗攻击：Random/FGSM/IGSM/CW/IPGuard 评价指标： ①匹配率：得到模型预测输出后，可疑模型预测数据点与目标分类器预测数据点标签匹配的分数。（阳性模型的分数高，阴性模型的分数低） ②ARUC：鲁棒性与唯一性曲线围成的面积。其中：阳性模型的匹配率代表鲁棒性，阴性模型的匹配率代表唯一性。 ③测试准确率：模型的测试准确率。 实验内容：（只有正文） 1.各种模型的测试准确率；（目标模型+可疑模型） 2.整体性能情况：所有情况下最优参数对应的ARUC的值； （CIFAR10/CIFAR100/ImageNet; Random/FGSM/IGSM/CW/IPGuard） 3.整体性能情况：各种攻击方式和各种对抗样本生成方式下，匹配率的值； （攻击①-⑨; CIFAR10/CIFAR100/ImageNet; FGSM/IGSM/CW/IPGuard） 4.FGSM、IGSM、CW对抗攻击中超参数对ARUC的影响。我们应该讨论我们方法超参数的影响； 5.不同数据集下，不同对抗攻击方法需要的时间； （Random/CIFAR10/CIFAR100/ImageNet; FGSM/IGSM/CW/IPGuard; n=100） 整体性能： （实验三） CIFAR10-ResNet20 CIFAR100-WRN-22-4 （实验三） ImageNet-ResNet50 （实验二）实验三是计算的匹配率，实验二是ARUC Knowledge Distillation主要思想：利用对抗性攻击来发现支持决策边界的样本，从而实现知识蒸馏。具体的，提出了一种对抗攻击方法（类似deepfool），在决策边界处得到对抗样本（BSSs），使得知识蒸馏后的模型决策边界能够接近原本的模型分类边界。 具体步骤：（其中BSSs的生成就需要使用对抗样本技术） 1.挑选N个原始点（base sample）以及对应的对抗标签（target label）。1）样本选择方法：选出能够被teacher和student均预测为该类的样本，个数为C，若C小于N，则用这C个样本，若C大于N，则在C中选出teacher与student预测概率相差最大的N个样本；2）标签选择方法：选取距离该样本最近的决策边界。 2.进行对抗攻击生成BSSs。方法为：优化损失函数，并进行更新，类似Deepfool。 其中b为原始class，k为目标class。 3.设计模型蒸馏损失函数，进行模型蒸馏，优化student。其中J为entropy function：J(a; b) =- aTlogb。 实验环境： Datasets – Target Models(Teacher) – Student CIFAR10 – ResNet26 – ResNet8 ResNet14 ResNet20 ImageNet – ResNet32 – ResNet8 Tiny ImageNet – ResNet42 – ResNet10 攻击方式： 知识蒸馏Knowledge distillation。 蒸馏方式：Proposed和FSP + Proposed，还有一些对比实验（Original/Hinton）。 生成对抗样本的方式： 见具体步骤1. 对抗攻击：Baseline/Random/noise L2 minimize/FGSM/DeepFool/Proposed 评价指标： ①测试准确率：模型的测试准确率。 ②蒸馏后得到的student的决策边界与teacher决策边界的相似度：MagSim和AngSim。 实验内容：（只有正文） 1.整体性能情况：不同方法蒸馏后的student测试准确率对比； （CIFAR10/ImageNet/Tiny; Proposed/FSP + Proposed；BSSs） 2.对抗样本对知识蒸馏的影响； （CIFAR10; Baseline/Random/noise L2 minimize/FGSM/DeepFool/Proposed） 3.不同方法下的相似度情况； （CIFAR10; DSSs; Original/Hinton/Proposed） 4.超参数的影响（选取样本个数、选取方式等）； 整体性能：","link":"/2022/12/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E6%89%80%E6%9C%89%E6%9D%83/"},{"title":"java基础（八）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的高级特性——java反射机制。具体讲解java的反射概念和实现，以及反射的应用：动态代理设计模式。 java反射机制关于java.lang.Class的理解： 1.类的加载过程： 程序经过javac.exe命令（即编译）以后，会生成一个或多个字节码文件（.class结尾）； 接着我们用java.exe命令对某个字节码文件进行解释运行。相当于将某个字节码文件加载到内存中。此过程就称为类的加载。加载到内存中的类，我们就称为运行时类，此运行时类，就作为Class的一个实例； 2.换句话说，Class的实例就对应着一个运行时类； 3.加载到内存的运行时类，会缓存一定时间。在此时间之内，我们可以通过不同的方式来获取此运行时类。 获取Class实例的方式：123456789Class clazz1 = Person.class； //调用运行时类的属性：.classPerson p1 = new Person();Class clazz2 = p1.getClass(); //通过运行时类的对象，调用getClass()方法Class clazz3 = Class.forName(&quot;包名.Person&quot;); //调用Class的静态方法：forName(String classPath);ClassLoader classLoader = 文件名.class.getClassLoader();Class clazz4 = classLoader.loadClass(&quot;包名.Person&quot;); //使用类的加载器：ClassLoader，此方式了解即可 通过反射创建对应运行时类的对象：newInstance(): 调用此方法，创建对应的运行时类的对象。内部调用了运行时类的空参的构造器 要想此方法正常创建运行时类的对象，要求： 1.运行时类必须提供空参的构造器； 2.空参的构造器的访问权限得够。通常设置为public。 在javabean中要求提供一个public的空参构造器。原因： 1.便于通过反射，创建运行时类对象； 2.便于子类继承父类时，默认调用super()时，保证父类有此构造器。 12345678//例子：Class clazz = Person.class;Object obj = clazz.newInstance(); //obj即为Person类的对象//Person obj = (Person) clazz.newInstance(); //进行强转，结果一样//若添加泛型：Class&lt;Person&gt; clazz = Person.class;Person obj = clazz.newInstance(); //添加泛型后相当于得到的对象一定是Person类的 获取运行时类的属性、方法、构造器的结构：获取运行时类的属性结构： getFields()：获取当前运行时类及其所有父类中声明为public访问权限的属性； getDeclaredFields()：获取当前运行时类中声明的所有属性。（不包含父类中声明的属性）; 获取运行时类的方法结构： getMethods()：获取当前运行时类及其所有父类中声明为public访问权限的方法； getDeclaredMethods()：获取当前运行时类中声明的所有方法。（不包含父类中声明的方法）; 获取构造器结构： getConstructors()：获取当前运行时类中声明public的构造器； getDeclaredConstructors()：获取当前运行时类中声明的所有构造器； 调用运行时类的属性、方法、构造器：如何操作运行时类中的指定的属性： 1234567891011121314151617181920Class clazz = Person.class;//创建运行时类的对象Person p = (Person) clazz.newInstance(); //p即为Person类的对象//1. 获取指定的属性//getDeclaredFields(String fieldname)：获取指定的属性//Field id = clazz.getFields(&quot;id&quot;); //getFields(String name)：只能获取public的属性，不采用Field name = clazz.getDeclaredFields(&quot;name&quot;); //2. 保证当前属性可访问name.setAccessible(true); //操作非public属性时需要添加，保证当前属性可访问//3. 设置当前属性的值//set()：参数1：指明设置哪个对象的属性；参数2：将此属性值设置为多少name.set(p, &quot;Tom&quot;); //4. 获取当前属性的值//get()：参数：获取哪个对象的属性值。注：正常为Object类型，为基本数据类型时，打印需要强转System.out.println(name.get(p)); 如何操作运行时类中的指定的方法： 12345678910111213141516171819Class clazz = Person.class;//创建运行时类的对象Person p = (Person) clazz.newInstance(); //p即为Person类的对象//1. 获取指定的某个方法//getDeclaredMethod()，参数1：指明获取的方法名称；参数2：指明获取方法的形参列表，因为可能会有多个同名方法Method show = clazz.getDeclaredMethod(&quot;show&quot;, String.class);//2. 保证当前方法可访问show.setAccessible(true); //3. 给指定的某个方法赋值//invoke()，参数1：方法的调用者；参数2：给方法形参赋值的实参//invoke()方法的返回值即为对应类中调用方法的返回值，若没有返回值，则返回nullObject returnValue = show.invoke(p, &quot;CHN&quot;); //类似于之前的String nation = p.show(&quot;CHN&quot;)System.out.println(returnValue); //注：若为静态方法，则invoke的第一个参数为Person.class，也可以写成None，因为加载时就知道静态方法；静态属性同理 如何操作运行时类中的指定的构造器：（使用较少） 1234567891011121314Class clazz = Person.class;//1.获取指定的构造器//getDeclaredConstructor()：参数：指明构造器的参数列表Constructor constructor = clazz.getDeclaredConstructor(String.class);//2.保证此构造器是可访问的constructor.getAccessible(true);//3.调用此构造器创建运行时类的对象Person per = (Person) constructor.newInstance(&quot;Tom&quot;); //默认为ObjectSystem.out.println(per); //注：上述是调用有参构造器时使用，并进行类的实例化；若调用无参构造器，采用Person p = (Person) clazz.newInstance()即可。 反射的应用：动态代理– 特别重要 Spring的底层用的就是这个 代理设计模式的原理： 使用一个代理将对象包装起来，然后用该代理对象取代原始对象。任何对原始对象的调用都要通过代理。代理对象决定是否以及何时将方法调用转到原始对象上。 之前为大家讲解过代理机制的操作，属于静态代理，特征是代理类和目标对象的类都是在编译期间确定下来，不利于程序的扩展。同时，每一个代理类只能为一个接口服务，这样一来程序开发中必然产生过多的代理。最好可以通过一个代理类完成全部的代理功能； 动态代理是指客户通过代理类来调用其它对象的方法，并且是在程序运行时根据需要动态创建目标类的代理对象。动态代理使用场合：1.调试；2.远程方法调用； 动态代理相比于静态代理的优点：抽象角色中（接口）声明的所有方法都被转移到调用处理器一个集中的方法中处理，这样，我们可以更加灵活和统一的处理众多的方法。 动态代理举例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/**对于动态代理，对于代理模式，需要有接口、被代理类、代理类。代理类要改成动态**///定义接口 -- 即一种规范interface Human{ String getBelief; void eat(String food);}//被代理类 -- 实现该接口class SuperMan implements Human(){ @Override public String getBelief(){ return &quot;I believe I can fly!&quot;; } @Override public void eat(String food){ System.out.println(&quot;我喜欢吃&quot;+food); }}/*要想实现动态代理，要解决两个问题：问题一：如何根据加载到内存中的被代理类，动态的创建一个代理类及其对象；问题二：当通过代理类的对象调用方法时，如何动态的去调用被代理类中的同名方法。*///动态创建一个与被代理类实现接口一样的类，代理对被代理类的执行；//这个类不是具体的一个类，是会根据具体的对象变化的类；如果是具体的类，就变成了静态代理//生成一个代理工厂，用于动态的生成代理类class ProxyFactor{ //调用此方法，返回一个代理类的对象，解决问题一 public static Object getProxyInstance(Object obj){ //obj为被代理类的对象 //采用反射中的Proxy类，构建一个代理的实例 //要求体现在三个参数中：与被代理类加载器一致，与被代理类的实现接口一致，动态的调用方法 MyInvocationHandler handler = new MyInvocationHandler(); handler.bind(obj); //传入被代理类的对象 return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), handler); }}//实现动态性class MyInvocationHandler implements InvocationHandler{ private Object obj; //需要使用被代理类的对象进行赋值 //对obj对象进行赋值 public void bind(Object obj){ this.obj = obj; } //作用：当我们通过代理类的对象，调用方法a时，就会自动的调用如下的方法：invoke() //将被代理类要执行的方法a的功能就声明在invoke()中 @override public Object invoke(Object proxy, Method method, Object[] args){ //method：即为代理类对象调用的方法，此方法也就作为了被代理类对象要调用的方法 //obj：被代理类的对象 Object returnValue = method.invoke(obj, args); //上述方法的返回值，就作为当前类中invoke()方法的返回值 return returnValue; }}//主测试类public class ProxyTest { public static void main(String[] args){ //1.创建被代理类对象 SuperMan superMan = new SuperMan(); //2.创建代理类对象proxyInstance Human proxyInstance = (Human) ProxyFactory.getProxyInstance(superMan); //返回值是Object，但实际上是Human //3.实现方法，实际上自动调用了代理类的invoke方法 //其中三个参数值分别为：(Object proxy：代理类对象proxyInstance；Method method：调用方法getBelief；Object[] args：方法实参null/&quot;四川麻辣烫&quot;) //即：当通过代理类对象调用方法时，会自动的调用被代理类中同名的方法 //这两个方法实际上是被代理类SuperMan的方法，而我们通过代理类来调用，但又找不到具体的代理类（即代理类的对象没有显式创建），因此实现了动态代理 String belief = proxyInstance.getBelief(); proxyInstance.eat(&quot;四川麻辣烫&quot;); //因此：只需要提供被代理类（如SuperMan）和被代理类实现的接口（如Human），会自动的生成代理类对象（proxyInstance），去代理实现被代理类中的方法。 }}","link":"/2023/01/19/java%E5%9F%BA%E7%A1%80%E5%85%AB/"},{"title":"java基础（七）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的高级特性——网络编程。计算机网络是指把分布在不同地理区域的计算机与专门的外部设备用通信线路互连成一个规模大、功能强的网络系统，从而使众多的计算机可以方便的相互传递信息、共享硬件、软件、数据信息等资源。而网络编程的目的是直接或间接地通过网络协议与其它计算机实现数据交换，进行通讯。 本篇文章会从通信的两大要素：IP和端口号、网络协议的方面进行java网络编程的介绍。 网络编程计算机网络：把分布在不同地理区域的计算机与专门的外部设备用通信线路互连成一个规模大、功能强的网络系统，从而使众多的计算机可以方便的相互传递信息、共享硬件、软件、数据信息等资源。 网络编程的目的：直接或间接地通过网络协议与其它计算机实现数据交换，进行通讯。 通信要素一：IP和端口号 IP：唯一的表示Internet上的计算机（通信实体）； 在JAVA中使用InetAddress类代表IP； IP 分类：IPv4 和 IPv6；万维网 和 局域网； 域名：www.baidu.com…； 本地回路地址：127.0.0.1 ，对应着localhost。 举例 IP 地址的实例化： 123InetAddress inet1 = InetAddress.getByName(&quot;192.168.10.14&quot;);InetAddress inet2 = InetAddress.getByName(&quot;www.baidu.com&quot;);InetAddress inet3 = InetAddress.getLocalHost(); 端口号：标识正在计算机上运行的进程；不同的进程有不同的端口号； 端口号被规定为一个16位整数0~65535； 端口号与 IP 地址的组合得出一个Socket套接字。 通信要素二：网络通信协议网络通信协议：计算机网络中实现通信必须有一些约定，即通信协议，对速率、传输代码、代码结构、传输控制步骤、出错控制等指定标准。 TCP 和 UDP： TCP协议: 使用TCP协议前，须先建立TCP连接，形成传输数据通道； 传输前，采用“三次握手”方式，点对点通信，是可靠的； TCP协议进行通信的两个应用进程:客户端、服务端； 在连接中可进行大数据量的传输； 传输完毕，需释放已建立的连接（“四次挥手”），效率低。 UDP协议: 将数据、源、目的封装成数据包，不需要建立连接； 每个数据报的大小限制在64K内； 发送不管对方是否准备好，接收方收到也不确认，故是不可靠的； 可以广播发送； 发送数据结束时无需释放资源，开销小，速度快。 TCP生活案例：打电话；UDP案例：发短信、发电报。 TCP的三次握手和四次挥手： 实现TCP的网络编程： 例子：客户端发送信息给服务端，服务端将数据显示在控制台上 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//客户端public void client() throws IOException{ //1.创建Socket对象，指明服务器端的ip和端口号 InetAddress inet = InetAddress.getByName(&quot;127.0.0.1&quot;); //为**服务端**的端口号 Socket socket = ne w Socket(inet, 8899); //创建socket ip+端口号 //2.获取一个输出流，用于输出数据 OutputStream os = socket.getOutputStream(); //3.写出数据的操作 os.write(&quot;你好，我是客户端&quot;.getBytes()); //4.资源的关闭 os.close(); socket.close()} //服务端public void server() throws IOException{ //1.创建服务器端的Socket对象，指明自己的端口号 ServerSocket ss = new Socket(8899); //创建socket ip(用服务端自己的ip)+端口号 //2.调用accept方法，表示接收来自于客户端的socket Socket socket = ss.accept(); //3.获取输入流 InputStream is = socket.getInputStream(); //4.读取输入流中的数据 //使用ByteArrayOutputStream类进行读取，避免采用String方式直接读取出现字符的乱码情况 ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] buffer = new byte[5]; int len; while((len = is.read(buffer)) != -1)){ baos.write(buffer, 0, len); //String str = new String(buffer, 0, len); //System.out.println(str); } System.out.Println(baos.toString()); //显示内容 //5.资源关闭 baos.close(); is.close(); socket.close(); ss.close();} 注意：1. 上述代码的异常需要用try-catch-finally处理，类似于之前的IO编程； ​ 2. 运行时需要先启动服务端，再运行客户端去连接； ​ 3. 客户端与服务端的连接除了自定义的方式，还可以采用浏览器+Tomcat服务器的方式实现，javaweb中用得多。（如自己git bash中hexo server中的 localhost:4000 网站，即为此方式实现的） 实现UDP的网络编程： 12345678910111213141516171819202122232425262728293031323334//发送端public void sender() throws IOException{ //1.创建socket对象 DatagramSocket socket = new DatagramSocket(); //2.设置要发送的数据报 String str = &quot;我是UDP方式发送的数据&quot;; byte[] data = str.getBytes(); //转化为字节数据 InetAddress inet = InetAddress.getByName(&quot;127.0.0.1&quot;); DatagramPacket packet = new DatagramPacket(data, 0, data.length, inet, 9090); //为接收端的ip和端口号 //3.发送数据 socket.send(packet); //4.资源关闭 socket.close();}//接收端public void receiver() throws IOException{ //1.创建socket对象 DatagramSocket socket = new DatagramSocket(9090); //2.设置要接收的数据报 byte[] buffer = new buffer[100]; DatagramPacket packet = new DatagramPacket(data, 0, buffer.length); // 自己的ip和端口号就不用写了 //3.接收数据报 socket.receive(packet); System.out.Println(new String(packet.getData(), 0, packet.getLength())); //显示内容 //4.资源关闭 socket.close();} URL网络编程 URL(Uniform Resource Locator)：统一资源定位符，它表示Internet上某一资源的地址； 它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源； 通过URL我们可以访问Internet上的各种网络资源，比如最常见的 www，ftp站点。浏览器通过解析给定的URL可以在网络上查找相应的文件或其他资源； URL的基本结构由5部分组成： &lt;传输协议&gt;:/&lt;主机名&gt;:&lt;端口号&gt;/&lt;文件名&gt;#片段名?参数列表&gt; 例如：http://192.168.1.100:8080/helloworld/index.jsp#a?username=shkstart&amp;password=123 参数列表格式：参数名=参数值&amp;参数名=参数值… 例子：用URL类实现Tomcat服务器上的图片下载，并保存到本地。 123456789101112131415161718192021//1.配置urlURL url= new URL(&quot;http://localhost:8000/examples/beauty.jpg&quot;);HttpURLConnection urlConnection = (HttpURLConnection) url.openConnection();urlConnection.connect();//2.配置流InputStream is = urlConnection.getInputStream(); //输入流：从Tombat服务器中输入FileOutputStream fos = new FileOutputStream(&quot;beauty1.jpg&quot;); //输出流：保存为本地文件//3.进行读取和写入byte[] buffer = new byte[1024];int len;while((len = is.read()) != -1){ fos.write(buffer, 0, len);}System.out.println(&quot;下载完成！&quot;);//4.关闭资源is.close();fos.close();urlConnecton.disconnect();","link":"/2023/01/19/java%E5%9F%BA%E7%A1%80%E4%B8%83/"}],"tags":[{"name":"java","slug":"java","link":"/tags/java/"},{"name":"html","slug":"html","link":"/tags/html/"},{"name":"元学习","slug":"元学习","link":"/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"机器学习基础","slug":"机器学习基础","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"},{"name":"成员推断攻击","slug":"成员推断攻击","link":"/tags/%E6%88%90%E5%91%98%E6%8E%A8%E6%96%AD%E6%94%BB%E5%87%BB/"},{"name":"联邦学习","slug":"联邦学习","link":"/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"},{"name":"论文写作","slug":"论文写作","link":"/tags/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/"},{"name":"论文阅读笔记","slug":"论文阅读笔记","link":"/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"categories":[{"name":"java","slug":"java","link":"/categories/java/"},{"name":"web基础","slug":"web基础","link":"/categories/web%E5%9F%BA%E7%A1%80/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"编程基础","slug":"编程基础","link":"/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"},{"name":"论文写作","slug":"论文写作","link":"/categories/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/"},{"name":"论文阅读笔记","slug":"论文阅读笔记","link":"/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"pages":[]}