{"posts":[{"title":"java基础（一）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的基本语法，包括java的数据类型，变量，运算符，语句，数组等。 java语言的特点：面向对象，健壮性，跨平台性 java语言三大特性：封装，继承，多态 java数据类型 类型 存储空间 数据范围 byte 1字节=8bit位 -128~127 short 2字节 -2^15~2^15-1 int 4字节 -2^31~2^31-1 long 8字节 float 4字节 double 8字节 char 2字节 Java 的整型常量默认为 int 型，声明 long 型变量，必须以 ‘l’ 或 ‘L’ 结尾。long a=124548784L Java 的浮点型常量默认为 double 型，声明 float 型常量，变量要以 ‘f’ 或 ‘F’ 结尾。通常定义浮点变量时，使用 double。 char 型数据用来表示通常意义上“字符”。Java 中的所有字符都使用 Unicode 编码，故一个字符可以存储一个字母，一个汉字，或其他书面语的一个字符。 字符串类型String：String不是基本数据类型，属于引用数据类型。使用方式与基本数据类型一致。如： String str = “abcd”; String s2 = “a”; String s3 = “”。 String可以和8种基本数据类型变量做运算，且运算只能是连接运算 ‘+’ 。运算结果还是String类型。 判断+是加法还是连接：+前后两个要运算的有一个是字符串就是连接，没有就是加法。如： char c = ‘a’; //a:97 A:65 int number = 10; String str = “hello”; System.out.printIn(c + num + str); //107hello java的变量语法（声明并赋值，二者可分开）： &lt;数据类型&gt; &lt;变量名&gt; = &lt;初始化值&gt; 如：int var = 10; 变量的作用：用于在内存中保存数据 使用变量注意： Java中每个变量必须先声明(定义且赋值)，后使用 使用变量名来访问这块区域的数据 变量的作用域：其定义所在的一对{ }内 变量只有在其作用域内才有效 同一个作用域内，不能定义重名的变量 java运算符算数运算符： b=++a：先运算后取值；b=a++：先取值后运算 /：除法：整数之间做除法时，只保留整数部分而舍弃小数部分。如：12/5=2 (double)12/5=2.4 %：取模：对负数取模，可以把模数负号忽略不记， 与被模数符号相同。如：12%5=2; (-12)%5=-2; (-12)%(-5)=-2 赋值运算符： 符号：=；当“=”两侧数据类型不一致时，可以使用自动类型转换或使用强制类型转换原则进行处理。支持连续赋值。 扩展赋值运算符：+=, -=,*=, /=, %=。两者区别：扩展赋值运算符不会改变本身变量的数据类型，如: short s=10; s=s+10; //编译失败，但是s+=10编译成功 逻辑运算符：&amp;逻辑与 &amp;&amp;短路与 |逻辑或 ||短路或 !逻辑非 ^逻辑异或 在Java中不可以写成3&lt;x&lt;6，应该写成x&gt;3 &amp; x&lt;6 。 位运算符：&amp; | ^ ~ &lt;&lt; &gt;&gt; 三元运算符：(条件表达式)?表达式1: 表达式2； 可嵌套 java循环语句while循环的语法如下： 先判断再循环 while(布尔表达式){ 循环体;} do-while循环的语法如下： 先循环再判断 do{ 循环体; }while(布尔表达式); for循环的语法结构： for(表达式1; 表达式2; 表达式3){ 循环体; } 其中：表达式1的作用是给循环变量初始化；表达式2的作用是给出循环条件；表达式3的作用是改变循环变量的值；循环体可以是一条或多条语句。 for循环的执行过程是：执行表达式1，计算表达式2，如果表达式2的值为true，执行循环体，执行表达式3，改变循环变量的值，再计算表达式2的值，如果是true，再进入循环体，形成循环，直到表达式2的值为false，结束循环，执行for后面的语句。 java数组一维数组的声明与创建： 元素类型[] 数组名 = new 元素类型[元素个数或数组长度]; –动态 元素类型[] 数组名 = new 元素类型[]{元素，元素，……}; –静态 元素类型[] 数组名 = {元素，元素，……}; –静态 示例： int[] arr = new int[5]; //此时初始值为0，初始化方式如: arr[0]=1 int[] arr = new int[]{3,5,1,7}; //创建并初始化 int[] arr = {3,5,1,7}; //创建并初始化 注意：1.给数组分配空间时，必须指定数组能够存储的元素个数来确定数组大小。创建数组之后不能修改数组的大小。可以使用length 属性获取数组的大小。 2.元素类型为String时，初始化的值为null 3.元素类型后面的[]可以放在数组名后面 4.若要复制数组arr1，需要new一个新数组arr2=new int[arr1.length]，而不能 直接arr2=arr1，直接相等会导致arr1和arr2是同一个地址，改变arr2也会改变arr1的值，而new一个新的arr说明arr1和arr2地址不同。 Arrays的使用： 遍 历： Arrays.toString(array) 将数组的元素以字符串的形式返回，如”[1, 2, 3]” 排序： Arrays.sort(array) 将数组按照升序排列 查找： binarySearch()在指定数组中查找指定元素，返回元素的索引，如果没有找到返回（-插入点-1） 注意：使用查找的功能的时候，数组一定要先排序 二维数组定义： 动态定义： 数组类型[][] 数组名 = new 数组类型[一维数组的个数][每一个一维数组中元素的个数]; 数组类型[][] 数组名 = new 数组类型[一维数组的个数][]; 此方法需要再定义一次一维数组，用于元素个数不确定的情况 或者直接进行静态定义 注意：1.二维数组不要求每个一维数组的元素个数相等","link":"/2023/01/11/java%E5%9F%BA%E7%A1%80%E4%B8%80/"},{"title":"html入门","text":"本篇文章讲解了html的入门知识。首先讲解了html的基本元素和格式，之后讲解了一个html文档的基本结构，其中具体介绍了head内容和body内容的拓展。 HTML元素：一个HTML元素包括： 基本格式： &lt;元素 属性&gt;内容&lt;/元素&gt; &lt;&gt;中可以添加属性，用引号进行表示，它们不会显示出来 &lt;!–我是注释–&gt;间可以添加注释 &lt;p&gt;&lt;/p&gt;：封装为段落。元素的属性有： · class 赋予名字(id)，这个名字此后可以被用来识别此元素的样式信息和其他信息 &lt;em&gt;&lt;/em&gt;：斜体 &lt;strong&gt;&lt;/strong&gt;：加粗 &lt;h&gt;&lt;/h&gt;：标题 有h1，h2… &lt;img&gt;：插入指定图片 · src 图片地址 &lt;a&gt;：是被包裹的内容成为一个链接。&lt;a&gt;元素的属性有： &lt;input&gt;：输入数据 · type 数据格式 · disabled 禁止输入 HTML文档：一个HTML文档由多个HTML元素构成。 1.&lt;!DOCTYPE html&gt;: 声明文档类型 2.&lt;html&gt;&lt;/html&gt;：根元素，包裹了整个界面 3.&lt;head&gt;&lt;/head&gt;: &lt;head&gt;元素. 这个元素是一个容器，它包含了所有你想包含在HTML页面中但不想在HTML页面中显示的内容。这些内容包括你想在搜索结果中出现的关键字和页面描述，CSS样式，字符集声明等等。 4.&lt;meta charset=”utf-8”&gt;: 这个元素设置文档使用utf-8字符集编码，utf-8字符集包含了人类大部分的文字。基本上他能识别你放上去的所有文本内容。毫无疑问要使用它，并且它能在以后避免很多其他问题。 5.&lt;title&gt;&lt;/title&gt;: 设置页面标题，出现在浏览器标签上，当你标记/收藏页面时它可用来描述页面。 6.&lt;body&gt;&lt;/body&gt;: &lt;body&gt;元素。 包含了你访问页面时所有显示在页面上的内容，文本，图片，音频，游戏等等。 Head内容拓展：1.添加作者和描述 2.其它类型源数据 3.添加自定义图标 4.在HTML中应用CSS和Javascript Body内容拓展：1.标题和段落： 2.列表： 每份无序的清单从&lt;ul&gt;元素开始——需要包裹清单上所有被列出的项目； 然后用 &lt;li&gt;元素把每个列出的项目单独包裹起来： 有序列表的结构和无序列表一样，除了需要用&lt;ol&gt;元素将所有项目包裹, 而不是&lt;ul&gt;。 3.斜体、粗体、下划线 其它：实体引用（转义字符）： 代码格式：通常每一个嵌套的元素以两个空格缩进。","link":"/2022/12/22/html%E5%85%A5%E9%97%A8/"},{"title":"java基础（三）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的面向对象部分（下），包括多态性，Object类和包装类，代码块，抽象类(abstract)，接口(interface)等，此外介绍了关键字static的使用和异常的处理等。 java多态性多态性的理解：一个事物的多种形态 对象的多态性：父类的引用指向子类的对象 如：Person p1 = new Women() 举例：可将new Women()或者new Men()作为方法func(Person person)的person参数，即func(new Women())，并在func中实际调用Women或Men类重写的方法。 多态的使用：虚拟方法调用（原父类被重写的方法叫虚拟方法） 有了对象的多态性以后，我们在编译期，只能调用父类中声明的方法，但在运行期，我们实际执行的是子类重写父类的方法。总结：编译，看左边；运行，看右边。 多态性的使用前提：1.类的继承关系 2.要有方法的重写 不然这样用就没有意义，不如直接调用父类的对象 注意：1. 对象的多态性，只适用于方法，不适用于属性（编译和运行都看左边） ​ 2. 多态是运行时行为 向下转型：将父类的对象转换成子类对象，以使用子类独有的属性和方法（多态实际上是向上转型） 如 Woman p2 = (Woman)p1，这样p2就变成了Woman类的对象 instanceof的使用：a instanceof A 判断对象a是否是类A的实例，如果是，返回true，如果不是，返回false 使用情境：为了避免在向下转型时出现ClasscastException的异常，我们在向下转型之前，先进行instanceof的判断，一旦返回true，就进行向下转型。如果返回false，不进行向下转型。如上述向下转型需判断 p1 instanceof Woman为true 如果a instanceof A返回true,则a instanceof B也返回true.其中,类B是类A的父类。 Object类和包装类运算符==的使用： 可以使用在基本数据类型变量和引用数据类型变量中 如果比较的是基本数据类型变量：比较两个变量保存的数据是否相等(不一定类型要相同) 如果比较的是引用数据类型变量，比较两个对象的地址值是否相同，即两个引用是否指向同一个对象实体 方法equals()的使用： object类中equals()的定义: public booiean equals(object obj) { ​ return (this==obj); } 说明: equals()是一个方法，只能应用于引用数据类型 object类中定义的equals()和==的作用是相同的。比较两个对象的地址值是否相同.即两个引用是否指向同一个对象实体。 像String、 Date、File、包装类等都重写了Object类中的equals()方法。重写以后，比较的不是两个引用的地址是否相同，而是比较两个对象的实体内容是否相同。 方法toString()的使用： 当我们输出一个对象的引用时（ 即System.out.println() 时），实际上就是调用当前对象的toString()方法 object类中toString()的定义: public string toString(){ ​ return getclass().getName()+”@” + Integer.toHexString(hashcode()); } 像String、Date、File、包装类等都重写了object类中的toString()方法，使得在调用对象的toString()时,返回”实体内容”信息。 包装类：针对八种基本数据类型定义相应的引用类型——包装类（封装类）。 具体的，一般是将首字母的小写变大写，如byte-&gt;Byte，此外有一些特殊：int-&gt;Integer；char-&gt;Character 基本数据类型，包装类，String之间的相互转化： static关键字1.static:静态的 2.static可以用来修饰: 属性、方法、代码块、内部类 3.使用static修饰属性: 静态变量（或类变量) 3.1. 属性：按是否使用static修饰，又分为: 静态属性Vs 非静态属性(实例变量) 实例变量: 我们创建了类的多个对象，每个对象都独立的拥有一套类中的非静态属性。当修改其中一个对象中的非静态属性时,不会导致其他对象中同样的属性值的修改。 静态变量: 我们创建了类的多个对象，多个对象共享同一个静态变量。当通过某一个对象修改静态变量时，会导致其他对象调用此静态变量时，是修改过了的。 3.2. static修饰属性的其他说明: 静态变量随着类的加载而加载。可以通过”类.静态变量”的方式进行调用静态变量的加载要早于对象的创建。 由于类只会加载一次，则静态变量在内存中也只会存在一份:存在方法区的静态域中。 类可以调用其类变量，但不能调用实例变量；对象可以调用类变量，也可以调用实例变量 3.3. 静态属性举例：System.out Math.PI 4.使用static修饰方法：静态方法 随着类的加载而加载，可以通过”类.静态方法”的方式进行调用 静态方法中，只能调用静态的方法或属性；非静态方法中，既可以调用非静态的方法或属性,也可以调用静态的方法或属性 类可以调用其静态方法，但不能调用非静态方法；对象都可以调用 在静态的方法内,不能使用this关键字、super关键字 关于静态属性和静态方法的使用，可以从生命周期的角度去理解。静态的是随着类的创建就创建，随着类的消失而消失；非静态的是随着对象的创建而开始，对象的消失而终止。 5.1 开发中，如何确定一个属性是否要声明为static的? ​ 属性是可以被多个对象所共享的，不会随着对象的不同而不同的。 5.2 开发中，如何确定一个方法是否要声明为static的? ​ 操作静态属性的方法，通常设置为static的； ​ 工具类中的方法，习惯上声明为static的 代码块格式： { ​ //代码块中内容 ​ } 1.代码块的作用:用来初始化类、对象 2.代码块如果有修饰的话，只能使用static 3.分类：静态代码块Vs非静态代码块 4.静态代码块 （加了static） 内部可以有输出语句 随着类的加线而执行,而且只执行一次 作用:初始化类的信息 静态代码块要优于非静态代码块执行 5.非静态代码块 内部可以有输出语句 随着对象的创建而执行，每创建一个对象，就执行一次非静态代码块 作用:可以在创建对象时，对对象的属性等进行初始化 final关键字的使用final：最终的 1.final可以用来修饰的结构：类、方法、变量 2.final用来修饰一个类：此类不能被其他类所继承。 比如：String类、System类、StringBuffer类 3.final用来修饰方法：表明此方法不可以被重写。 比如，Object类中getClass(); 4.final修饰变量，此时变量变常量，即不能改变 abstract关键字的使用1.abstract修饰类：抽象类 抽象类不能被实例化；抽象类中一定有构造器，便于子类实例化时调用；开发中，都会提供抽象类的子类，让子类对象实例化 2.abstract修饰方法：抽象方法 抽象方法中只有方法的声明，没有方法体；包含抽象方法的类一定是抽象类，而抽象类中可以没有抽象方法 若子类重写了父类中的所有抽象方法，则此子类可以被实例化；若子类没有重写父类的所有抽象方法，则该子类也是一个抽象类，需要用abstract修饰。 3.abstract不能用来修饰：属性、构造器等结构，不能修饰私有方法、静态方法、final修饰的方法和类 interface：接口的使用Java中，接口和类是并列的两个结构 如何定义接口：定义接口中的成员 JDK7及以前，只能定义全局常量和抽象方法 ​ &gt;全局常量：public static final的，但是书写时，可以省略不写 ​ &gt;抽象方法：public abstract的，但是书写时，可以省略不写 JDK8:除了定义全局常量和抽象方法之外，还可以定义静态方法、默认方法（略) 接口中不能定义构造器的！意味着接口不可以实例化 Java开发中，接口通过让类去实现(implements)的方式来使用。 如果实现类覆盖了接口中的所有抽象方法，则此实现类就可以实例化如果实现类没有覆盖接口中所有的抽象方法，则此实现类仍为一个抽象类 JAVA类可以定义多个接口，class AA extends BB implements CC,DD,EE；接口课可以继承接口，甚至可以继承多个接口","link":"/2023/01/12/java%E5%9F%BA%E7%A1%80%E4%B8%89/"},{"title":"java基础（五）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的高级特性——集合。java集合可分为Collection和Map两种体系。Collection接口：单列集合，存储一个一个的对象。其中包括List接口和Set接口；Map接口：双列集合，用来存储一对（key-value）一对的数据。 java集合可分为Collection和Map两种体系。 1.Collection接口：单列集合，存储一个一个的对象 ​ 1.1 List接口，存储有序的、可重复的数据； ​ 如：ArrrayList、LinkedList、Vector ​ 1.2 Set接口，存储无序的、不可重复的数据； ​ 如：HashSet、 LinkedHashSet、TreeSet 2.Map接口：双列集合，用来存储一对（key-value）一对的数据。 ​ 如：HashMap、LinkedHashMap、TreeMap Collection接口Collection接口中的常用方法新建一个Collection接口对象。如：Collection coll1 = new ArrayList() add(Object e)：将元素e添加到集合中； addAll(Collection coll)：将集合coll中的元素添加到该集合中； size()：获取添加元素的个数； clear()：清空集合元素； isEmpty()：判断当前集合是否为空； contains(Object e)：判断集合中是否存在元素e；–containsAll同理 remove(Object e)：删除一个元素e，并返回是否删除成功；–removeAll同理 retrainAll(Collection coll)：求集合交集，并将结果返回在原集合中； equals(Object e)：返回与e是否相等，要想返回true，e首先得是Collection； toArray(Collection coll)：集合转化为数组。 注意：向Collection接口的实现类的对象中添加数据obj时，要求obj所在类重写equals()。 集合Collection的遍历使用Iterator迭代器遍历集合Collection[主要是List]：使用hasNext()和next() 例子： 1234Collection coll = new ArrayList();Iterator iter = coll.interator();while(iter.hasNext()): System.out.println(iter.next()); //打印当前集合中的对应元素 注意：1. 可以想象有一个指针，iter最先指向空，hasNext()判断下一个元素有没有值，如果有，则使用next()先将指针移动到下一个元素，然后返回指向元素的值。 Iterator仅用于遍历集合，本身没有承装对象的能力。如果需要创建Iterator对象，则必须有一个被迭代的集合； 集合对象每次调用iterator()方法都得到一个全新的迭代器对象，默认指针都在第一个元素之前（即空）； iter.remove()：可以在遍历的时候，对集合的元素进行移除操作。 foreach遍历集合和数组：（jdk5.0新增） 格式：for(集合中元素类型 局部变量 : 集合对象){ … } 如：for(Object obj : coll){ ​ System.out.println(obj); //其实obj内部调用的还是迭代器 ​ } List接口List接口：存储有序的、可重复的数组–&gt;”动态”数组，可替换原有数组 ArrayList：List接口的主要实现类；线程不安全的，效率高；底层使用Object[] elementData存储； LinkedList：底层使用双向链表存储；对于频繁的插入和删除操作，此类效率更高； Vector：List接口的远古实现类；线程安全的，效率低；底层使用Object[] elementData存储 ArrayList类ArrayList源码分析： 1.jdk 7情况下： ArrayList list = new ArrayList(); //底层创建了长度是10的object[]数组elementData list.add(123); //elementData[e] = new Integer(123); … list.add(11); //如果此次的添加导致底层elementData数组容量不够，则扩容。 默认情况下，扩容为原来的容量的1.5倍，同时需要将原有数组中的数据复制到新的数组中。 结论：建议开发中使用带参的构造器：ArrayList list = new ArrayList(int capacity) 2.jdk 8中ArrayList的变化: ArrayList list = new ArrayList(); //底层object[] elementData初始化为{}，并没有创建长度为10的数组 list.add(123); //第一次调用add()时，底层才创建了长度10的数组，并将数据123添加到elementData中 后续的添加和扩容操作与jdk 7无异。 3.小结：jdk7中的ArrayList的对象的创建类似于单例的饿汉式，而jdk8中的ArrayList的对象的创建类似于单例的懒汉式,延迟了数组的创建，节省内存。 LinkedList类LinkedList源码分析： LinkedList list = new LinkedList(); // 内部声明了Node类型的first和last属性，默认值null list.add(123);//将123封装到Node中，创建了Node对象。 其中，Node的定义体现了LinkedList的双向链表的说法： 123456789private static class Node&lt;E&gt; { E item; Node&lt;E&gt;next; Node&lt;E&gt;prev; Node(Node&lt;E&gt; prev, E eLement, Node&lt;E&gt; next) { this.item = element; this.next = next; this.prev = prev;}} List接口中常用方法： Set接口Set接口：存储无序的、不可重复的数组–&gt;高中讲的”集合” HashSet：Set接口的主要实现类；线程不安全的；可以存储null值； LinkedHashSet：作为HashSet的子类；遍历其内部数据时，可以按照添加的顺序遍历；在添加数据的同时，每个数据还维护了两个引用，记录此数据的前一个数据和后一个数据；（类似于添加了链表的功能） TreeSet：可以按照添加对象的指定属性，进行排序。 Set接口没有单独定义方法，均是Collection中定义过的方法； 向Set中添加的数据，其所在的类一定要重写hashCode()和equals()方法； hashCode()和equals()还需要保持一致性。 以HashSet为例说明: 无序性：不等于随机性。存储的数据在底层数组中并非按照数组索引的顺序添加，而是根据数据的哈希值进行添加； 不可重复性：保证添加的元素按照equals()判断时，不能返回true。即：相同的元素只能添加一个。 添加元素的过程：（以HashSet为例说明） 我们向HashSet中添加元素a，首先调用元素a所在类的hashcode()方法，计算元素a的哈希值，此哈希值接着通过某种算法计算出在HashSet底层数据中的存放位置（即为索引位置），判断数组此位置上是否有元素： ​ 如果此位置上没有其他元素，则a添加成功； —&gt; 情况一 ​ 如果此位置上有其它元素b（或以链表形式存在的多个元素），则比较元素a与元素b的hash值： ​ 如果hash值不同，则元素a添加成功； —&gt;情况二 ​ 如果hash值相同，进而需要调用元素a所在类的equals()方法： ​ equals() 返回true，元素a添加失败； ​ equals() 返回false，元素a添加成功。 —&gt;情况三 对于添加成功的情况二和情况三而言，元素a与已经存在指定索引位置上的数据以链表的方式存储。 Jdk7：元素a放到数组中，指向原来的元素 Jdk8：原来的元素在数组中，指向元素a HashSet底层：数组+链表 TreeSet：可以按照添加对象的指定属性，进行排序 向TreeSet中添加数据，需要保证是相同类的对象； 两种排序方式：自然排序（实现comparable接口）和定制排序（Comparator类）； 自然排序时，比较两个对象相同的标准为：compareTo()返回0，而不是equals()； 定制排序时，比较两个对象相同的标准为：compare()返回0，而不是equals() Map接口Map接口：双列数据，用来存储一对（key-value）一对的数据。 HashMap：作为Map的主要实现类；线程不安全的，效率高；可以存储null的key和value；LinkedHashMap：保证遍历map元素时，可以按照添加的顺序实现遍历；在原有的HashMap底层结构的基础上，添加了一对指针，指向前一个和后一个元素；对于频繁的遍历操作，执行效率要高于HashMap；底层使用红黑树； TreeMap：可以按照添加的key-value对进行排序，实现排序遍历，此时考虑key的自然排序或定制排序； Hashtable：Map的古老实现类；线程安全的，效率低；不可以存储null的key和value； Properties：常用来处理配置文件，key和value都为String类型。 Map结构的理解： key是无序的、不可重复的，使用Set存储所有的key； —&gt;key所在的类要重写equals()和hashCode() value是无序的、可重复的，使用Collection存储所有的value； —&gt;value所在的类要重写equals() 一个键值对：key-value构成了一个Entry对象，使用Set存储所有的Entry HashMap类HashMap的底层结构：数组+链表（jdk7之前） 数组+链表+红黑树（jdk8之后） HashMap原理：jdk7 HashMap map = new HashMap()： 在实例化以后，底层了创建了一个长度是16的一维数组Entry[] table …可能执行了多个put… map.put(key1, value1)： 首先调用key1所在类的hashcode()计算key1的哈希值，此哈希值接着通过某种算法计算以后，得到在Entry数组中的存放位置。判断数组此位置上是否有元素： ​ 如果此位置上的数据为空，则key1-value1添加成功； —&gt; 情况一 ​ 如果此位置上的数据不为空（意味着存在一个或多个数据（以链表形式存在）），则比较key1与已经存在元素的hash值： ​ 如果hash值都不同，则key1-value1添加成功； —&gt;情况二 ​ 如果key1的hash值与已经存在的某一个元素key2-value2相同，则比较equals()方法： ​ equals() 返回true，使用value1替换value2； ​ equals() 返回false，元素a添加成功。 —&gt;情况三 对于添加成功的情况二和情况三，此时key1-value1与已经存在指定索引位置上的数据以链表的方式存储。 在不断的添加过程中，会存在扩容问题，默认的扩容方式：扩容为原来的两倍，并将数据复制。 HashMap原理：jdk8 jdk8相较于jdk7在底层实现方面的不同: new HashMap()：底层没有创建一个长度为16的数组； jdk 8底层的数组是：Node[]，而非Entry[]； 首次调用put()方法时，底层创建长度为16的数组； jdk7底层结构只有：数组+链表。jdk8中底层结构：数组+链表+红黑树； 当数组的某一个索引上的元素以链表形式存在的个数&gt;8，且当前数组的长度&gt;64时，此时此索引位置上的数据改为红黑树存储。 Map的常用方法 遍历所有的key集：keySet Map map = new HashMap(); …..多次put…. Set set = map.keySet(); Iterator iter = set.iterator(); while(iter.hasNext()): System.out.println(iter.next());} 遍历所有的value集：values() Collection values = map.values(); for(Object obj : values): System.out.println(obj);} Collections工具类Collections工具类：可以操作Collection和Map的工具类 使用方法：如 List list = new Arraylist(); ​ ….多次add….. ​ Collections.reverse(list);","link":"/2023/01/14/java%E5%9F%BA%E7%A1%80%E4%BA%94/"},{"title":"java基础（二）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的面向对象部分（上），包括类和对象的介绍，封装性、继承性的体现等，此外介绍了关键字this、package、import、super的使用。 java类和对象类是抽象的一类事物，对象是具体的一个实例。 类的定义： class Person{ ​ //属性 String name; int age = 10; //方法 public void speak(String language) { system.out.println(‘说的语言是:’, language) }} 类的实例化: Person zhangsan = new Person() 调用属性和方法：zhangsan.name; zhangsan.speak(‘Chinese’) 方法的声明：权限修饰符 返回值类型 方法名(形参列表) { ​ 方法体 ​ } 四种权限修饰符：private、public、缺省、protected 返回值类型： 若没有返回值 则为void，在方法中不写return或就写一个return; 若有返回值 则需要在声明时写返回值的类型，并在方法中写 return+返回值 关于变量的赋值： 如果变量是基本数据类型，则此时赋值的是变量所保存的数据 如果变量是引用数据类型，则此时赋值的是变量所保存数据的地址值 方法形参的传递机制：值传递 形参：方法定义时，声明的小括号的参数 实参：方法调用时，实际传递给形参的数据 值传递机制： 如果参数是基本数据类型，此时实参赋给形参的是实参真实存储的数据值 如果参数是引用数据类型，此时实参赋给形参的是实参存储数据的地址值 构造器（构造方法，constructor）：任何类中都有，用于1.创建对象 2.属性初始化 使用位置：Person zhangsan = new Person() 其中Person()就是构造器 如果没有显式的定义类的构造器的话，则系统默认提供一个空的构造器 构造器的表示为 类名()，可以理解为名称与类名相同的方法，类似于python的__init__ 一个类中可以定义多个构造器，彼此构成重载 一旦定义了显式构造器，则系统不再提供空的构造器 属性赋值的先后顺序：默认初始化(系统默认值)-显式初始化(类中定义时手动的赋值)/代码块中赋值(取决于先后顺序)-构造器中赋值-通过’对象.属性’或’对象.方法’赋值 java类的封装性封装性的设计思想：隐藏对象内部的复杂性，只对外公开简单的接口，便于外界调用，从而提升系统的可扩展性、可维护性。通俗的说，把该隐藏的隐藏起来，该暴露的暴露起来。 封装性的体现：我们将类的属性xxx私有化(private)，同时提供公共的(public)方法来获取(getXxx)和设置(setXxx)此属性的值。 这只是一个体现，还有很多体现，如设置不对外暴露的私有化方法，只在类中可见；单例模式，即构造器的私有化等。 封装性的体现，需要权限修饰符的配合。从小到大排列：private、缺省、protected、public 修饰符 类内部 同一个包 不同包的子类 同一个工程 private Yes default(缺省) Yes Yes protected Yes Yes Yes public Yes Yes Yes Yes 注：1. 对于类的权限修饰只能是public和缺省。其中public可以在任意地方被访问，缺省类只可以被同一个包的内部访问。 ​ 2. 四种权限都可以用来修饰类的内部结构：属性，方法，构造器，内部类 this的使用： this可以用来修饰、调用：属性、方法、构造器 this修饰属性和方法：this理解为：当前对象 ​ 2.1. 在类的方法中，我们可以使用’this.属性’或’this.方法’的方式，调用当前对象的属性或方法，但是，通常情况下，我们都选择省略’this.’。特殊情况下，如果方法的形参与类的属性同名时，我们必须显示的使用’this.变量’的方式，表明此变量是属性，而不是形参。 ​ 2.2. 在类的构造器中，我们可以使用’this.属性’或’this.方法’的方式，调用当前正在创建的对象属性或方法，但是，通常情况下，我们都选择省略’this.’。特殊情况下，如果构造器的形参与类的属性同名时，我们必须显示的使用’this.变量’的方式，表明此变量是属性，而不是形参。 this调用构造器 ​ 3.1 我们在类的构造器中，可以显示的使用’this(形参列表)’方式，调用本类中指定的其它构造器 ​ 3.2 构造器不能通过’this(形参列表)’自己调用自己；如果类中有n个构造器，最多有n-1个构造器使用’this(形参列表)’调用其它构造器 ​ 3.3 规定’this(形参列表)’必须声明在当前构造器的首行，构造器内部最多只能声明一个’this(形参列表)’来调用其他的构造器 package: 包 便于实现项目中类的管理 同一个包下，不能命名同名的类、接口 不同的包下，可以命名同名的类、接口 import: 导入 1．在源文件中显式的使用import结构导入指定包下的类、接口 2．声明在包的声明和类的声明之间 3．如果需要导入多个结构,则并列写出即可 4．可以使用”XXX.*”的方式,表示可以导入XXX包下的所有结构 5．如果使用的类或接口是java.lang包下定义的，则可以省略import结构 6．如果使用的类或接口是本包下定义的，则可以省略import结构 7．如果在源文件中，使用了不同包下的同名的类，则必须至少有一个类需要以全类名的方式显示。 8．使用”xxx.*”方式表明可以调用xxx包下的所有结构。但是如果使用的是xxx子包下的结构，则仍需要显式导入: 9．import static:导入指定类或接口中的静态结构。 java类的继承性继承性的好处： 减少了代码的冗余，提高了代码的复用性 便于功能的扩展 为之后的多态性的使用，提供了前提 继承性的格式： class A extends B{} A：子类、派生类、subclass B：父类、超类、基类、superclass 一旦子类A继承了父类B，子类A中就获取了父类B中的声明的所有属性和方法。 特别的，父类中声明为private的属性或方法，子类继承父类以后，仍然认为获取了父类中私有的结构。只有因为封装性的影响,使得子类不能直接调用父类的结构而已。 子类继承了父类后，还可以声明自己的属性或方法，实现功能的拓展。 注意： 子父类是相对的概念；子类直接继承的父类，称为:直接父类。间接继承的父类称为:间接父类 子类继承父类以后，就获取了直接父类以及所有间接父类中声明的属性和方法 如果没有显式声明父类的话，则此类继承于java.lang.Object类 方法的重写： 在子类中可以根据需要对从父类中继承来的方法进行改造，也称为方法的重置、覆盖。在程序执行时，子类的方法将覆盖父类的方法。 子类重写的方法必须和父类被重写的方法具有相同的方法名称、参数列表 子类重写的方法的返回值类型不能大于父类被重写的方法的返回值类型3.子类重写的方法使用的访间权限不能小于父类被重写的方法的访问权限 子类不能重写父类中声明为private权限的方法 子类方法抛出的异常不能大于父类被重写方法的异常注意: 注意：子类与父类中同名同参数的方法必须同时声明为非static的(即为重写)，或者同时声明为static的（不是重写)。因为static方法是属于类的，子类无法覆盖父类的方法。 super的使用： 对于this，是先在自己类中找属性或方法，如果没找到，然后再去对应父类找 对于super，则是直接在父类中找，如果直接父类没有，再继续往上找 （this就是理解为自己类，super理解为父类） super调用属性或方法： 1．我们可以在子类的方法或构造器中。通过使用”super.属性”或”super.方法”的方式，显式的调用父类中声明的属性或方法。但是,通常情况下,我们习惯省略”super. “ 2．特殊情况：当子类和父类中定义了同名的属性时，我们要想在子类中调用父类中声明的属性，则必须显式的使用”super.属性”的方式，表明调用的是父类中声明的属性。 3．特殊情况：当子类重写了父类中的方法以后，我们想在子类的方法中调用父类中被重写的方法时，则必须显式的使用”super.方法”的方式,表明调用的是父类中被重写的方法。 super调用构造器 1． 我们可以在子类的构造器中显式的使用”super(形参列表)”的方式，调用父类中声明的指定的构造器 2．”super(形参列表)”的使用,必须声明在子类构造器的首行! 3．我们在类的构造器中，针对于”this(形参列表)”或”super(形参列表)”只能二选一，不能同时出现 4．在构造器的首行，没有显式的声明”this(形参列表)”或”super(形参列表)”，则默认调用的是父类中空参的构造器 5．在类的多个构造器中，至少有一个构造器使用了”super(形参列表)”(显式或隐式)，调用父类的构造器 子类对象实例化的全过程 1．从结果上来看:（继承化） 子类继承父类以后，就获取了父类中声明的属性或方法。 创建子类的对象,在堆空间中,就会加载所有父类中声明的属性。 2．从过程上来看: 当我们通过子类的构造器创建子类对象时，我们一定会直接或间接的调用其父类的构造器，进而调用父类的父类的构造器.直到调用了java.lang.Object类中空参的构造器为止。正因为加载过所有的父类的结构，所以才可以看到内存中有父类中的结构,子类对象才可以考虑进行调用。 明确：虽然创建子类对象时调用了父类的构造器，但是自始至终就创建过一个对象，即为new的子类对象。","link":"/2023/01/12/java%E5%9F%BA%E7%A1%80%E4%BA%8C/"},{"title":"java基础（六）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的高级特性——泛型和IO流。在IO流中，会介绍File类、文件流和处理流（缓冲流、转换流、对象流等）的使用。 java泛型在集合中使用泛型： 集合接口或集合类在jdk5.0时都修改为带泛型的结构。在实例化集合类时，可以指明具体的泛型类型； 指明完以后，在集合类或接口中凡是定义类或接口时，内部结构（比如：方法、构造器、属性等）使用到类的泛型的位置，都指定为实例化时的反向类型； 比如: add(E e) —&gt;实例化以后: add(Integer e) 注意点：泛型的类型必须是类，不能是基本数据类型。需要用到基本数据类型的位置，拿对应的包装类作为泛型的类型； 如果实例化时，没有指明泛型的类型。默认类型为java.lang.object类型。 IO流File类File类的使用 File类的一个对象，代表一个文件或一个文件目录（文件夹）； 来自于java.io包下； 实例化方法1：File file1 = new File(“hello.txt”); //相对路径，相对于当前module 实例化方法2：File file2 = new File(“D:\\study\\java\\hello.txt”); //绝对路径 实例化方法3：File file3 = new File(“study”, “java”); //父路径+子路径 实例化方法4：File file4 = new File(file3, “hello.txt”); //之前的file路径+新增路径 File类中只涉及到关于文件和文件目录的创建、删除、重命名等方法，并未设计到写入或读取文件内容的操作。如果需要写入或读取内容，必须使用IO流实现； 后续File类的对象常会作为参数传递到流的构造器中，指明读取或写入的“终点”。 File的创建和删除123456789101112131415//创建和删除文件File file1 = new File(&quot;hello.txt&quot;);//如果file1在硬盘中不存在，则创建file1if(!file1.exists()){ file1.createNewFile();}else{ //文件存在，就删除文件 file1.delete() }//创建文件目录File file2 = new File(&quot;D:\\\\io\\\\io1&quot;);Boolean mkdir1 = file2.mkdir(); //只创建当前目录，前提是其父目录一定存在，否则返回false创建失败Boolean mkdir2 = file2.mkdirs(); //会创建上层没有的目录，不管父目录是否存在都会创建成功if(mkdir1): System.out.println(&quot;创建成功&quot;) 文件流IO流原理和分类： IO是Input/Output的缩写，用于处理设备之间的数据传输，如读/写文件，网络通讯等； java程序中，对于数据的输入/输出操作以“流stream”的方式进行； IO流的相关类和接口来自于java.io包中，通过标准的方法输入和输出数据； 我们是站在内存（即程序）的角度理解输入（读取外部数据到内存）和输出（将程序的数据输出到外部）； 按操作数据单位分为字节流（8 bit）和字符流（16 bit）；按流向分为输入流和输出流；按流的角色分为节点流和处理流。 基础类有：字节输入流InputStream，字节输出流OutputStream；字符输入流Reader，字符输出流Writer。这些都是抽象类，派生的子类才能被实例化，对应的子类的名称都是以其父类名称作为后缀。 文件内容的读入：FileReader例子：将hello.txt内容读入到程序中，并输出 read()的理解：返回读入的第一个字符，如果达到文件末尾，则返回-1； 异常的处理：为保证流资源一定可以执行关闭操作，需要使用try-catch-finally处理异常; 读入的文件一定要存在，否则会报异常。 1234567891011121314151617181920212223242526272829303132333435363738FileReader fr = null;try{//1.实例化File对象，指明需要操作的文件File file = new File(&quot;hello.txt&quot;); //2.提供具体的流fr = new FileReader(file); //3.读入操作//3.1 方法一：一次读一个//int data;//while(data = fr.read() != -1):{//System.out.print((char)data);//}//3.2 方法二：一次读指定个char[] cbuf = new char[5]; // 一次五个int len;while((len = fr.read(cbuf)) != -1){ //3.2.1用for循环读 for(int i = 0; i &lt; len; i++){ System.out.print(char[i]); } //3.2.2 还可以用String读取char[]内容 String str = new String(cbuf, 0, len); System.out.print(str); }} catch (IOException e){ e.printStackTrace();} finally{//4.流的关闭if(fr != null){ try{ fr.close();} catch (IOException e){ e.printStackTrace(); } }} 从内存中写出数据到硬盘的文件里：FileWriter例子：将hello.txt内容读入到程序中，并写入到hello1.txt中。 输出操作时，对应的File可以不存在。如果不存在，会自动创建文件；如果存在，调整构造器FileWriter(file, true/false)，决定是否向原文件中追加内容，即false为覆盖原文件； FileInputStream和FileOutputStream实现原理与FileReader和FileWriter同理； 字符流不能处理图片这种字节数据；字节流处理文本文件有时候会出现乱码。因此，通常，对于文本文件（.txt, .java, .c, …），使用字符流处理，对于非文本文件（.jpg, .mp3, .avi, .doc, …），使用字节流处理； 12345678910111213141516171819202122232425262728293031323334//由于会有异常，finally中一定会运行，因此需要先定义FileReader和FileWriter的对象FileReader fr = null;FileWriter fw = nulltry{//1.实例化File对象，指明读入和写出到的文件File srcfile = new File(&quot;hello.txt&quot;);File destfile = new File(&quot;hello1.txt&quot;);//2.提供具体的流fr = new FileReader(file) ;fw = new FileWriter(file) ;//3.读入和写出操作char[] cbuf = new char[5]; // 一次五个int len;while((len = fr.read(cbuf)) != -1){ //每次写多个字符 fw.write(cbuf, 0, len) }}catch (IOException e){ e.printStackTrace();} finally{//4.流的关闭if(fr != null){try{ fr.close();} catch (IOException e){ e.printStackTrace();}}if(fw != null){try{ fw.close();} catch (IOException e){ e.printStackTrace();}}} 处理流之一：缓冲流处理流均为 在节点流之外包裹的一个流，用于对节点流进行优化操作。 缓冲流的作用：提高流的读取、写入的速度。 主要包括：BufferedInputStream; BufferedOutputStream; BufferedReader; BufferedWriter 任务：添加缓冲层后实现非文本文件的复制 1234567891011121314151617181920212223242526272829303132333435363738394041424344BufferedInputStream bis = null;BufferedOutputStream bos = null;try{//1.实例化File对象，指明读入和写出到的文件File srcfile = new File(&quot;爱情与友情.jpg&quot;);File destfile = new File(&quot;爱情与友情1.txt&quot;);//2.提供具体的流//2.1 造节点流（文件流）FileInputStream fis = new FileInputStream(srcfile);FileOutputStream fos = new FileOutputStream(destfile);//2.2 造缓冲流bis = new BufferedInputStream(fis) ;bos = new BufferedOutputStream(fos) ;//3.读入和写出操作byte[] buffer = new byte[5]; // 一次五个int len;while((len = bis.read(buffer)) != -1){//每次写多个字符bis.write(buffer, 0, len);}}catch (IOException e){ e.printStackTrace();} finally{//4.流的关闭 关闭缓冲流即可，因为会自动关闭内层的文件流if(bis != null){try{ bis.close();} catch (IOException e){ e.printStackTrace();}}if(bos != null){try{ bos.close();} catch (IOException e){ e.printStackTrace();}}}//注意：对于BufferedReader，有一个新的方法：readLine，用于读取数据，就不用定义char[]数组了。//使用方法：String data;while(data = br.readLine() != null){ //每次写一行文本 bw.write(data); // data中不包含换行符 bw.newLine(); //新建一行} 处理流之二：转换流转换流：属于字符流。包含： InputStreamReader：将一个字节的输入流转换为字符的输入流； OutputStreamWriter ：将一个字符的输出流转换为字节的输出流 作用：提供字符流和字节流之间的转换。 解码：字节、字节数组 –&gt; 字符数组、字符串； 编码：字符数组、字符串 –&gt; 字节、字节数组。 例子： 解决任务：如将UTF-8格式的txt文件复制，并转换为jbc格式的新的txt文件输出。（将字节转换成字符流的方式，读取和写入txt文件，最终又以字节流保存）（因为之前提到过，字节流读取文本数据会出现乱码） 解决方法：1.实例化File；2.造节点流（字符节点流）；3.造转换流：读为InputStreamReader，写为OutputStreamWriter；4.关闭流，关闭外层即可。 处理流之三：对象流对象流用于存储和读取基本数据类型数据或对象的处理流。它的强大之处就是可以把java中的对象写入到数据源中，也能把对象从数据源中还原出来。 主要包括的类有：ObjectInputStream和ObjectOutputStream 序列化：用ObjectOutputStream类保存基本类型数据或对象的机制； 反序列化：用ObjectInputStream类读取基本类型数据或对象的机制； ObjectInputStream和ObjectOutputStream不能序列化static和transient修饰的成员变量。 对象的序列化： 对象序列化机制允许把内存中的Java对象转换成平台无关的二进制流，从而允许把这种二进制流持久地保存在磁盘上，或通过网络将这种二进制流传输到另一个网络节点。当其它程序获取了这种二进制流，就可以恢复成原来的Java对象； 序列化的好处在于可将任何实现了Serializable接口的对象转化为字节数据，使其在保存和传输时可被还原； 序列化是RMI (Remote Method Invoke-远程方法调用）过程的参数和返回值都必须实现的机制，而RM是JavaEE的基础。因此序列化机制是JavaEE平台的基础； 如果需要让某个对象支持序列化机制，则必须让对象所属的类及其属性是可序列化的，为了让某个类是可序列化的，该类必须实现如下两个接口之一（Serializable，Externalizable）。否则，会抛出NotSerializableException异常。","link":"/2023/01/14/java%E5%9F%BA%E7%A1%80%E5%85%AD/"},{"title":"java基础（四）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的高级特性（上），包括java多线程，java常用类，枚举类与注解等，java的常用类中主要介绍String类。 java多线程创建多线程方式一：继承于Thread类 创建一个继承于Thread类的子类； 重写Thread类的run() –&gt;将此线程执行的操作声明在run()中； 创建Thread类的子类的对象；（可创建多个） 通过此对象调用start()：①启动当前线程；②调用当前线程的run()方法 则start后面的程序为主线程，run中运行的程序为子线程，二者同时运行。 Thread中的常用方法: start()：启动当前线程；调用当前线程的run()； run()：通常需要重写Thread类中的此方法，将创建的线程要执行的操作声明在此方法； currentThread()：静态方法，返回执行当前代码的线程； getName()：获取当前线程的名字； setName()：设置当前线程的名字； yield()：释放当前cpu的执行权； join()：在线程a中调用线程b的join()，此时线程a就进入阻塞状态，直到线程b完全执行完以后，线程a才结束阻塞状态； stop()：已过时。当执行此方法时，强制结束当前线程； sleep(long millitime)：让当前线程”睡眠”指定的millitime毫秒。在指定的millitime毫秒时间内，当前线程是阻塞状态； isALive()：判断当前线程是否存活。 getPriority()：获取线程的优先级 setPriority()：设置线程的优先级 注意：高优先级的线程会抢占低优先级的线程的cpu，但不是高优先级的线程先执行，再执行低优先级的线程；而只是一个概率问题。 方式二：实现Runnable接口 创建一个实现了Runnable接口的类； class Windows implements Runnable 实现类去实现Runnable中的抽象方法: run()； 创建实现类的对象； Windows w= new Windows() 将此对象作为参数传递到Thread类的构造器中，创建Thread类的对象；（可创建多个） 如：Thread t1 = new Thread(w); Thread t2 = new Thread(w)… 通过Thread类的对象调用start()：①启动线程；②调用当前线程的run()–&gt;调用了Runnable类型的target的run()，也就是自己写的run() 。 t1.start(); t2.start()… 优先使用方式二，原因： 实现的方式没有类的单继承的局限性； 实现的方式更适合来处理多个线程共享数据的情况。使用方法一需要使用static 方法三：采用Callable接口（jdk5新增方法） 创建一个实现Callable接口的实现类； 实现call方法，将此线程需要执行的操作声明在call()中；—可以有返回值 创建Callable接口实现类的对象； NumThread numThread = new NumThread() 将此Callable接口实现类的对象作为参数传递到FutureTask构造器中，创建FutureTask的对象； FutureTask futureTask = new FutureTask(numThread) 将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象，并调用start()，启动线程； new Thread(futureTask).start() 获取Callable中call方法的返回值，采用get获取。 Object sum = futureTask.get() 方法四：采用线程池（jdk5新增方法）提前创建好多个线程，放入线程池中，使用时直接获取。 线程的生命周期： 线程的安全问题当一个线程未操作完时，其它线程参与进来，进行相同的操作。如：一个线程操作车票过程中，还没有操作完成，票没有卖出去，其它线程参与了进来，也操作了车票，会出现重票、错票的情况。 解决方法：一个线程a操作时，其它线程不能参与进来，直至其操作完成。这种情况即使线程a出现了阻塞，也不能被改变。java中，通过同步机制，来解决线程的安全问题。 方法一：同步代码块synchronized(同步监视器){ ​ //需要被同步的代码 } 说明：1. 操作共享数据的代码，即为需要被同步的代码； ​ 2. 共享数据：多个线程共同操作的变量。比如：票ticket就是共享数据； ​ 3. 同步监视器，俗称：锁。任何一个类的对象，都可以充当锁。其中，方法一(Thread)中可用类，方法二(Runnable)中可用this。也都可以自己创建。 要求：多个线程必须要共用同一把锁。 方法二：同步方法 使用方法：方法声明前加一个synchronized，如public synchronized void show() 同步方法也需要同步监视器，只是不需要显示声明； 非静态的同步方法，其同步监视器是this； 静态的同步方法，其同步监视器是其类本身 同步的方式，解决了线程的安全问题。但同步的代码块运行时，只能有一个线程参与，其余线程等待，因此效率低。 方法三：Lock锁需要手动启动锁（启动同步 lock()）和手动关闭锁（关闭同步unlock()） java常用类String类的介绍 代表字符串，使用一对””引起来表示，代表不可变的字符序列； ​ 体现：1.当对字符串重新赋值时，需要重写指定内存区域赋值，不能使用原有的value进行赋值；2.对字符串进行拼接或字符替换时，也会重新指定内存区域赋值，不能使用原有区域添加； String对象的字符内容是存储在一个字符数组value[]中的； final char[] value 可以比大小，支持序列化； 通过字面量的方式（区别于new）给一个字符串赋值，此时的字符串声明在字符串常量池中，字符串常量池不会存储相同的字符串； String s1 = “javaEE” 若采用new+构造器的方式给字符串赋值，则字符串声明在堆中，地址就会有区别了。 String s2 = new String(“javaEE”) 注意：常量和常量的拼接在常量池，但凡有一个是变量，则拼接结果在堆中。 字符串的常用方法： 注意：1. 原字符串不可变，只是添加了新的字符串 ​ 2. char值序列就可以理解为字符串 String字符串转化为基本数据类型/包装类：调用包装类的静态方法：parseXxx(str) 如：String str1 = “123” int num = Integer.parseInt(str1) //123 基本数据类型/包装类转化为String字符串：调用String重载的valueOf(xxx) 如：int num = 123 String str2 = String.valueOf(num2) //“123” String字符串转化为char[]：采用toCharArray()；反过来，调用直接调用String的构造器即可 如： String str3 = “abc123” Char[] charArray = str3.toCharArray(); // {‘a’, ‘b’, ‘c’, ‘1’, ‘2’, ‘3’} String str4 = new String(charArray) // “abc123” StringBuffer与StringBuilderStringBuffer：可变的字符序列；线程安全的，效率低；底层使用char[]存储 StringBuilder：可变的字符序列；线程不安全的，效率高；底层使用char[]存储 注意：可变和不可变只的是空间中是否创建新的地址存放变化后的字符串。可变表示不用重新创建，在原来地址处进行修改即可。主要体现为：char[]是否用final修饰 源码分析： String str = new String(); //char[] value = new char[0]; String str1 = new String(“abc”); //char[] value = new char[]{‘a’, ‘b’, ‘c’}; StringBuffer sb1 = new StringBuffer(); //char value = new char[16]; 底层创建了一个长度为16的char型数组 StringBuffer sb1 = new StringBuffer(“abc”); //char value = new char[“abc”.length()+16] StringBuffer的常用方法： 开发中建议使用StringBuffer和 StringBuilder，采用new StringBuffer(capacity)进行定义 此外常用类还有System类、Math类等等。 枚举类与注解 类的对象只有有限个、确定的，这样的类叫做枚举类。 当需要定义一组常量时，强烈建议使用枚举类。 使用enum定义枚举类： enum Season() 提供当前枚举类的对象，多个对象之间用”,”隔开，末尾对象用”;”结束； SPRING(“春天”), SUMMER(“夏天”); 声明对象的属性，用private final 修饰； private final String seasonName; 私有化类的构造器，并给对象属性赋值； private Season(String seasonName){…} 测试类调用时，直接采用类名.对象名调用。 Season summer = Season.SUMMER 注意：1.定义类：enum+类名，没有class； ​ 2.enum定义的枚举类自动继承了java.lang.enum类，如重写了toString方法，直接打印对象名 注解：Annotation Annotation其实就是代码里的特殊标记，这些标记可以在编译，类加载，运行时被读取，并执行相应的处理； Annotation可以像修饰符一样被使用，可用于修饰包，类，构造器，方法，成员变量，参数，局部变量的声明，这些信息保存在Annotation的”name=value”对中。 如@Override","link":"/2023/01/14/java%E5%9F%BA%E7%A1%80%E5%9B%9B/"},{"title":"元学习","text":"本篇文章讲解了机器学习中的元学习相关内容。首先讲解了元学习的概念和大致的算法流程，之后具体介绍了三种不同的元学习方法，包括MAML，Reptile，FOMAML。 元学习概念Meta Learning: Meta Learning 被称作元学习，不同于Machine Learning，Machine Learning的目标是让机器能够学习，Meta Learning则是要让机器学会如何去学习。 对于一般的机器学习流程，首先将原始数据分为两类(train_test_spilt)，为训练数据和测试数据，通过将训练数据代入到此学习算法F中，得到一个生成的函数f，之后利用测试数据来对此函数进行测试，并得到相应的损失值l。如果效果达标就证明机器学到了该特定任务的实现函数。 其中，传统的机器学习算法是由人来人为制定学习算法F，而Meta Learning则是机器自己生成。得到的L(F)为损失函数，为各个任务通过测试得到的损失值的和，通过损失函数可以判断此F的好坏。 具体算法首先有一个初始参数parameter，随训练数据一起代入到梯度计算中，得到此参数的更新值，循环往复，得到最后的数据θ。 损失函数定义完毕后，我们该如何降低F的损失呢？由于Meta Learning的求解是非常复杂的过程，我们先以MAML算法为例讲解一个Meta Learning的简单情况的求解。 MAML算法想要解决的问题是，对于F在每一个任务中学习到的f，规定f只负责决定参数的赋值方式，而不设计模型的架构，也不改变参数更新的方式。也就是说，MAML中的f的网络结构和更新方式都是提前固定的，MAML要解决的是如何针对不同任务为网络赋不同的初始值。 MAML在意的是用Ф训练出的θn的表现如何；而Model-training则是在意在所有task中均有最佳loss的初始值Ф。 此外对于Reptile，对应生成初始参数Ф的方向为，由初始值到多次训练得到最后的θn的方向。 实例一(MAML)概念通过大量的学习任务来得到一个模型，当出现一小批新任务时，能够对模型进行微调，并快速学习。基本思想：训练模型的初始参数，以便在通过一个或多个梯度步骤更新参数后，该模型在新任务上具有最佳性能，而该梯度步骤是根据该新任务中的少量数据计算得出的。 从此图可以看出，MAML的目标是找到对任务(task)的变化敏感的模型参数(model parameters)，这样，当损失梯度(loss gradient)的方向改变时，参数的微小变化将对从所有任务分布 p(T) 提取的任何一个任务(task)的损失函数(loss function)产生较大的改善。即可以使用新任务(new task)上少量的样本fine tune模型后得到新的模型参数(model parameters, θ)对新任务检测的性能有很大的提升。 算法过程 1、第一个Require的 p(T) 指的是meta-train中tasks的分布；第二个Require中的 α 和 β 指的是步长(step size)，也可以理解为学习率(learning rate). MAML的模型训练过程是gradient by gradient，即MAML是基于二级梯度的，每次迭代包含两次的参数更新的过程，分别对应两个学习率 α 和 β。2、步骤1：随机初始化模型的参数。3、步骤2：是一个外循坏。每次迭代可以理解为一个epoch，每个epoch训练多个任务中的若干个任务。预训练过程有多个任务，也就对应多个epoch。（循环变量：时期（mata batch）。存在这多个时期，每一个时期中有多个任务。）4、步骤3：随机对若干个(meta size)任务进行采样，形成一个meta batch训练数据。5、步骤4：这是一个内循环。利用meta batch中的每一个任务Ti，分别对模型的参数进行更新（比如4个任务更新4次参数）。（循环变量：任务(Ti)。在某一个具体时期中，有多个任务，分别对这些任务进行参数更新）6、步骤5：在N-way K-shot（N-way指训练数据中有N个类别class，K-shot指每个类别下有K个被标记数据）的设置下，利用meta batch中的某个task中的support set（任务中少量中有标签的数据，可以理解为训练集training set）的N*K个样本计算每个参数的梯度。7、步骤6：第一次梯度的更新的过程。针对Meta batch的每个任务Ti更新一次参数得到新的模型参数θi，这些新模型参数会被临时保存，用来接下的第二次梯度计算，但其并不是真正用来更来更新模型。8、步骤7：内循环结束。9、步骤8：第二次梯度更新的过程。这个是计算一个query set（另一部分有标签的数据，可以理解为验证集validation set，用来验证模型的泛化能力）中的5-wayV（V是一个变量，一般等于K，也可以自定义为其他参数比如15）个样本的损失loss，然后更新meta模型的参数，这次模型参数更新是一个真正的更新，更新后的模型参数在该次meta batch结束后回到步骤3用来进行下一次mata batch的计算。10、步骤9：外循环结束。 两个种类：（1）Regression：小样本监督学习（2）RL：强化学习区别：RL需要从任务对应的环境中采样 实例二(Reptile)一阶的基于梯度的元学习算法。 基本思想：通过重复采样任务，对其进行训练并将初始化朝着该任务的训练权重进行工作。 对应参数的更新方向：由初始值到多次训练得到最后的θn的方向。 具体算法步骤： 1、初始化参数 2、开始循环迭代i =0,1,2… 3、采样一个meta batch,每个batch内有多个任务task 4、对于每一个task，根据迭代次数k采样出含k个batch的minibatch, 5、对minibatch内的每一个batch使用梯度下降法更新初始化参数，得到Ψ’ 6、将每个task更新后的参数Ψ’与初始参数Ψ相减，将这个相减的结果经过某个映射（将这个差值看做某个梯度，加入到某种自适应的算法中）。在我们的实现中一般是（Ψ’-Ψ）/a，这个a我们一般设置为一个可以变的值。 这一步可以理解为： （Ψi~表示第i个任务上对Ti的更新操作。） 7、回到2，继续，直到循环结束。 当k=1时，算法对应于期望损失的随机梯度下降（SGD） 当k&gt;1时，算法包含了LT更高阶的微分项 Reptile的核心代码： Reptile有效的原因： 1、通过用泰勒级数近似表示更新过程，发现SGD自动给出了与MAML计算的二阶项相同的项。这一项调整初始权重，以最大限度地增加同一任务中不同小批量梯度之间的点积，从而增大模型的泛化能力。 2、Reptile通过利用多次梯度更新，找到了一个接近所有最优解流形的点。 当执行SGD更新时，MAML形式的更新过程就已经被自动包含在其中了，通过最大化模型在不同批次数据之间的泛化能力，从而使得模型在微调（fine-tune）时能取得显著的效果。 实例三(FOMAML)忽略了MAML中的二阶微分项，节省了计算开销，但损失了部分梯度信息 具体步骤： 将梯度向量视为常量，即可将雅可比矩阵转化为恒等操作，所以可以简化外循环优化过程中所使用的梯度公式。 具体流程如下： 1、采样任务T； 2、对初始化参数执行更新操作，得到ϕ~; 3、利用ϕ~计算对ϕ的梯度，得到gFOMAML; 4、将gFOMAML应用到外部循环优化中。 Reptile和FOMAML在内循环过程中都是使用的SGD进行的优化，在这个优化过程中任何微小的变化都将导致最终模型性能的巨大变化，两者对于内循环中的超参数都有很强的敏感性，FOMAML在minibatch以错误的方式选取时会出现显著的性能下降情况。","link":"/2022/12/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"title":"python常用方法","text":"本篇文章讲解了python中各个数据结构的常用方法与实现。包括：列表list，字符串，链表，队列，栈，树，堆等。 list的常用方法1.对List进行翻转：list(reverse(List))；# reversed也行，reversed是python自带，reverse是List特有，不过返回的都是迭代器 2.对List进行排序：List.sort(reverse = True)，reverse = True代表降序，默认为升序 3.插入元素：List.append() 4.插入列表：List.extend() 5.获取指定元素m的下标：List.index(m) 6.List的切割：list无法直接切割，如List[a:b][c:d]是不行的，只有numpy数组可以 但一维list可以直接切割，如List[: a] 7.读取List某一行：List[a]，不是List[a, :] 读取List某一列：[x[a] for x in List]，而不是List[:, a] 8.定义一个a*b的全零列表: s = [[0 for j in range(b)] for i in range(a)] 定义二维空列表: s=[][] 要先插入后赋值 9.list元素的删除：①list.remove(a) 删除第一个a；②list.pop(index) 删除并返回序列为index的元素，常用于栈、队列中；③切片 实际上上面说的List都是数组，数组和列表的最大区别是：数组具有索引，且数组中的数据是连续存储的。 字符串的常用方法1.字符串遍历：for i in range(Str): Str[i] // for eachstr in Str: eachstr 2.返回字符串中某一字符s的索引值：Str.index(s) 3.字符串中字符的替换：Str.replace(old, new, count)，count表示替换次数，若没有则表示全部替换 4.字符串的分割：Str.split(s). 将字符串Str沿字符s进行切割，并返回各部分组成的数组 5.字符串的拼接：Str = Str1 + Str2 + Str3 6.字符串的翻转：’’.join(reversed(Str)); 列表合并为字符串’’.join(Str) 7.计算一个字符串中间某个字符出现的次数: Str1.count(s) 8.大小写转化：.lower()；.upper() 9.字符串的查找：Str.find(s, begin, end) (从Str中查找s，begin end为开始和结束的下标) 10.字符串的删除：①Str.strip(s）从str中删除s的所有符号； ②删除固定位置字符：切片操作s’=Str[0:3]+Str[4:] 删除Str中第三个位置 ③删除字符串中的某一种字符：替换操作Str.replace(s, ‘’) 链表的常用方法1.单链表插入新节点： class Node: # constructor def init(self, data, next=None): ​ self.data = data；self.next = next # 插在开头 dummy = Node(0)；dummy.next = head；head = dumy；return head # 插在中间 dummy = Node(0)；dummy.next = prev.next；prev.next = dummy # 插在末尾 dummy = Node(0) while head.next: head = head.next head.next = dummy；dummy.next = None 2.单链表删除结点时，可以先找到要删除结点的上一个结点node，node.next = node.next.next，同时还不用考虑删除最后一个结点的情况，因为右边为None 3.双链表基本方法：查找、插入、删除，见Leetcode707.设计链表 https://leetcode.cn/problems/design-linked-list/ 记住，链表可以直接用头结点来表示，返回头结点就等于返回了整个链表； 记住，一旦一个节点的next指向了None，就不能直接对这个None赋值了，而是要让该节点的next指向一个新的值 队列的常用方法队列(先进先出FIFO) python实现队列： import collections q = collections.deque()// q=list() 一般情况下用list就行了，deque是双端队列 q.append(element); q.popleft() // q.pop(0) 一定要加上0，因为list的地址是固定的 注：list没有empty()方法 栈的常用方法栈(后进先出LIFO) python实现栈： import collections q = collections.deque() // q=list() 一般情况下用list就行了 q.append(element); q.pop() # pop会返回取出元素 树的常用方法树的遍历 前序遍历[https://leetcode.cn/leetbook/read/data-structure-binary-tree/xeywh5/]： 递归： 非递归： 中序遍历：[https://leetcode.cn/leetbook/read/data-structure-binary-tree/xecaj6/] 后序遍历：[https://leetcode.cn/leetbook/read/data-structure-binary-tree/xebrb2/] 总结一下：三种遍历的中心思想是一致的，若采取非递归的方法，都需要创建一个栈。然后都是先按左子树找到最左边的叶子结点，并依次入栈，之后进行出栈并遍历右子树。对于后序遍历，出栈需要进行条件判定：右子树为空或已经遍历，才能出栈，因此需要设定标志位。 层序遍历：[https://leetcode.cn/leetbook/read/data-structure-binary-tree/xefh1i/] 注意，与链表相似，树的根节点可以代表整棵树，对根节点采用left和right属性就可以调用各个节点。在leetcode中，返回根节点等于返回了整棵树，但是不要忘了，它本质上还是一个节点。 堆的常用方法python中的优先队列都是从小到大排列的（即最小根堆），主要方法有： q = list() 1.heapq.heapify(q) 列表转化为堆 2.heapq.heappush(q, (value,key)) 将m放入堆中—O(logn) 3.heapq.heappop(q) 弹出并返回堆顶元素，即最小值 排序方法：按value大小排序","link":"/2022/12/22/python%E6%96%B9%E6%B3%95/"},{"title":"机器学习优化方法讲解","text":"本篇文章讲解了机器学习中的优化方法。包括梯度下降算法及其优化算法等。 1）梯度下降算法： ①BGD(Batch gradient descent)： 采用整个训练集的数据来进行梯度的计算，对于凸函数可以收敛到全局最小值，非凸函数可以收敛到局部最小值。 优点：梯度是在全部数据集上计算出的，因此每次迭代都是向着整体的最优化方向 缺点：计算量大，速度慢； ​ 容易陷入极小值点，因为在极小值点（鞍点）梯度为0，所以参数不会更新。 ②SGD(Stochastic gradient descent)： 和BGD 的一次用所有数据计算梯度相比，SGD 每次更新时随机选择一个样本进行梯度更新，一次只进行一次更新。 优点：速度快，并且可以新增样本； ​ SGD 可能会跳到更好的局部极小值处，因为极小值时，梯度是随机选择的一个样本，这个梯度未必是0。 缺点：SGD不是每次迭代都向着整体最优化方向，准确度下降，不是全局最优； ​ SGD 因为更新比较频繁，会造成 cost function 有严重的震荡。 ③Mini-batch gradient descent： 将二者综合，每一次参数更新时使用样本中的一小部分（使用一小批数据进行更新）。 缺点：不能保证很好的收敛性。学习率太小收敛慢，太大会在极小值附近震荡。 ​ batch-size大小难以选择。 2）梯度下降算法的优化：①动量梯度下降算法(Momentum)： 梯度不仅与当前梯度有关，还与之前的梯度有关，这样参数更新的方向会朝向更加有利于收敛的方向（有利于减小震荡），收敛速度更快。对于动量梯度下降算法，当前时刻的梯度是 从开始时刻到当前时刻的梯度指数加权平均。 其中动量参数通常取0.9左右。 优点：增加收敛稳定性，减小震荡，收敛速度更快 缺点：所有特征用同一种学习率，无法进行学习率自适应调节，如对于稀疏特征更希望大一点的学习率； ②自适应梯度算法Adagrad(Adaptive gradient algorithm): Adagrad可以对低频的参数做较大的更新，对高频的做较小的更新，对于稀疏的数据它的表现很好，很好地提高了 SGD 的鲁棒性。Adagrad优化算法就是在每次使用一个 batch size 的数据进行参数更新的时候，算法计算所有参数的梯度，那么其想法就是对于每个参数，初始化一个变量 s 为 0，然后每次将该参数的梯度平方求和累加到这个变量 s 上，然后在更新这个参数的时候，学习率就变为： Adagrad 的核心想法是：如果一个参数的梯度一直都非常大，那么其对应的学习率就变小一点，防止震荡，而一个参数的梯度一直都非常小，那么这个参数的学习率就变大一点，使得其能够更快地更新，这就是Adagrad算法加快深层神经网络的训练速度的核心。 ③均方根传递算法RMSProp(Root Mean Square Prop)： RMSprop 是为了解决 Adagrad 学习率急剧下降的问题。RMS使用的是指数加权平均，旨在消除梯度下降中的摆动，与Momentum的效果一样，某一维度的导数比较大，则指数加权平均就大，某一维度的导数比较小，则其指数加权平均就小，这样就保证了各维度导数都在一个量级，进而减少了摆动。 建议η=0.001，β=0.9. ④ADAM(Adaptive Moment Estimation)： Adam不仅存储了过去梯度的平方的指数衰减平均值，还像Momentum一样保持了过去提取的指数衰减平均值。 如果 mt 和 vt 被初始化为 0 向量，那它们就会向 0 偏置，所以做了偏差校正，通过计算偏差校正后的 mt 和 vt 来抵消这些偏差： 梯度更新规则: 超参数设定：建议β1 ＝ 0.9，β2 ＝ 0.999，ϵ ＝ 10e−8。","link":"/2022/12/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/"},{"title":"机器学习-成员推断攻击","text":"本篇文章讲解了机器学习中的成员推断攻击（Membership Inference Attack, MIA），成员推断攻击是指：给定一个数据记录，攻击者需要判断该数据记录是否存在于目标模型的训练数据集中。本文将依次讲解：成员推断攻击的分类，白盒成员推断攻击，黑盒成员推断攻击，以及数据模型泄露的结论。 成员推断攻击的分类1.按攻击者的观察方式分为白盒和黑盒攻击： ​ 其中，黑盒攻击者无法访问参数和计算过程，但给定输入可以观测到输出值；白盒攻击时，这些中间结果对于攻击者来说是可得的。除此之外，模型的参数和结构对于攻击者来说也是可见的。 2.按攻击者的目标分，目标可以是独立学习和联邦学习： ​ 其中，独立学习时，攻击者可以观测到微调前后的模型情况；联邦学习时，攻击者可以作为中心服务器或者参与者进行观测。 3.按攻击者的攻击模式分为主动攻击和被动攻击： ​ 推理攻击大多数为被动攻击，即对手在不改变学习过程的情况下进行观察；而主动攻击中，参与训练过程的对手可以主动影响目标模型，以提取有关其训练集的更多信息。 4.按先验知识分为监督和非监督学习攻击： ​ 若对手的数据集D’与目标数据集D重叠。给定该数据集，他可以以监督的方式训练攻击模型，并用其攻击其余的训练数据集。而非监督攻击时，攻击者可以访问与目标训练集D部分重叠的数据集D’，但是，对手不知道D’∩D中的数据点。 白盒成员推断攻击这里白盒成员推断攻击的讲解以《Comprehensive Privacy Analysis of Deep Learning》论文为例，并应用于了联邦学习的环境中。其白盒攻击结构为： ​ 其中，攻击者知道目标模型的训练数据(x,y)和模型的参数信息W，模型f，并可以计算得到隐藏层h、模型输出f(x)和损失值L。将这些信息作为攻击模型的输入，经过卷积神经网络和全连接网络等形式，计算得出相应的攻击输出值，并获得成员信息。若为非监督模式，则还需要结合译码过程，得到最终的模型。 ​ 成员推理攻击的目的：判断某个数据记录是否属于目标的训练集。 ​ 联邦学习的详细解释：拥有不同训练集Di的N个参与者就单个深度学习任务和模型架构达成共识，以训练全局模型。 中央服务器为全局模型保留参数W的最新版本。 每个参与者具有局部模型，因此具有局部参数Wi。 在培训的每个时期，每个参与者都下载全局参数，使用SGD算法在其本地培训数据上对其进行本地更新，然后将其上传回服务器。参数服务器使用所有参与者上载的参数来计算每个参数的平均值。这种协作式培训一直持续到全局模型收敛为止。 黑盒成员推断攻击对于黑盒成员推断攻击，攻击者不知道目标模型的结构。这里以论文《Membership Inference Attacks Against Machine Learning Models》为例，这是第一篇有关成员推断攻击的文章，主要思想是借助一个与目标模型类似的模型（影子模型），来实现成员推断攻击。 攻击条件与判定：给予攻击者数据记录和对目标模型的黑匣子查询访问权限。如果攻击者可以正确确定此数据记录是否属于模型的训练数据集，则攻击成功。攻击准确性的标准度量标准是精度（由成员推断出的记录的确确实是训练数据集的成员）和召回率（由攻击者正确推断出训练数据集的成员的几率）。 黑盒设置中的成员资格推断攻击。攻击者使用数据记录查询目标模型并获得对该记录的模型预测。预测是记录属于某个类的概率向量(每类一个)。该预测向量与目标记录的标签一起传递到攻击模型，攻击模型会推断记录是在目标模型的训练数据集中还是不在目标模型的训练数据集中。 攻击者的目的：构建一个攻击模型，该模型可以识别目标模型行为中的此类差异，并仅根据目标模型的输出，使用它们来区分目标模型训练数据集的成员与非成员。 需要通过影子模型来构建攻击模型： ​ 借助影子模型来生成攻击模型的训练数据集(下图中的Attack Training Set)，进而生成攻击模型。推断影子模型的训练数据集中的成员资格，会生成一个攻击模型，该攻击模型也可以成功地推断目标模型的训练数据集中的成员资格。 ​ 使用与用于训练目标模型相同的机器学习平台来训练影子模型。目标模型和阴影模型的训练数据集具有相同的格式，但不相交。阴影模型的训练数据集可能会重叠。所有模型的内部参数均经过独立训练。 ​ 虽然目标模型的类型和结构是未知的，但是攻击者知道训练目标模型相关的服务信息，可以使用与用于训练目标模型的服务完全相同的服务，例如GooglePrediction API来训练影子模型，来做到二者模型平台类似，训练数据集格式类似。 影子模型的数据从何而来(上图中的Training Set and Test Set)： ​ ①如果攻击者没有真实的训练数据，也没有关于其分布的任何统计信息，他可以使用目标模型本身为阴影模型生成合成训练数据(借助具体算法，详见论文Ⅴ.C) ​ ②攻击者具有一些有关从中提取目标模型的训练数据的统计信息(如不同特征的边际分布的先验知识)。 在我们的实验中，我们通过从每个特征的边际分布中独立采样每个值的值来生成阴影模型的综合训练记录。 ​ ③攻击者可能会访问一些与目标模型的训练数据相似的数据，并被视为“嘈杂”版本。 在我们使用位置数据集的实验中，我们通过翻转10％或20％随机选择的特征的（二进制）值，然后在产生的噪声数据集上训练阴影模型，来模拟此情况。 模型数据泄露的结论①模型的类越多，任务越多，泄露的信息就越多。 ②每个类的训练数据量与成员推断准确性之间的关系：这种关系更加复杂，通常，训练数据集中与给定类别关联的数据越多，该类别的攻击精度越低。 ③较早的训练时期包含数据集的一般特征的信息，不会泄漏重要的隶属信息，但是，随着模型开始学习此类时期中的离群值，较晚的时期包含更多的隶属信息，因此使用训练了一段时间后的模型攻击效率更高。 ④与层输出相比，梯度泄漏的训练集成员信息更多。","link":"/2022/12/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%88%90%E5%91%98%E6%8E%A8%E6%96%AD%E6%94%BB%E5%87%BB/"},{"title":"编程注意事项","text":"本篇文章讲解了python中的一些编程注意事项，主要涉及到python的一些基本语法和机器学习有关知识的实现，还在更新中。 1.x为torch.tensor，M为模型，M(x)为模型输出，假设模型输出标签为m： y1=M(x).argmax(-1)，则y1=tensor([m])，y1.shape=torch.size([1]); y2=torch.argmax(M(x), -1)，则y2=tensor([m])，y2.shape=torch.size([1]); y3=torch.argmax(M(x))，则y3=tensor(m)，y3.shape=torch.size([])。 2.各个数据类型的相互转化： torch.tensor转numpy：a.numpy() numpy转torch.tensor：torch.from_numpy (a) numpy转tf.tensor：tf.convert_to_tensor(a) tf.tensor转numpy：a.eval() 3.模型和学习率的保存： ①先建立一个字典，保存四个参数：（有scheduler动态变化才需要保存scheduler） state = {‘net’:model.state_dict(), ‘optimizer’:optimizer.state_dict(), ‘epoch’:epoch, ‘scheduler’:scheduler.state_dict()} ②调用torch.save(): torch.save(state, dir) 其中dir表示保存文件的绝对路径+保存文件名，如’/home/qinying/Desktop/modelpara.pth’ ③当你想恢复某一阶段的训练（或者进行测试）时，那么就可以读取之前保存的网络模型参数等。 checkpoint = torch.load(dir) model.load_state_dict(checkpoint[‘net’]) optimizer.load_state_dict(checkpoint[‘optimizer’]) start_epoch = checkpoint[‘epoch’] + 1 scheduler.load_state_dict(checkpoint[‘scheduler’]) 4.随机数种子设置，保证每次运行结果相同： random.seed(args.seed) np.random.seed(args.seed) torch.manual_seed(args.seed)","link":"/2022/12/25/%E7%BC%96%E7%A8%8B%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"title":"联邦学习（三）","text":"本篇文章为联邦学习系列的第三篇。主要讲解机器学习中的一个新型方向——联邦学习（Federated Learning, FL）。联邦学习是一种新的机器学习框架，在满足隐私保护和数据安全的同时，使数据拥有方能够共同拥有和交换数据，搭建一个更加稳定、高效的系统。本文继续介绍纵向联邦学习（Vertical Federated Learning, VFL）的相关知识，继续讲解隐私保护问题，本文章以分析论文的方式进行介绍。 论文5：真实场景的VFL隐私泄露论文“Privacy Leakage of Real-World Vertical Federated Learning” CoRR 2021 针对真实场景（真实安全计算框架），提出了两种不同的攻击方式，评估了VFL的隐私泄露。 In this paper, we provide the first systematic study on the potential privacy risk of practical learning protocols in vertical federated learning. Specially, our work seeks to answer the crucial research question: How much is the privacy risks of the practical learning protocols for computing participates whose data is used as part of the training set? In other words, how much is the privacy leakage of the learning protocol about the participants’ training data? 提出的攻击方法：reverse multiplication attack（反向乘法攻击）and reverse sum attack（反向和攻击）。 场景：在论文3的基础上，加了一些真实的隐私保护措施和协议限制，大致还是相同，两个用户和一个中央服务器（也叫第三方协调器 third-party coordinator）。主要挑战：加密的中间输出和异质的训练数据。一方面，加密的中间输出使得参与者无法通过梯度更新直接推断私有数据，导致任何基于学习的攻击都不能工作。另一方面，由于参与者的训练数据是异质的，他们中没有人可以通过恶意查询推断其它用户的私有数据。 攻击者信息：其中的一个参与者被攻击者控制，攻击者可以发送或接收该参与者训练数据的静态结果（如梯度信息或梯度与数据的乘法结果…）对应的加密信息，通常攻击者可以恶意控制该用户的局部训练过程。攻击者不会破坏协议规则，但希望从协议中收集尽可能多的私人信息。如在reverse multiplication attack中，攻击者可以构造特定的字符串，并将它们插入到梯度的最低有效位，同时保持学习协议不变；在reverse sum attack，攻击方还可能破坏第三方服务器，以从协议中获取更多隐私。 攻击者的目标：尽可能多地推断参与者的私人训练数据集。在reverse multiplication attack中，攻击者旨在推断目标参与者的原始训练数据；在reverse sum attack中，攻击者试图推断目标参与者训练数据的部分顺序。 具体实现内容好复杂，涉及到编码、解密这些，这里不多阐述。 论文6：第一个VFL对成员信息保密的框架 论文“Vertical Federated Learning without Revealing Intersection Membership” CORR2021 提出了VFL中第一个对成员信息保密的框架。 场景：与[2]中场景相同，但多强调了一点：VFL各个用户在开始训练本地模型之前，需要先进行样本ID的对齐，也就是确定各方共享的相同实体(定义为交集)。通常，这是通过私有集交集(PSI)协议实现的。然而，这个过程中会产生成员隐私的泄露，具体的，各参与方都能够看到相互重叠的数据ID。因此，这篇文章提出了PSU协议，并基于这一协议提出了新的VFL框架，来在保持模型肖泳的同时保护交集成员的隐私。这里主要拓展视野并了解威胁模型。 威胁模型：假设用户一个为active party Pa，数据集Da=(Ia, Xa, ya)一个为passive party Pp，数据集Dp=(Ip, Xp)，攻击者为其中之一，且honest-but-curious，攻击者的目标是找到交集ID。分为两种情况：①Pa为攻击者，Pa通过yid和Pp传递的特征值z进行攻击，找到id∈Ia∩Ip；②Pp为攻击者，Pp通过xid和Pa回传的梯度值g进行攻击，找到id∈Ia∩Ip。 原文参考：We assume malicious parties are honest-but-curious, i.e. Pa and Pp faithfully run the VFL protocol, but they may infer important information including raw sample data and intersection membership from the exchanged information. In particular, we consider two privacy leakage scenarios: 1) for id∈Ia, Pa finds out if id∈Ia∩Ip by checking yid and the embedding forwarded by Pp, and 2) for id∈Ip, Pp finds out if id∈Ia∩Ip by checking xid and the gradient sent back by Pa. 论文7：第一个VFL的数据恢复工作 论文“CAFE: Catastrophic data leakage in vertical federated learning” NeurPIS 2021 提出了一种VFL下的数据泄露攻击，能够有效的从共享梯度中恢复批数据，可用于大批量数据。(参与标准FL的私人数据，特别是VFL情况下，有很高的风险从训练梯度中泄露) 场景：作用于通用VFL场景，与论文3相同，一个active party(server)和多个passive party，server拥有标签信息，可以选定每一轮更新哪些id的数据。攻击者为server，通过全局模型的梯度泄露，控制id，恢复出每轮训练的数据。 攻击者信息：1) 全局模型的梯度信息(分为很多梯度信息，包括每一个批次损失函数的梯度、每一层损失函数的梯度、总损失函数的梯度，这个是server本身就能得到的)，2) 批次身份，即每轮全局训练指定每位用户参与训练的一个批次的数据量。(public shared gradients and batch identities)。注：θ 为全局模型的参数，θ­1 为全局模型第一个FC Layer的参数，b1 为第一个FC Layer的bias，D 为目标batch的全部训练数据。 攻击者的目标：分为三个步骤：1) 恢复第一个FC Layer输出的损失和梯度信息(借助)；2) 恢复第一个FC Layer的输入数据；3) 获取所有输入数据。具体如下图所示。左边为VFL的框架，右边为CAFE的框架。 CAFE的具体实现功能这里不再阐述，有很多复杂的推导。 CAFÉ的related works：即一些有关联邦学习中从客户端上传的梯度信息中恢复出原始数据的方法，大致思想都是优化目标函数，通过修改目标函数和优化思想，作用于不同的场景下。这种方法需要大量理论的分析。每种方法的优缺点和比较CAFÉ文章中都有。 CAFÉ的后续工作：没有直接follow CAFE的文章，但有一些其它数据恢复的文章。VFL下的数据恢复，就CAFÉ一篇。 再读CAFÉ，看看改进点：1. 采用更新的优化方式，实现更好的性能（不会）；2. 限制条件，不用梯度。去做属性推断攻击。（但又能用什么呢？z、x、y、θ和用梯度也没什么区别好像）；3. 更强的场景，攻击者为被动方（即参与VFL的任意一个用户），去恢复数据，这样条件就只有zp、xp、θp了。","link":"/2023/01/06/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%B8%89/"},{"title":"联邦学习（一）","text":"本篇文章为联邦学习系列的第一篇。主要讲解机器学习中的一个新型方向——联邦学习（Federated Learning, FL）。联邦学习是一种新的机器学习框架，在满足隐私保护和数据安全的同时，使数据拥有方能够共同拥有和交换数据，搭建一个更加稳定、高效的系统。本文主要对联邦学习进行一个概述，同时进行横向联邦学习的讲解。 联邦学习概述随着互联网的发展，人工智能（Artificial Intelligence, AI）得到了越来越广泛的应用，为人们的生活提供了很大的便利。但是，数据分布与隐私保护的问题也随之而来，一些大型的AI项目需要融合各个公司的数据，但在现实中想要将分散在各地、各个机构的数据进行整合几乎是不可能的。同时，随着通用数据保护条例（General Data Protection Regulation，GDPR）的出台，数据之间的交流越来越困难，用户的隐私保护和安全管理更加严格。 要解决上述数据交流的困境，传统的机器学习算法已经很难满足要求，在目前的法规和GDPR下，各个公司在用户没有批准的情况下无法直接进行数据交流。因此，需要设计一个新的机器学习框架，在满足隐私保护和数据安全的同时，使数据拥有方能够共同拥有和交换数据，搭建一个更加稳定、高效的系统，这就是联邦学习。 联邦学习最近已成为传统机器学习的一种替代方法，它允许两个或更多参与者（每个人都有自己的训练数据集）构建联合模型。各参与者使用自己的数据，在本地训练自己的模型，服务器进行参数的汇总并更新联合模型。联邦学习的各个步骤均为加密操作，在模型的构建过程中，各个用户的数据均在本地保留，没有进行数据共享，一定程度上保证了机器学习过程中的安全问题。因此，联邦学习系统有望在有效的保护数据隐私的同时扩大机器学习的规模。 联邦学习框架联邦机器学习（Federated machine learning），又名联邦学习，是一个机器学习框架，能在有效帮助多个机构在满足用户隐私保护、数据安全的前提下，进行数据使用和机器学习建模。联邦学习系统构架如下图所示。 上图主要介绍了两个数据持有方的情况。联邦学习系统主要由两部分组成，数据持有方（用户）和第三方协作者（服务器），用户分别在各自本地训练模型，且用户之间的数据不共享；服务器用来进行加密模型训练，保护用户数据隐私的同时进行模型参数汇总。训练过程可分为以下几个步骤： （1）协作者对训练过程中需要使用的数据信息进行加密，并将公钥传递给参与联邦学习的用户； （2）各用户接受公钥，并交互用于训练本地模型的中间参数信息，开始准备本地模型的训练； （3）各用户在本地各自计算梯度值和损失，进行加密模型训练，并把结果和参数传递给服务器。服务器进行参数的汇总，更新全局模型，得到全局参数信息（总梯度值）； （4）服务器将梯度加密回传给各个用户，用户继续在本地各自模型的参数。 重复上述过程，根据具体情况设置合适的损失函数和优化方式，当损失函数收敛时结束整个训练过程。在模型训练过程中，用户各自的数据仍然保留在本地，没有进行数据共享，数据的交互和模型的训练均为加密操作，不会造成隐私泄露。借助联邦学习系统，各用户合作实现了整个全局模型的训练，达到隐私保护的效果。 横向联邦学习的实现本地模型训练在联邦学习中，各个用户需要在本地进行模型的训练，本地模型的训练与大部分机器学习模型类似，即为由一组参数θ进行参数化的函数 f(θ): X-&gt;Y，其中X表示输入（或特征）空间，Y表示输出空间。 本文专注于用于分类任务的监督学习。其训练数据是一组标记有其正确类别的数据点，测试数据则没有类别标签，使用将输入图像或文本作为输入并输出类标签的模型。为了找到适合训练数据的最佳参数集，训练算法优化了目标（损失）函数，当模型在数据点上输出错误的标签时，该函数会对模型进行惩罚。我们使用 表示在给定模型参数的情况下在数据点 上计算出的损失，而 表示在批次b的数据点上计算出的平均损失。 有许多方法可以优化目标函数，如随机梯度下降（Stochastic Gradient Descent, SGD），Adam优化、Adagrad优化等，SGD优化在目前的机器学习和神经网络中的使用最为普遍，SGD是一种迭代方法，其中，优化器在每个步骤中都会接收一小批训练数据，并根据模型的方向更新模型参数。目标函数相对于学习速率的负梯度并由其缩放。当模型收敛到局部最小值（梯度接近零）时训练结束，使用保留的数据测试训练后的模型，该数据在训练期间未使用。标准度量标准是测试准确性，即正确分类的保留的数据点的百分比，常用的优化器还有Adam优化器等。对于梯度下降算法，当要找到损失函数的最小值时，任取一个初始点，找到给定点的梯度，朝着梯度相反的方向，就能让函数值下降的最快，因为梯度的方向就是函数之变化最快的方向。因此，通过梯度下降算法，反复求取梯度，就能到达局部的最小值。 全局模型更新各用户进行了本地模型训练后，将模型参数传递给服务器，由服务器进行全局模型更新。全局模型更新的方法有很多种，如同步梯度更新、模型平均等。 对于同步梯度更新的协作学习，在每次迭代中，每个参与者都从中央服务器得到全局模型，并根据他的一批训练数据进行更新，将更新发送到服务器。服务器等待所有参与者的梯度更新，然后使用随机梯度下降汇总的更新应用于全局模型。 对于模型平均的联合学习，在每个回合中，第k个参与者使用其整个大小为nk的训练数据集（即全局可见的更新不是基于批次，而是基于参与者的整个数据集），在当前模型上本地执行SGD步骤。每个参与者将结果模型提交给服务器，该服务器计算加权平均值。服务器在保留的数据集上评估生成的各个模型，并在性能停止改善时停止训练。 两种全局模型更新方法的收敛速度在很大程度上取决于学习任务和超参数（如参与者的数量和数据批次的大小），同时，二者都能达到较高的效率，其中同步梯度更新的协作学习只能共享用户的小部分梯度信息，故基于模型平均的联合学习更为常见。","link":"/2023/01/06/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%B8%80/"},{"title":"联邦学习（二）","text":"本篇文章为联邦学习系列的第二篇。主要讲解机器学习中的一个新型方向——联邦学习（Federated Learning, FL）。联邦学习是一种新的机器学习框架，在满足隐私保护和数据安全的同时，使数据拥有方能够共同拥有和交换数据，搭建一个更加稳定、高效的系统。本文主要介绍纵向联邦学习（Vertical Federated Learning, VFL）以及一部分纵向联邦学习的隐私保护问题，本文章以分析论文的方式进行介绍。 论文1：VFL综述论文**“Vertical Federated Learning: Challenges, Methodologies and Experiments” ** IEEE Network 2022: VFL的具体步骤： Step1: 私有集交集(Private set intersection)。在模型训练之前，框架需要找到所有参与者(即来宾组织和宿主组织)服务的公共标识符(id)来对齐训练数据样本，称为私有集交集(private set intersection, PSI)或安全实体对齐。PSI是一个安全的多方协议，它允许多个参与者在他们的数据中找出可用的公共id。广泛采用的PSI技术包括哈希、多项式求值和转移. Step2: 底层模型正向传播(Bottom model forward propagation)。在确定了所有参与者的对齐样本之后，每一个参与者将使用基于其底层(本地)模型的本地数据完成一个向前传播过程。这种正向传播过程除了没有计算损失值外，与传统训练类似。 Step3: 正向输出传输(Forward output transmission.)。每个参与者将其底层模型的输出传输到标签所有者。直观地说，正向输出包含局部神经网络的中间结果，能够将原始属性转换为特征。这样的传输过程可能会泄露参与者的隐私信息。因此，应该利用先进的隐私保护方法，如差分隐私(DP)，以解决潜在的隐私风险，但可能会产生额外的通信成本和计算复杂性。 Step4: 顶部模型正向传播(Top model forward propagation)。标签所有者根据收集到的所有参与者的输出，根据顶层模型和标签计算损失函数值。 Step5: 顶部模型反向传播(Top model backward propagation)。标签所有者进行反向传播，计算两个梯度: 1)顶层模型的模型参数; 2)转发每个参与者的输出。使用顶级模型的梯度，标签所有者可以计算每批样品的平均梯度，并更新其模型。 Step6: 反向输出传输(Backward output transmission)。正向输出的梯度被发送回每个来宾参与者。可以注意到，所需的通信成本(传输比特)通常比Step2中的要小得多，因为它们是梯度而不是中间输出。 Step7: 底部模型向后传播(Bottom model backward propagation)。每个参与者根据本地数据和来自标签所有者的正向输出的梯度计算其底部模型参数的梯度，然后更新其底部模型。 VFL的安全隐私问题：现有VFL模型的隐私和安全风险研究不足。在VFL中，参与者需要获得一致的样本空间，来自其他参与者的成员推断攻击可能是多余的。在VFL中，对抗参与者只控制联邦模型的一部分，该联邦模型不能独立运行，并且只能访问自己的底层模型的梯度。然而，通过分析交换的消息，即中间输出和梯度，参与者可以从其他参与者推断客户端的属性，如标签推断攻击和私有数据泄漏。 ​ 保护每个参与者所拥有的标签的隐私应该是VFL的基本要求，因为标签可能是高度敏感的，例如，一个人是否患有某种类型的疾病。在某些特殊情况下，来自宿主组织的梯度也可以直接泄漏标签信息。此外，还证明了从共享梯度恢复批处理数据是可用的。我们还可以注意到攻击方法在不同的数据类型中是不同的。例如，表格数据在学习之前通常需要进行嵌入，从嵌入的属性中获取私有信息很困难。然而，对手能否利用VFL中交换的消息恢复原始属性值仍是一个有待研究的问题。 可能的防御措施： 安全框架：Differential privacy(DP)、Secure multi-party computing(SMC)、Homomorphic encryption(HE) 论文2：VFL的隐私保护——标签推断攻击（Label Inference Attack）论文 “Label Inference Attacks Against Vertical Federated Learning” Security 2022 第一个VFL下的标签推断攻击。 场景：在VFL中，有n≥2个用户参与训练，且有一个用户拥有数据的真实标签，一个用户为攻击者。每个用户都有各自数据的部分特征（可以理解为，样本集相同但特征集不同），用户都有自己的bottom model。共采用了两种不同场景：①VFL without model splitting：中央服务器不进行模型的训练，而是简单的将各个用户的输出结果进行汇总，并得到最终的输出；②VFL with model splitting：中央服务器有特定的模型top model（也就是我们说的全局模型），同时也拥有标签信息，服务器进行模型的训练，并聚合各个用户的特征输出，并回传梯度信息。其实我们通常将第二种情况看作，中央服务器的训练就在带标签的用户上进行，或者说就是指该用户，因为该用户控制着中央服务器。 攻击者为不具有标签数据的某一用户，被攻击者为具有标签的用户，攻击者试图获取标签信息。 攻击者信息：①由于攻击者为参与者，攻击者拥有自己的数据信息（只有x没有y）和本地模型，还有模型每轮训练后中央模型传递的梯度信息。②部分少量辅助数据信息i.e. a few dozens of auxiliary labeled samples，在实际情况中，这部分数据是可以获取的。③攻击者感兴趣的样本x，用于最后推断x的标签，x可以是任何能够得到的样本，不仅仅是原始拥有的训练数据。 攻击者目标：推断出给定数据的标签值（包括训练数据和感兴趣的数据）。摘自原文： Note that the adversary’s goal is to infer the labels of any interested samples, not just the ones in the training dataset. 于是这篇文章根据不同情况，设计了三种不同的标签推断方法。 \\1) 被动微调训练好的底层模型作为攻击模型，输入待测样本实现推断； \\2) 主动参与训练，提出一种恶意优化方案，得到攻击模型，输入待测样本实现推断； \\3) 进行直接标签推断，通过理论推导，全局训练的每一轮中，攻击者通过收到的梯度符号来直接判断标签是否正确，实现推断。可实现100%成功率。 论文3：VFL的隐私保护——属性推断攻击（Feature Inference Attack）论文 “Feature Inference Attack on Model Predictions in Vertical Federated Learning” ICDE 2021 第一个VFL下的属性推断攻击。 场景：VFL，用户个数n≥2，其中一个为active party，拥有真实标签，其余的为passive party，联邦学习的全局模型训练在active party上完成，并将参数回传给各个用户，与label inference②相同。 攻击者为active party，被攻击者为target passive party（没有标签的用户中的一个用户），攻击者甚至可以拉拢其它所有passive party对target passive party进行属性推断。 攻击者信息：①攻击者拥有自己的数据信息，即特征值xadv，②由于攻击者为主动方，故还拥有标签信息y、VFL各用户的模型参数θ = (θadv, θtar)、全局模型的输出v，③关于其它用户的粗略信息（如数据分布，数据类型，属性名称等），这个也是正常的，因为主动方会经常需要这些信息来证明训练模型的有效性，④攻击者不知道其它用户的具体数据值。 攻击者目标：推断目标用户的属性值。摘自原文： The adversary Padv is given the VFL model parameters θ, the prediction output v, and the feature values xadv that belongs to himself. Padv’s goal is to infer the feature values of Ptarget, i.e., ​ xtarget = A(xadv; v; θ) (1) 于是这篇文章设计了攻击模型A，在只知道上述信息的情况下，实现了VFL的属性推断。 简单学习一下实现过程：提出了三种攻击方式，分别作用于两种常用模型和通用模型解法 1) Equality Solving Attack 针对逻辑回归模型LR 攻击方通过收集VFL预测结果和Active party和Passive Party的半边模型参数聚合更新结果和feature推断估计Passive party的feature信息。推导了相应的公式，见论文Equ.(7)(8)。 2) Path Restriction Attack 针对决策树模型DT 攻击方可以根据自己的部分特征信息(蓝色方框) 限制树模型中可能的路径(灰色-蓝色箭头)，结合预测类别结果1进一步限制决策路径(蓝色-红色箭头)，可以推测目标方的属性(绿色方框)，见论文图Fig.2。 3) GRN(generative regression network) Attack 针对通用模型，包括复杂模型NN、RF等 攻击方在进行VFL模型训练时进行对GRN的训练，在前向传播阶段，单独训练VFL模型，进行loss反向传播阶段，更新VFL model参数时共同训练生成模型GRN。对于GRN模型，攻击者收集目标方的属性信息生成伪造的目标样本，具体的，攻击者根据自己的已有特征集和部分随机变量，估计出目标用户的未知特征集。 论文4：论文3的升级版论文**“Comprehensive Analysis of Privacy Leakage in Vertical Federated Learning During Prediction“ **Proceedings on Privacy Enhancing Technologies 2022 对论文3进行了更严格的要求，并提升了性能。 场景：与论文3相同，攻击者信息有较大差别。这里主要学习了解论文说的黑盒和白盒情况。 VFL的框架如下图所示，通常情况下，各个本地的模型采用LR模型，模型参数为θact和θpas，z为输出特征向量，全局模型输出为 c = ξ (z) = ξ (f (xact, θact) + f (xpas, θpas))，最后 c 会返回到active party中。 攻击者信息：论文3中为白盒情况：由于攻击者为active party，攻击者能够拥有全部模型的模型参数，包括 θact和θpas，因此公式(1)可以写作： ​ xpas = Awb (xadv; v; θact; θpas) (2) 论文4设计了黑盒情况：攻击者不知道其余用户本地模型的参数信息，但拥有少量其余用户的输入数据(即辅助数据auxiliary data)，因此公式(1)改为： ​ xpas = Abb (xadv; v; θact; xaux; vaux) (3)","link":"/2023/01/06/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%BA%8C/"},{"title":"论文常用句式","text":"本篇文章讲解了英文论文写作的常用句式，包括常用词语，常用句式和常用细节等，主要涉及到机器学习和隐私保护方向论文的写作。 常用词语1. exploit：运用、利用 Our EncoderMI exploits the overfitting of the image encoder towards its training data. 2. overfitting：过拟合 n. the overfitting of … adj. an overfitted image … 3. pre-training of model：模型预训练 v. uses the public data to pre-train the model. 4. private/sensitive：隐私的/敏感的 to determine if the data is private/sensitive. 5. confidence score vector：置信向量 posteriority：后验 feature vector：特征向量 construct a vector 6. scenario：情况、条件 ~ case We assume an inferrer has a black-box access to a pre-trained image encoder, which is the most difficult and general scenario. 7. module：模块、部分 ~ part An important module in contrastive learning is data augmentation. 8. state-of-the-art：最先进的 we generalize early stopping, which is a state-of-the-art overfitting-preventionbased countermeasure against membership inference to classifiers. 9. binary classifier：二分类器 multiple classifier：多分类器 10. extract：提取、获取 extract membership features and construct an inference training dataset. 11. ground truth：真实情况、理想情况、标准答案 for each target encoder, we have 10,000 ground truth members and 10,000 ground truth non-members. 12. model architecture：模型结构 We adopt the same architecture (i.e., ResNet18) for a shadow encoder. 13. otherwise****：否则，表示对立面 ~ while We adopt ResNet18 for a shadow encoder if the inferrer knows the architecture of the target encoder and use VGG-11 with batch normalization otherwise. 14. metrics：评价指标 We set accuracy, precision, and recall as our evaluation metrics. 15. ratio：比率 The accuracy of a method is the ratio of the ground truth members/non-members correctly predicted by the method. 16. cosine similarity：余弦相似度 All contrastive learning algorithms use cosine similarity to measure similarity between two feature vectors. 17. curves：曲线 The curves are obtained via tuning the classification thresholds in the three inference classifiers to produce different precisions and recalls. 常用句式1. 成员推断攻击定义： 1）given an input and a black-box access to an image encoder, EncoderMI aims to infer whether the input is in the training dataset. 2. 我们的方法有着很好的效果： 1）Our results show that EncoderMI can achieve high accuracy, precision, and recall. 2） 3. 之前的研究主要集中于做…： 1）Existing studies on contrastive learning mainly focus on how to train a better image encoder such that it can achieve better performance on the downstream tasks. 2）Existing membership inference methods are mainly designed for classifiers. For example, … 3）Existing membership inference methods are insufficient. 4. …的应用是…： 1）Membership inference in contrastive learning has two important applications. The first application of membership inference is that a data owner can use a membership inference method to audit whether his/her (public) data was used to pre-train image encoders. 2）The first step of our EncoderMI is to train a shadow encoder whose ground truth members/nonmembers are known to the inferrer. 5. 有着相同的数据集分布： 1）the shadow dataset has the same (a different) distribution from the pre-training dataset. 6. 我们将在后面的一节进行讨论： 1）we will discuss in Section 4； 7. 我们用 … 来表示 … ： 1）We use a triplet B = (P, E, T) to denote the three dimensions of the inferrer’s background knowledge. 我们用一个三维元组来表示推断者拥有的背景知识 8. 数据集分割： 1）We randomly split a shadow dataset into two disjoint sets, i.e., shadow member dataset and shadow non-member dataset, each of which contains 10,000 images. [each of which：其中的每一个] 9. 网络的描述： 1）We use a fully connected neural network with two hidden layers as our vector-based classifier. 2）We adopt the following default parameters for our method. 10. baseline 对比句式： 1）We compare our methods with the following five baseline methods … In this baseline method, we … 11. 表格内容描述： 1）Table 2, 5 (in Appendix), and 6 (in Appendix) show the accuracy, precision, and recall of our methods under the 8 different types of background knowledge for CIFAR10, STL-10, and Tiny-ImageNet datasets, 12. 图像内容描述 1）Figure 1b shows the impact of the number of augmented inputs 𝑛 on the accuracy of our methods for CIFAR10. 13. 曲线趋势描述： 1）Our results show that precision drops slightly as recall increases up to around 0.9, and then drops sharply as recall further increases. 14. 具体指标粗略描述 1）EncoderMI-V achieves higher accuracy as the inferrer has access to more background knowledge, and we have the same observation for EncoderMI-S and EncoderMI-T in most cases. 15. 具体指标细致描述 1）For instance, EncoderMI-V achieves 96.5% accuracy when the inferrer knows all the three dimensions of background knowledge while achieving 88.7% accuracy when the inferrer does not know any of them for Tiny-ImageNet dataset. 常用细节1. 在这项工作中：in this work；in our work；in our method 2. 常用动词（we为主语）： [判断]：decide；determine；judge；infer；consider；predict； **[证明]**：confirm； **[发现]**：find；perform；observe；note； **[提出]**：propose； **[展示]**：show； **[假设]**：assume； **[生成、得到]**：get；create **[进行、实施]**：do；conduct；process；implement **[作用、应用]**：apply；operate **[看待]**：treat；think；suspect(猜想) **[构建、构造]**：construct、build **[选择、选取]**：select、choose **[设置、设计]**：set、design **[对比、比较]**：compare、contrast **[表示、代表]**：denote、represent （attacker为主语）： **[查询、访问]**：query **[了解]**：know **[欺骗]**：cheat；deceive 3. 常用形容词： **[有效的]**：effective；efficient；valid **[足够的]**：sufficient；enough **[脆弱的]**：vulnerable 4. 常用连接词： **[粗略的说]**：roughly speaking；for simplicity **[通常来说]**：generally speaking **[特别地]**：in particular；particularly；specially **[例如]**：for example；for instance **[此外]**：moreover；in addition；besides **[因此]**：as a result；therefore **[默认情况下]**：by default 5. 测试常用词： close to：接近；around：接近；increases up：上升；drop：下降 the reason is that：理由是 be viewed as：被看作 to some extent：在一定程度下 respectively.：分别地 6. 一些简写 i.e. ：也就是、即； e.g. ：例如；s.t. ：使得","link":"/2022/12/23/%E8%AE%BA%E6%96%87%E5%B8%B8%E7%94%A8%E5%8F%A5%E5%BC%8F/"},{"title":"论文阅读笔记(Surfree)","text":"本篇文章为《Surfree: a fast surrogate-free black-box attack》(CVPR 2021) 阅读笔记。 该论文提出了一种新的对抗样本生成方法。与梯度无关，也不需要估计梯度，全靠理论推导，利用了决策边界的几何属性，在更少的查询量的条件下得到较好的对抗样本。 Surfree: a fast surrogate-free black-box attack (CVPR 2021) 该论文提出了一种新的对抗样本生成方法。与梯度无关，也不需要估计梯度，全靠理论推导，利用了决策边界的几何属性，在更少的查询量的条件下得到较好的对抗样本。 基本流程：首先构建超平面，通过旋转角度搜索更近的对抗样本，再通过二分法细化角度。如果第二步找不到更近的对抗样本，则重新采样方向构建另一个超平面去寻找。（见算法1） ①初始化：该算法需要一个初始化的点，通过目标攻击或非目标攻击生成对抗样本点。方法与我们的类似：nontarget：加噪，target：取对应数据集中的点，再二分法。 ②搜索新方向：第k次迭代中，原始样本和当前对抗样本连线向量u­k，使用DCT基产生一个伪随机向量tk，将tk与和uk前k-1次产生的方向做施密特正交化，正交后的方向向量为vk，即本次产生的新方向。（见算法2） ③搜索：在当前方向v**k和u­k所构成的平面内，由当前给定的最大角度θmax，乘以系数，来试探点Z*(θmax*T)是否为对抗样本（点Z*(θ)就是指与向量的角度为θ的处于该圆弧上的点，具体含义和内容见本论文，参考图2），一旦发现对抗样本图片搜索立即停止。否则缩小θmax重新生成一个vk进行上述搜索。（由于决策边界的法向量未知，则需要从大幅震荡使用+和-进行交替测试，碰到对抗性的样本就停止）；也可以0、θ*/2、θ*为节点，采用插值的方法估计最优θ；（参考图3） ④二分法搜索：找到角度θ以及符号后，用二分法搜索θ再细化t步，最后增大θmax。","link":"/2022/12/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-surfree/"},{"title":"论文阅读笔记(Dataset Inference)","text":"本篇文章为《DATASET INFERENCE: OWNERSHIP RESOLUTION IN MACHINE LEARNING 》(ICLR 2021) 阅读笔记。该论文提出了数据集推断的思想，通过训练数据集与测试数据集到决策边界距离的差异性，获取特征值，实现数据集推断。 《DATASET INFERENCE: OWNERSHIP RESOLUTION IN MACHINE LEARNING 》(ICLR 2021) 该论文提供了一种能与我们方法完全匹配的场景。需要通过计算点到决策边界的距离，进而进行特征值获取，实现数据集推断。因此需要生成离原始样本最近的对抗样本。而且此文章采用的黑盒方法过于简单，我们可以进行优化。 该文章主要思想：提出了数据集推断，用来进行模型的窃取攻击的防御，具体地，判断某一可疑模型是否使用了目标模型的部分隐私数据，来进行模型训练。 该文章具体步骤：（其中Embedding特征值的计算就是点到决策边界的距离计算） 1.将受害者的私有数据集和公有数据集进行标记：Sv-&gt;b=0; S-&gt;b=1 2.任取部分受害者的私有数据和公有数据，进行fv下Embedding特征值的计算。并将特征值作为输入x，对应的成员标签(b)作为y，训练回归模型gv(类似于成员推断攻击的二分类模型，只不过加了一个评分，同时修改了损失函数使得成员数据对应的评分小)。该回归模型gv的作用：给定一个样本在可疑模型 F 计算的特征值，模型输出一个概率(认为该条数据包含fv隐私信息的置信度) \\3. 进行假设检验HypothesisTesting。取m条受害者的私有数据和公有数据，计算可疑模型fA*下的Embedding特征值，并传入gv计算置信度，将m个数据的置信度构成向量c=(c0…cm)和cv。检验无效假设H0:μ&lt;μv，计算p值，通过设定阈值α，若p＜α，则H0被拒绝，模型被盗。 一些笔记： 一、模型窃取攻击的主要类型： 1.模型提取。对手利用对模型： (1.a)预测向量的访问(如API)，来重现模型的副本； (1.b)使用受害者模型作为标记预言，从初始未标记数据集上训练他们的模型。 2.访问用于训练受害者模型的数据集本身。并通过： (2.a)提取受害者模型； (2.b)从头训练来训练自己的模型。 3.对受害者模型的完全访问权，但不能访问数据集。 (3.a)对受害者模型进行微调， (3.b)采用受害者模型进行无数据蒸馏。","link":"/2022/12/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-dataset-inference/"},{"title":"论文阅读笔记(数据所有权系列)","text":"本篇文章为数据所有权相关的论文笔记。包括数据集的IP认证(Dataset Inference)，DL模型的IP认证(IPGuard)和DL模型的知识蒸馏(Knowledge Distillation)。我们系统的介绍了这三种方法，同时在理论基础、实现方法、实验环境、实验内容和实验结果等方面进行了对比。 Dataset Inference主要思想：提出了数据集推断，用来进行模型窃取攻击的防御，具体地，判断某一可疑模型是否使用了目标模型的部分隐私数据，来进行模型的训练。 具体步骤：（其中Embedding特征值的计算就是点到决策边界的距离计算） 1.将受害者的私有数据集和公有数据集进行标记：Sv-&gt;b=0; S-&gt;b=1 2.任取部分受害者的私有数据和公有数据，进行fv下Embedding特征值的计算。并将特征值作为输入x，对应的成员标签(b)作为y，训练回归模型gv(类似于成员推断攻击的二分类模型，只不过加了一个评分，同时修改了损失函数使得成员数据对应的评分小)。该回归模型gv的作用：给定一个样本在可疑模型 F 计算的特征值，模型输出一个概率(认为该条数据包含fv隐私信息的置信度) （Embedding特征值的计算：提出了白盒和黑盒两种，但不够精细化） 3.进行假设检验HypothesisTesting。取m条受害者的私有数据和公有数据，计算可疑模型fA*下的Embedding特征值，并传入gv计算置信度，将m个数据的置信度构成向量c=(c0…cm)和cv。检验无效假设H0:μ&lt;μv，计算p值，通过设定阈值α，若p＜α，则H0被拒绝，模型被盗。 实验环境： Datasets - Target Models CIFAR10 – WRD-28-10 CIFAR100 – WRD-28-10 攻击方式： ①模型提取，预测向量的访问；(Model exaction using unlabeled data and victim confidence) ②模型提取，仅使用标签；(Model exaction using unlabeled data and victim labels) ③访问数据集，提取受害者模型；(Data distillation) ④访问数据集，重新训练自己的模型；(Different model) ⑤对受害者模型进行微调；(Fine tuning) ⑥对受害者模型进行无数据蒸馏；(Data-free distillation/Zero shot learning) ⑦独立模型（对比实验）。(Train a teacher model on a separate dataset) 生成对抗样本的方式： ①White ②Black 评价指标： ①Δμ = μ – μv：置信度均值之差 ②p-value：无效假设H发生概率； 实验内容：（1 2为正文, 3 4 5为附录） 1.数据集推断整体性能评估：固定m，计算每种攻击下的Δμ和p-value值。 （攻击①-⑦; CIFAR10/CIFAR100; Black/White; m=10） 2.检验所需样本个数m对数据集推断的影响：改变m，计算p-value的变化。 （攻击①-⑥; CIFAR10/CIFAR100; Black/White; m=0-50） 3.生成距离特征size大小（也就是计算该点到几条决策边界的距离）对数据集推断的影响：改变Embedding Size，计算p-value的变化。（攻击①-⑥; CIFAR10/CIFAR100; Black; m=15/30/45/60/75/90） 4.补充了另外两个数据集（SVHN/Imagenet）的实验整体性能表：固定m，计算每种攻击下的Δμ和p-value值。（SVHN:攻击①-⑦; Imagenet:攻击③-④; Black; m=10） 5.双方私有数据集重叠对性能影响（作为一种新的攻击方式）：改变fraction overlap，计算p-value的变化。（SVHN; Black; m=10; fraction overlap=0.0/0.3/0.5/0.7/1.0） 整体性能： (实验1) CIFAR10-WRD-28-10 CIFAR100 – WRD-28-10 (实验4) ImageNet IPGuard主要思想：提出了IPGuard，用来保护深度网络的知识产权。具体地，判断某一可疑模型是否是目标模型的后处理版本（盗版）。 具体步骤：（其中footprint的生成就需要使用对抗样本技术） 1.取n个点，随机/就近取一条决策边界作为target label，采用优化方式生成对抗样本，将这些对抗样本（nearest samples）和他们对应的标签（target label）作为footprint； （优化方法为： ，需要白盒条件且不够精细化） 2.生成多种可疑模型，包括阳性（盗版）和阴性（正常）模型，将模型对nearest samples进行预测，与target label进行比较，计算匹配率。 实验环境： Datasets - Target Models CIFAR10 – ResNet20 CIFAR100 – WRN-22-4 Imagenet – ResNet50 攻击方式： 1.阳性模型 ①微调最后一层全连接层；(Fine-tune last layer) ②微调所有层；(Fine-tune all layer) ③重新训练最后一层；(Retrain last layer) ④重新训练所有层；(Retrain all layer) ⑤权重修剪；(Weight pruning) ⑥过滤器修剪；(Filter pruning) 2.阴性模型 ⑦同结构模型；（同结构不同初始化） ⑧不同结构模型； ⑨随机森林模型。 生成对抗样本的方式： ①初始化样本：随机/选训练集数据 ②找target label：随机/取最近的 ③对抗攻击：Random/FGSM/IGSM/CW/IPGuard 评价指标： ①匹配率：得到模型预测输出后，可疑模型预测数据点与目标分类器预测数据点标签匹配的分数。（阳性模型的分数高，阴性模型的分数低） ②ARUC：鲁棒性与唯一性曲线围成的面积。其中：阳性模型的匹配率代表鲁棒性，阴性模型的匹配率代表唯一性。 ③测试准确率：模型的测试准确率。 实验内容：（只有正文） 1.各种模型的测试准确率；（目标模型+可疑模型） 2.整体性能情况：所有情况下最优参数对应的ARUC的值； （CIFAR10/CIFAR100/ImageNet; Random/FGSM/IGSM/CW/IPGuard） 3.整体性能情况：各种攻击方式和各种对抗样本生成方式下，匹配率的值； （攻击①-⑨; CIFAR10/CIFAR100/ImageNet; FGSM/IGSM/CW/IPGuard） 4.FGSM、IGSM、CW对抗攻击中超参数对ARUC的影响。我们应该讨论我们方法超参数的影响； 5.不同数据集下，不同对抗攻击方法需要的时间； （Random/CIFAR10/CIFAR100/ImageNet; FGSM/IGSM/CW/IPGuard; n=100） 整体性能： （实验三） CIFAR10-ResNet20 CIFAR100-WRN-22-4 （实验三） ImageNet-ResNet50 （实验二）实验三是计算的匹配率，实验二是ARUC Knowledge Distillation主要思想：利用对抗性攻击来发现支持决策边界的样本，从而实现知识蒸馏。具体的，提出了一种对抗攻击方法（类似deepfool），在决策边界处得到对抗样本（BSSs），使得知识蒸馏后的模型决策边界能够接近原本的模型分类边界。 具体步骤：（其中BSSs的生成就需要使用对抗样本技术） 1.挑选N个原始点（base sample）以及对应的对抗标签（target label）。1）样本选择方法：选出能够被teacher和student均预测为该类的样本，个数为C，若C小于N，则用这C个样本，若C大于N，则在C中选出teacher与student预测概率相差最大的N个样本；2）标签选择方法：选取距离该样本最近的决策边界。 2.进行对抗攻击生成BSSs。方法为：优化损失函数，并进行更新，类似Deepfool。 其中b为原始class，k为目标class。 3.设计模型蒸馏损失函数，进行模型蒸馏，优化student。其中J为entropy function：J(a; b) =- aTlogb。 实验环境： Datasets – Target Models(Teacher) – Student CIFAR10 – ResNet26 – ResNet8 ResNet14 ResNet20 ImageNet – ResNet32 – ResNet8 Tiny ImageNet – ResNet42 – ResNet10 攻击方式： 知识蒸馏Knowledge distillation。 蒸馏方式：Proposed和FSP + Proposed，还有一些对比实验（Original/Hinton）。 生成对抗样本的方式： 见具体步骤1. 对抗攻击：Baseline/Random/noise L2 minimize/FGSM/DeepFool/Proposed 评价指标： ①测试准确率：模型的测试准确率。 ②蒸馏后得到的student的决策边界与teacher决策边界的相似度：MagSim和AngSim。 实验内容：（只有正文） 1.整体性能情况：不同方法蒸馏后的student测试准确率对比； （CIFAR10/ImageNet/Tiny; Proposed/FSP + Proposed；BSSs） 2.对抗样本对知识蒸馏的影响； （CIFAR10; Baseline/Random/noise L2 minimize/FGSM/DeepFool/Proposed） 3.不同方法下的相似度情况； （CIFAR10; DSSs; Original/Hinton/Proposed） 4.超参数的影响（选取样本个数、选取方式等）； 整体性能：","link":"/2022/12/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E6%89%80%E6%9C%89%E6%9D%83/"},{"title":"java基础（八）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的高级特性——java反射机制。具体讲解java的反射概念和实现，以及反射的应用：动态代理设计模式。 java反射机制关于java.lang.Class的理解： 1.类的加载过程： 程序经过javac.exe命令（即编译）以后，会生成一个或多个字节码文件（.class结尾）； 接着我们用java.exe命令对某个字节码文件进行解释运行。相当于将某个字节码文件加载到内存中。此过程就称为类的加载。加载到内存中的类，我们就称为运行时类，此运行时类，就作为Class的一个实例； 2.换句话说，Class的实例就对应着一个运行时类； 3.加载到内存的运行时类，会缓存一定时间。在此时间之内，我们可以通过不同的方式来获取此运行时类。 获取Class实例的方式：123456789Class clazz1 = Person.class； //调用运行时类的属性：.classPerson p1 = new Person();Class clazz2 = p1.getClass(); //通过运行时类的对象，调用getClass()方法Class clazz3 = Class.forName(&quot;包名.Person&quot;); //调用Class的静态方法：forName(String classPath);ClassLoader classLoader = 文件名.class.getClassLoader();Class clazz4 = classLoader.loadClass(&quot;包名.Person&quot;); //使用类的加载器：ClassLoader，此方式了解即可 通过反射创建对应运行时类的对象：newInstance(): 调用此方法，创建对应的运行时类的对象。内部调用了运行时类的空参的构造器 要想此方法正常创建运行时类的对象，要求： 1.运行时类必须提供空参的构造器； 2.空参的构造器的访问权限得够。通常设置为public。 在javabean中要求提供一个public的空参构造器。原因： 1.便于通过反射，创建运行时类对象； 2.便于子类继承父类时，默认调用super()时，保证父类有此构造器。 12345678//例子：Class clazz = Person.class;Object obj = clazz.newInstance(); //obj即为Person类的对象//Person obj = (Person) clazz.newInstance(); //进行强转，结果一样//若添加泛型：Class&lt;Person&gt; clazz = Person.class;Person obj = clazz.newInstance(); //添加泛型后相当于得到的对象一定是Person类的 获取运行时类的属性、方法、构造器的结构：获取运行时类的属性结构： getFields()：获取当前运行时类及其所有父类中声明为public访问权限的属性； getDeclaredFields()：获取当前运行时类中声明的所有属性。（不包含父类中声明的属性）; 获取运行时类的方法结构： getMethods()：获取当前运行时类及其所有父类中声明为public访问权限的方法； getDeclaredMethods()：获取当前运行时类中声明的所有方法。（不包含父类中声明的方法）; 获取构造器结构： getConstructors()：获取当前运行时类中声明public的构造器； getDeclaredConstructors()：获取当前运行时类中声明的所有构造器； 调用运行时类的属性、方法、构造器：如何操作运行时类中的指定的属性： 1234567891011121314151617181920Class clazz = Person.class;//创建运行时类的对象Person p = (Person) clazz.newInstance(); //p即为Person类的对象//1. 获取指定的属性//getDeclaredFields(String fieldname)：获取指定的属性//Field id = clazz.getFields(&quot;id&quot;); //getFields(String name)：只能获取public的属性，不采用Field name = clazz.getDeclaredFields(&quot;name&quot;); //2. 保证当前属性可访问name.setAccessible(true); //操作非public属性时需要添加，保证当前属性可访问//3. 设置当前属性的值//set()：参数1：指明设置哪个对象的属性；参数2：将此属性值设置为多少name.set(p, &quot;Tom&quot;); //4. 获取当前属性的值//get()：参数：获取哪个对象的属性值。注：正常为Object类型，为基本数据类型时，打印需要强转System.out.println(name.get(p)); 如何操作运行时类中的指定的方法： 12345678910111213141516171819Class clazz = Person.class;//创建运行时类的对象Person p = (Person) clazz.newInstance(); //p即为Person类的对象//1. 获取指定的某个方法//getDeclaredMethod()，参数1：指明获取的方法名称；参数2：指明获取方法的形参列表，因为可能会有多个同名方法Method show = clazz.getDeclaredMethod(&quot;show&quot;, String.class);//2. 保证当前方法可访问show.setAccessible(true); //3. 给指定的某个方法赋值//invoke()，参数1：方法的调用者；参数2：给方法形参赋值的实参//invoke()方法的返回值即为对应类中调用方法的返回值，若没有返回值，则返回nullObject returnValue = show.invoke(p, &quot;CHN&quot;); //类似于之前的String nation = p.show(&quot;CHN&quot;)System.out.println(returnValue); //注：若为静态方法，则invoke的第一个参数为Person.class，也可以写成None，因为加载时就知道静态方法；静态属性同理 如何操作运行时类中的指定的构造器：（使用较少） 1234567891011121314Class clazz = Person.class;//1.获取指定的构造器//getDeclaredConstructor()：参数：指明构造器的参数列表Constructor constructor = clazz.getDeclaredConstructor(String.class);//2.保证此构造器是可访问的constructor.getAccessible(true);//3.调用此构造器创建运行时类的对象Person per = (Person) constructor.newInstance(&quot;Tom&quot;); //默认为ObjectSystem.out.println(per); //注：上述是调用有参构造器时使用，并进行类的实例化；若调用无参构造器，采用Person p = (Person) clazz.newInstance()即可。 反射的应用：动态代理– 特别重要 Spring的底层用的就是这个 代理设计模式的原理： 使用一个代理将对象包装起来，然后用该代理对象取代原始对象。任何对原始对象的调用都要通过代理。代理对象决定是否以及何时将方法调用转到原始对象上。 之前为大家讲解过代理机制的操作，属于静态代理，特征是代理类和目标对象的类都是在编译期间确定下来，不利于程序的扩展。同时，每一个代理类只能为一个接口服务，这样一来程序开发中必然产生过多的代理。最好可以通过一个代理类完成全部的代理功能； 动态代理是指客户通过代理类来调用其它对象的方法，并且是在程序运行时根据需要动态创建目标类的代理对象。动态代理使用场合：1.调试；2.远程方法调用； 动态代理相比于静态代理的优点：抽象角色中（接口）声明的所有方法都被转移到调用处理器一个集中的方法中处理，这样，我们可以更加灵活和统一的处理众多的方法。 动态代理举例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/**对于动态代理，对于代理模式，需要有接口、被代理类、代理类。代理类要改成动态**///定义接口 -- 即一种规范interface Human{ String getBelief; void eat(String food);}//被代理类 -- 实现该接口class SuperMan implements Human(){ @Override public String getBelief(){ return &quot;I believe I can fly!&quot;; } @Override public void eat(String food){ System.out.println(&quot;我喜欢吃&quot;+food); }}/*要想实现动态代理，要解决两个问题：问题一：如何根据加载到内存中的被代理类，动态的创建一个代理类及其对象；问题二：当通过代理类的对象调用方法时，如何动态的去调用被代理类中的同名方法。*///动态创建一个与被代理类实现接口一样的类，代理对被代理类的执行；//这个类不是具体的一个类，是会根据具体的对象变化的类；如果是具体的类，就变成了静态代理//生成一个代理工厂，用于动态的生成代理类class ProxyFactor{ //调用此方法，返回一个代理类的对象，解决问题一 public static Object getProxyInstance(Object obj){ //obj为被代理类的对象 //采用反射中的Proxy类，构建一个代理的实例 //要求体现在三个参数中：与被代理类加载器一致，与被代理类的实现接口一致，动态的调用方法 MyInvocationHandler handler = new MyInvocationHandler(); handler.bind(obj); //传入被代理类的对象 return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), handler); }}//实现动态性class MyInvocationHandler implements InvocationHandler{ private Object obj; //需要使用被代理类的对象进行赋值 //对obj对象进行赋值 public void bind(Object obj){ this.obj = obj; } //作用：当我们通过代理类的对象，调用方法a时，就会自动的调用如下的方法：invoke() //将被代理类要执行的方法a的功能就声明在invoke()中 @override public Object invoke(Object proxy, Method method, Object[] args){ //method：即为代理类对象调用的方法，此方法也就作为了被代理类对象要调用的方法 //obj：被代理类的对象 Object returnValue = method.invoke(obj, args); //上述方法的返回值，就作为当前类中invoke()方法的返回值 return returnValue; }}//主测试类public class ProxyTest { public static void main(String[] args){ //1.创建被代理类对象 SuperMan superMan = new SuperMan(); //2.创建代理类对象proxyInstance Human proxyInstance = (Human) ProxyFactory.getProxyInstance(superMan); //返回值是Object，但实际上是Human //3.实现方法，实际上自动调用了代理类的invoke方法 //其中三个参数值分别为：(Object proxy：代理类对象proxyInstance；Method method：调用方法getBelief；Object[] args：方法实参null/&quot;四川麻辣烫&quot;) //即：当通过代理类对象调用方法时，会自动的调用被代理类中同名的方法 //这两个方法实际上是被代理类SuperMan的方法，而我们通过代理类来调用，但又找不到具体的代理类（即代理类的对象没有显式创建），因此实现了动态代理 String belief = proxyInstance.getBelief(); proxyInstance.eat(&quot;四川麻辣烫&quot;); //因此：只需要提供被代理类（如SuperMan）和被代理类实现的接口（如Human），会自动的生成代理类对象（proxyInstance），去代理实现被代理类中的方法。 }}","link":"/2023/01/19/java%E5%9F%BA%E7%A1%80%E5%85%AB/"},{"title":"java基础（七）","text":"本系列主要进行java语言的介绍，其中本篇文章介绍java的高级特性——网络编程。计算机网络是指把分布在不同地理区域的计算机与专门的外部设备用通信线路互连成一个规模大、功能强的网络系统，从而使众多的计算机可以方便的相互传递信息、共享硬件、软件、数据信息等资源。而网络编程的目的是直接或间接地通过网络协议与其它计算机实现数据交换，进行通讯。 本篇文章会从通信的两大要素：IP和端口号、网络协议的方面进行java网络编程的介绍。 网络编程计算机网络：把分布在不同地理区域的计算机与专门的外部设备用通信线路互连成一个规模大、功能强的网络系统，从而使众多的计算机可以方便的相互传递信息、共享硬件、软件、数据信息等资源。 网络编程的目的：直接或间接地通过网络协议与其它计算机实现数据交换，进行通讯。 通信要素一：IP和端口号 IP：唯一的表示Internet上的计算机（通信实体）； 在JAVA中使用InetAddress类代表IP； IP 分类：IPv4 和 IPv6；万维网 和 局域网； 域名：www.baidu.com…； 本地回路地址：127.0.0.1 ，对应着localhost。 举例 IP 地址的实例化： 123InetAddress inet1 = InetAddress.getByName(&quot;192.168.10.14&quot;);InetAddress inet2 = InetAddress.getByName(&quot;www.baidu.com&quot;);InetAddress inet3 = InetAddress.getLocalHost(); 端口号：标识正在计算机上运行的进程；不同的进程有不同的端口号； 端口号被规定为一个16位整数0~65535； 端口号与 IP 地址的组合得出一个Socket套接字。 通信要素二：网络通信协议网络通信协议：计算机网络中实现通信必须有一些约定，即通信协议，对速率、传输代码、代码结构、传输控制步骤、出错控制等指定标准。 TCP 和 UDP： TCP协议: 使用TCP协议前，须先建立TCP连接，形成传输数据通道； 传输前，采用“三次握手”方式，点对点通信，是可靠的； TCP协议进行通信的两个应用进程:客户端、服务端； 在连接中可进行大数据量的传输； 传输完毕，需释放已建立的连接（“四次挥手”），效率低。 UDP协议: 将数据、源、目的封装成数据包，不需要建立连接； 每个数据报的大小限制在64K内； 发送不管对方是否准备好，接收方收到也不确认，故是不可靠的； 可以广播发送； 发送数据结束时无需释放资源，开销小，速度快。 TCP生活案例：打电话；UDP案例：发短信、发电报。 TCP的三次握手和四次挥手： 实现TCP的网络编程： 例子：客户端发送信息给服务端，服务端将数据显示在控制台上 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//客户端public void client() throws IOException{ //1.创建Socket对象，指明服务器端的ip和端口号 InetAddress inet = InetAddress.getByName(&quot;127.0.0.1&quot;); //为**服务端**的端口号 Socket socket = ne w Socket(inet, 8899); //创建socket ip+端口号 //2.获取一个输出流，用于输出数据 OutputStream os = socket.getOutputStream(); //3.写出数据的操作 os.write(&quot;你好，我是客户端&quot;.getBytes()); //4.资源的关闭 os.close(); socket.close()} //服务端public void server() throws IOException{ //1.创建服务器端的Socket对象，指明自己的端口号 ServerSocket ss = new Socket(8899); //创建socket ip(用服务端自己的ip)+端口号 //2.调用accept方法，表示接收来自于客户端的socket Socket socket = ss.accept(); //3.获取输入流 InputStream is = socket.getInputStream(); //4.读取输入流中的数据 //使用ByteArrayOutputStream类进行读取，避免采用String方式直接读取出现字符的乱码情况 ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] buffer = new byte[5]; int len; while((len = is.read(buffer)) != -1)){ baos.write(buffer, 0, len); //String str = new String(buffer, 0, len); //System.out.println(str); } System.out.Println(baos.toString()); //显示内容 //5.资源关闭 baos.close(); is.close(); socket.close(); ss.close();} 注意：1. 上述代码的异常需要用try-catch-finally处理，类似于之前的IO编程； ​ 2. 运行时需要先启动服务端，再运行客户端去连接； ​ 3. 客户端与服务端的连接除了自定义的方式，还可以采用浏览器+Tomcat服务器的方式实现，javaweb中用得多。（如自己git bash中hexo server中的 localhost:4000 网站，即为此方式实现的） 实现UDP的网络编程： 12345678910111213141516171819202122232425262728293031323334//发送端public void sender() throws IOException{ //1.创建socket对象 DatagramSocket socket = new DatagramSocket(); //2.设置要发送的数据报 String str = &quot;我是UDP方式发送的数据&quot;; byte[] data = str.getBytes(); //转化为字节数据 InetAddress inet = InetAddress.getByName(&quot;127.0.0.1&quot;); DatagramPacket packet = new DatagramPacket(data, 0, data.length, inet, 9090); //为接收端的ip和端口号 //3.发送数据 socket.send(packet); //4.资源关闭 socket.close();}//接收端public void receiver() throws IOException{ //1.创建socket对象 DatagramSocket socket = new DatagramSocket(9090); //2.设置要接收的数据报 byte[] buffer = new buffer[100]; DatagramPacket packet = new DatagramPacket(data, 0, buffer.length); // 自己的ip和端口号就不用写了 //3.接收数据报 socket.receive(packet); System.out.Println(new String(packet.getData(), 0, packet.getLength())); //显示内容 //4.资源关闭 socket.close();} URL网络编程 URL(Uniform Resource Locator)：统一资源定位符，它表示Internet上某一资源的地址； 它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源； 通过URL我们可以访问Internet上的各种网络资源，比如最常见的 www，ftp站点。浏览器通过解析给定的URL可以在网络上查找相应的文件或其他资源； URL的基本结构由5部分组成： &lt;传输协议&gt;:/&lt;主机名&gt;:&lt;端口号&gt;/&lt;文件名&gt;#片段名?参数列表&gt; 例如：http://192.168.1.100:8080/helloworld/index.jsp#a?username=shkstart&amp;password=123 参数列表格式：参数名=参数值&amp;参数名=参数值… 例子：用URL类实现Tomcat服务器上的图片下载，并保存到本地。 123456789101112131415161718192021//1.配置urlURL url= new URL(&quot;http://localhost:8000/examples/beauty.jpg&quot;);HttpURLConnection urlConnection = (HttpURLConnection) url.openConnection();urlConnection.connect();//2.配置流InputStream is = urlConnection.getInputStream(); //输入流：从Tombat服务器中输入FileOutputStream fos = new FileOutputStream(&quot;beauty1.jpg&quot;); //输出流：保存为本地文件//3.进行读取和写入byte[] buffer = new byte[1024];int len;while((len = is.read()) != -1){ fos.write(buffer, 0, len);}System.out.println(&quot;下载完成！&quot;);//4.关闭资源is.close();fos.close();urlConnecton.disconnect();","link":"/2023/01/19/java%E5%9F%BA%E7%A1%80%E4%B8%83/"},{"title":"JDBC","text":"本篇文章介绍JDBC的相关内容。SUN公司为了简化开发人员的（对数据库的统一）操作，提供了一个（Java操作数据库的）规范，俗称JDBC。这些规范的实现由具体的厂商去做；而对于开发人员来说，我们只需要掌握JDBC接口的操作即可。具体实现时，需要在java中导入mysql-connector-java.jar包，同时需要使用java.sql和javas.sql。 JDBC，数据库，java程序的关系 JDBC程序的例子1234567891011121314151617181920212223242526272829303132333435public static void main(String[] args) throws ClassNotFoundException，SQLException { //1．加载驱动 class.forName(&quot;com.mysql.jdbc.Driver&quot;);//固定写法，加载驱动 //2. 用户信息和url //useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=true String url = &quot;jdbc:mysql://localhost:3306/jdbcstudy?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=true&quot;; String username = &quot;root&quot;; String password = &quot;123456&quot;; //3. 连接成功,数据库对象Connection代表数据库 Connection connection = DriverManager.getConnection(url，username，password); //4. 执行SQL的对象 Statement 执行sql的对象 Statement statement = connection.createStatement(); //5. 执行SQL的对象去执行SQL，可能存在结果，查看返回结果 String sql = &quot;SELECT * FROM users&quot;; //要执行的SQL语句 //返回的结果集，结果集中封装了我们全部的查询出来的结果 ResultSet resultSet = statement.executeQuery(sql); while (resultSet.next()){ //以链表形式存放 System.out.println(&quot;id=&quot;+resultSet.getObject(columnLabel: &quot;id&quot;)); System.out.println(&quot;name=&quot;+resultSet.getObject(columnLabel: &quot;NAME&quot;)); System.out.println(&quot;pwd=&quot;+resultSet.getObject(columnLabel: &quot;PASSWORD&quot;)); System.out.println(&quot;email=&quot;+resultSet.getObject(columnLabel: &quot;email&quot;)); System.out.println(&quot;birth=&quot;+resultSet.getObject(columnLabel: &quot;birthday&quot;)); } //6. 释放连接 resultSet.close(); statement.close(); connection.close();//耗资源，用完关掉！} statement对象JDBC中的statement对象用于向数据库发送SQL语句，想完成对数据库的增删改查，只需要通过这个对象向数据库发送增删改查语句即可。 Statement对象的executeUpdate方法，用于向数据库发送增、删、改的sql语句，executeUpdate执行完后，将会返回一个整数（即增删改语句导致了数据库几行数据发生了变化）。 Statement.executeQuery方法用于向数据库发送查询语句，executeQuery方法返回代表查询结果的ResultSet对象。 PrepareStatement对象此外，可以用PrepareStatement代替Statement，来防止SQL注入的问题。 具体方法：将sql语句中的值用？代替，再用set方法进行赋值。 PrepareStatement能够防止SQL注入的本质，把传递进来的参数当作字符，假设其中存在转义字符，则会直接转义，如 ‘ 。 1234567-- PrepareStatement对象使用方法conn = DriverManager.getConnection(url，username，password);string sql = &quot;select * from users where `NAME`=? and `PASSWORD`=?&quot;;st = conn.prepareStatement(sql);st.setString(parameterlndex: 1,username);st.setString(parameterlndex: 2,password); 事务的JDBC实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public static void main (string[] args） { connection conn = null; PreparedStatement st = null; ResultSet rs = null; try { // ------------数据库配置------------ //加载驱动 class.forName(&quot;com.mysql.jdbc.Driver&quot;);//固定写法，加载驱动 //用户信息和url //useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=true String url = &quot;jdbc:mysql://localhost:3306/jdbcstudy?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=true&quot;; String username = &quot;root&quot;; String password = &quot;123456&quot;; //连接成功，数据库对象Connection代表数据库 conn = DriverManager.getConnection(url，username，password); // -----------事务配置----------- //1. 关闭数据库的自动提交，自动会开启事务 conn.setAutocommit(false)；//开启事务 //2. 设置事务内容 String sql1 = &quot;update account set money = money-100 where name = 'A'&quot;; st = conn. prepareStatement(sql1); st.executeUpdate(); int x = 1/0; //报错，如果报错，即会回滚，即sql1和sql2都无法实现 String sql2 = &quot;update account set money = money+100 where name = 'B '&quot;; st = conn.prepareStatement(sql2); st.executeUpdate(); //3. 业务完毕，提交事务 conn.commit(); system.out.println(&quot;成功!&quot;); } catch (SQLException e) { //如果失败，则默认回滚 //try { //conn.rollback(); //如果失败则回滚事务 //} catch (SQLException e1) { //e1.printStackTrace();} e.printStackTrace(); } finally{ // 关闭资源，此处省略了异常处理，实际上需要进行异常处理，如if re!=null:.... re.close(); st.close(); conn.close(); }}","link":"/2023/01/25/JDBC/"},{"title":"MySQL学习（一）","text":"本系列主要进行MySQL数据库的学习介绍，其中本篇文章介绍MySQL的一些基本概念和基本操作，包括初识数据库，基本的命令行操作，和对数据库的部分操作（数据库的创建、表的创建）等。 初识MySQL什么是数据库数据库（DB, DataBase） 概念：数据仓库，软件，安装在操作系统（Windows, Linux, Mac…）之上！使用SQL语句，可以存储大量的数据； 作用：存储数据，管理数据。 数据库分类关系型数据库：（SQL） Mysql, Oracle, Sql, Server, DB2…； 通过表和表之间，行和列之间的关系进行数据的存储；（学院信息表，考勤表…） 非关系型数据库：（NoSQL） Not Only Redis, MongDB； 非关系型数据库，对象存储，通过对象的自身的属性来决定。 DBMS（数据库管理系统） 数据库的管理软件，科学有效的管理我们的数据，维护和获取数据； MySQL本质上是一个数据库管理系统。 sqlyog的使用创建数据库：选择字符集character为utf8，排列规则collate为utf8_general_ci； 每一个sqlyog的执行操作，本质就是对应了一个sql，可以在软件的历史记录中查看。 基本的命令行操作123456789101112131415161718192021222324252627mysql -uroot -p123456 --连接数据库update mysql.user set authentication_string=password('123456') where user='root' and Host='localhost'; -- 修改密码flush privileges; -- 刷新权限------------------------------------------------------------------------------------- 所有的语句都使用；结尾show databases; -- 查看所有数据库use school; -- 切换数据库 use+数据库名show tables; -- 查看数据库中的所有的表describe student; -- 显示数据库中表的信息 describe+表名create database westos; -- 创建一个数据库 create database+数据库名exit; -- 退出连接-- 单行注释 （SQL本来的注释）/* （SQL的多行注释）helloasdas*/ 数据库xxx语言（CURD增删改查）：DDL 定义；DML 操作；DQL 查询；DCL控制 操作数据库操作数据库 &gt; 操作数据库中的表 &gt; 操作数据库中表的数据 ==MySQL中的关键字不分大小写== 操作数据库（了解）1. 创建数据库 CREATE DATABASE [IF NOT EXISTS] westros; 2.添加数据库 DROP DATABASE [IF EXISTS] westros; 3.删除数据库 – 如果表名或字段名是一个特殊字符，就需要带 USE school; 4.查看数据库 SHOW DATABASES; 数据库的列类型（了解）数值： tinyint 十分小的数据 1个字节 smallint 较小的数据 2个字节 mediumint 中等大小的数据 3个字节 int 标准的整数 4个字节 常用 对应java的int bigint 较大的数据 8个字节 float 浮点数 4个字节 double 浮点数 8个字节 decimal 字符串形式的浮点数 金融计算的时候一般使用 字符串： char 字符串，固定大小 0-255 varchar 可变字符串 0-65535 常用 对应java的String tinytext 微型文本 2^8-1 text 文本串 2^16-1 保存大文本 时间日期： data YYYY-MM-DD 日期格式 time HH:mm:ss 时间格式 datetime YYYY-MM-DD HH:mm:ss 最常用的时间格式 timestamp 时间戳，1970.1.1到现在的毫秒数，也较为常用 year 年份表示 null： 没有值，未知 注意：不要使用null进行运算，结果为null 数据库的字段属性（重点）Unsigned: 无符号的整数； 声明了该列不能声明为负数 zerofill： 0填充的； 不足的位数，使用0来填充。如int(3)：5…005 自增： 自动在上一条记录中加一（默认）； 通常用来设置唯一的主键——index，必须是整数类型； 可自定义设计主键自增的起始值和步长。 非空 null / not null： 假设设置为not null ，如果不给它赋值，就会报错； null，如果不填写值，默认就是null 默认： 设置默认的值； 如：sex，默认值为男，如果不指定该列的值，则会有默认的值 拓展： 每一个表，都必须存在以下五个字段。未来做项目用的，表示一个记录存在意义。 id：主键；version：乐观锁；is_delete：伪删除；gmt_create：创建时间；gmt_update：修改时间 创建数据库表（重点）例子：创建一个表student，包含id，名称，性别等字段 12345678910111213141516-- 通常字段都加上``，避免出现特殊字符-- 表名后用英文括号()-- 字符串用单引号括起来-- 表中所有语句后面加英文逗号，最后一个不用加-- AUTO_INCREMENT自增-- PRIMARY KEY 主键，一般一个表只有一个唯一的主键CREATE TABLE IF NOT EXISTS `student`(`id` INT(4) NOT NULL AUTO_INCREMENT COMMENT '学号',`name` VARCHAR(30) NOT NULL DEFAULT '匿名' COMMENT '姓名',`password` VARCHAR(20) DEFAULT '123456' COMMENT '密码',`sex` VARCHAR(2) NOT NULL DEFAULT '女' COMMENT '性别',`birthday` DATETIME DEFAULT NULL COMMENT '出生日期',PRIMARY KEY(`id`) )ENGINE=INNODB DEFAULT CHARSET=utf8`student` 格式： CREATE TABLE [IF NOT EXISTS] 表名 ( 字段名 列类型 [属性] [索引] [注释], 字段名 列类型 [属性] [索引] [注释], …… 字段名 列类型 [属性] [索引] [注释] )[表类型] [字符集设置] [注释] 查看创建数据库的语句：SHOW CREATE DATABASE school 查看数据表的定义语句：SHOW CREATE TABLE student 不会写的时候可以用来看代码。 显示表的结构：DESC student 数据表的类型关于数据库引擎： INNODB：默认使用。安全性高，事物的处理强，支持多表多用户操作； MYISAM：早些年使用。节约空间，速度较快。 在物理空间的位置： 所有的数据库均存在data文件夹中，本质还是文件的存储。 数据库引擎在物理文件上的区别： INNODB在数据库表中只有一个*.frm文件，以及上级目录下的ibdata1文件； MYISAM对应的文件有：*.frm –表结构定义文件；*.MYD –数据文件；*.MYI –索引文件 修改和删除数据库表123456789101112131415161718192021-- **修改表的字段：**-- 修改表名：ALTER TABLE 旧表名 RENAME AS 新表名ALTER TABLE teacher RENAME AS teacher1-- 增加表的字段 ALTER TABLE 表明 ADD 字段名 列属性ALTER TABLE teacher1 ADD age INT(11)-- 修改表的字段（重命名，修改约束）-- ALTER TABLE 表名 MODIFY 字段名 列属性ALTER TABLE teacher1 MODIFY age VARCHAR(11) -- 修改约束，用MODIFY-- ALTER TABLE 表名 CHANGE 旧名字 新名字 列属性ALTER TABLE teacher1 CHANGR age age1 INT(1) -- 字段重命名，用CHANGE-- **删除表的字段：**-- ALTER TABLE 表名 DROP 要删除的字段ALTER TABLE teacher1 DROP age1 --DROP用来删除**删除表：（如果表存在）**DROP TABLE IF EXISTS teacher1 注：所有的创建和删除操作尽量加上判断，以免报错","link":"/2023/01/25/MySQL%E4%B8%80/"},{"title":"MySQL学习（三）","text":"本系列主要进行MySQL数据库的学习介绍，其中本篇文章介绍MySQL的其它概念，包括事务，索引，权限管理和备份，规范数据库设计等。 事务什么是事务：要么都成功，要么都失败 将一组SQL放在一个批次中执行 事务原则：ACID原子性，一致性，隔离性，持久性 原子性：这些步骤要么一起成功，要么一起失败，不能只发生一个动作。例子：A和B转账； 一致性：事务在完成后，符合逻辑运算；即事务前后的数据完整性要保持一致； 持久性：事务没有提交，恢复到原状；事务已经提交，持久化数据库。即事务结束后的数据不随着外界原因导致数据丢失； 隔离性：多个用户并发访问数据库时，数据库为每一个用户开启的服务，不能被其它事务的操作数据所干扰；即事务之间要相互隔离。 未正常隔离的话，会导致一些问题： 脏读：事务同时进行，其中一个事务读取到另外一个事务还没有提交的数据； 不可重复读：在一个事务内读取表的某一行数据，多次读取结果不同。（这个不一定是错误，只是某些场合不对）； 虚读（幻读）：是指在一个事务内读取到了别的事物插入的数据，导致前后读取不一致。 123456789101112131415161718192021222324252627282930-- ------------------------------事务例子-------------------------------------SET autocommit = 0 -- 关闭SET autocommit = 1 -- 开启（默认的）-- 手动处理事务SET autocommit = 0 -- 关闭自动提交-- 事务开启START TRANSACTION -- 标记一个事务的开始，从这个之后的sql都在同一个事务内-- 要执行的一组事务INSERT XXXINSERT XXXUPDATE XXX-- .....-- 提交：持久化COMMIT-- 回滚：回到原来的样子ROLLBACK-- 事务结束SET autocommit = 1 -- 开启自动提交-- 设置保存点（了解） 可选SAVEPOINT 保存点名 -- 设置一个事务的保存点ROLLBACK TO SAVEPOINT 保存点名 -- 回滚到保存点RELEASE SAVEPOINT 保存点名 -- 撤销保存点 索引MySQL官方对索引的定义为：索引（index）是帮助MySQL高效获取的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。 索引的分类： 在一个表中，主键索引只能有一个，而唯一索引可以有多个 主键索引（PRIMARY KEY） 唯一标识：主键不可重复，只能有一个列作为主键 唯一索引（UNIQUE KEY） 避免重复的列出现，唯一索引可以重复，多个列都可以标识为唯一索引 常规索引（KEY/INDEX） 默认的，可以用index或key关键字来设置 全文索引（FULLTEXT） 在特定的数据引擎下才有，MyISAM； 快速定位数据。 12345678910111213141516171819202122232425262728293031323334353637383940-- ------------------------------索引例子--------------------------------------- 1.创建表时增加索引-- 2.创建完毕后，增加索引-- 显示所有的索引信息SHOW INDEX FROM student-- 增加一个索引，此处增加全文索引 4式：索引名（列名）ALTER TABLE student ADD FULLTEXT INDEX `studentname`(`studentname`)-- 分析sql执行的状况 EXPLAINEXPLAIN SELECT * FROM student -- 非全文索引SELECT * FROM student WHERE MATCH(`studentname`) AGAINST('张') -- 全文索引-- 测试索引-- sql也可以用来编程-- 插入100万条数据DELIMITER $$ -- 写函数之前必须要写，当作标志CREATE FUNCTION mock_data()RETURN INTBEGIN -- 函数体 DECLARE num INT DEFAULT 1000000; DECLARE i INT DEFAULT 0; WHILE i&lt;num DO -- 插入语句 INSERT ... SET i = i+1; END WHILEEND;-- 创建一个索引-- 命名方式：CREATE INDEX 索引名 on 表(字段)CREATE INDEX id_student_phone ON student(`phone`)-- 进行查询，当数据量很大时索引能够提升很大的性能-- 因为创建索引时内部为一个树结构，能够很快实现遍历SELECT * FROM student WHERE `phone`='13800002222' 总结：索引在小数据量的时候，用处不大；但是在大数据的时候，区别十分明显。 索引原则： 索引不是越多越好； 不要对经常变动的数据增加索引； 小数据量的表不需要加索引； 索引一般加在常用来查询的字段上。 索引的数据结构： Hash 类型的索引 Btree：Innodb默认的数据结构 权限管理和备份用户管理123456789101112131415161718192021222324-- ---------------------------数据库用户管理---------------------------------- 创建用户 CREATE USER 用户名 identified BY '密码'CREATE USER tzh666 IDENTIFIED BY '123456'-- 修改当前用户密码SET PASSWORD = PASSWORD('123456')-- 修改指定用户密码SET PASSWORD FOR tzh666 = PASSWORD('111111')-- 重命名： 原名字 to 新名字RENAME USER tzh666 TO tianzehao-- 用户授权 ALL PRIVILEGES: 全部权限，库，表-- ALL PRIVILEGES：除了GRANT其它都有，即不能给别的用户授权GRANT ALL PRIVILEGES ON *.* TO tianzehao-- 查看指定用户的权限SHOW GRANTS FOR tianzehao SHOW GRANTS FOR root@localhost -- 撤销权限 REVOKE 哪些权限，在哪个库撤销，给谁撤销REVOKE ALL PRIVILEGES ON *.* FROM tianzehao 数据库备份为什么要备份： 保证重要的数据不丢失； 数据转移 MySQL数据库备份的方式： 直接拷贝物理文件； 在Sqlyog这种可视化工具中手动导出； 使用命令行导出 mysqldump命令行使用。 导出一张表：mysqldump -h主机 -u用户名 -p 密码 数据库 表名 &gt; 物理磁盘位置； 导出多张表：mysqldump -h主机 -u用户名 -p 密码 数据库 表1 表2 表3 &gt; 物理磁盘位置； 导入数据库所有文件：mysqldump -h主机 -u用户名 -p 密码 数据库 &gt; 物理磁盘位置； 命令行导入：登录的情况下，切换到指定的数据库。具体方法：source 备份文件路径 规范数据库设计为什么要进行数据库设计当数据库比较复杂时，就需要设计了。 糟糕的数据库设计： 数据冗余，浪费空间； 数据库的插入和删除都会麻烦、异常（屏蔽使用物理外键）； 程序的性能差。 良好的数据设计： 节省内存空间； 保证数据库的完整性； 方便我们开发系统。 软件开发中，关于数据库的设计： 分析需求：分析业务和需要处理的数据库的需求； 概要设计：设计关系图 E-R图。 数据库设计三大范式为什么要进行数据规范化： 信息重复，更新异常，插入异常，删除异常 第一范式（1NF）： 要求数据库表的每一列都是不可分割的原子数据项。 原子性：保证每一列不可再分。 第二范式（2NF）： 前提：满足第一范式 确保数据库表的每一列都和主键相关，而不能值与主键的某一部分相关。即每张表只描述一件事情。 第三范式（3NF）： 前提：满足第二范式 确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 规范性和性能的问题： 阿里的规范：关联查询的表不得超过三张表 考虑商业化的需求和目标，（成本，用户体验）数据库的性能更加重要； 在规范性能的问题的时候，需要适当的考虑一下规范性； 故意给某些表增加一些冗余的字段（从多表查询中变为单表查询）； 故意增加一些计算列（从大数据量降低为小数据量的查询）","link":"/2023/01/25/MySQL%E4%B8%89/"},{"title":"MySQL学习（二）","text":"本系列主要进行MySQL数据库的学习介绍，其中本篇文章介绍MySQL的数据管理，包括外键的介绍、数据库操作语言（DML），数据查询语言（DQL）等。 MySQL数据管理外键（了解）不采用物理外键，避免数据库过多造成困扰，因此不建议使用。 最佳实现方案： 数据库就是单纯的表，只有行（数据）和列（字段）； 我们想使用多张表的数据，想使用外键，采用程序去实现。 DML语言（全部记住）DML语言：数据操作语言 1. 添加INSERT： 12345678910-- 插入语句-- INSERT INTO 表名(字段名1, 字段名2, 字段名3) values ('值1', '值2', '值3', ...)-- 由于主键自增，我们可以省略 -- 如果不写表的字段，则会一一匹配；因此一般写插入语句，一定要数据和字段一一对应INSERT INTO`student`(`name`, `password`, `sex`) VALUES ('张三', '111111', '男')-- 插入多条语句-- INSERT INTO 表名(字段名1, 字段名2, 字段名3) values ('值1', '值2', '值3'), ('值1', '值2', '值3')INSERT INTO `student`(`name`) VALUES ('王五'), ('李四') 语法：INSERT INTO 表名(字段名1, 字段名2, 字段名3) values (‘值1’, ‘值2’, ‘值3’, …) 注意： 字段和字段之间用英文逗号隔开； 字段是可以省略的，但字段和值要一一对应，且不能少； 可以同时插入多条数据，但values后面的值需要英文逗号隔开。 2. 修改UPDATE： 123456789-- 修改学员名字UPDATE `student` SET `name`='狂神' WHERE `id`=3-- 不指定条件的话，会改动所有表UPDATE `student` SET `name`='长江7号'-- 修改多个属性，逗号隔开UPDATE `student` SET `name`='狂神', `password`='123456' WHERE `id`=3 语法：UPDATE 表名 SET column_name=value, [column_name=value…] WHERE [条件] （column_name=value, [column_name=value…]表明要修改的字段和要修改的值，可以一次修改多个字段） 条件语句：where 子句 ； 子句包括：运算符，id等于某个值/大于/某个区间，如：id&lt;5，id between 2 and 5(闭合), id=2 or id=5, `name`=’张三’ and `sex`=`女` 注意： column_name是数据库的列，尽量带上 ； value可以是一个值，也可以是一个变量； 条件语句用于筛选，如果没有条件语句，则会筛选所有的列； 多个设置的属性之间，使用英文逗号隔开。 3. 删除DELETE： 语法：DELETE FROM 表名 WHERE [条件] 清空数据表： TRUNCATE 表名：完全清空一个数据库表，表的结构和索引约束不会变 TRUNCATE和DELETE相同点：都能删除数据，都不会改变表的结构； TRUNCATE和DELETE不同点： TRUNCATE会重新设置，自增列、计数器会归零；不会影响事务 DELETE不会重新设置，不会影响自增； 了解即可（采用DELETE删除）：重启数据库，现象： lnnoDB引擎：自增列会从1开始(存在内存当中的，断电即失)； MylSAM引擎：继续从上一个自增量开始(存在文件中的，不会丢失) 4. 了解：MD5加密 在插入或更新时进行，如： INSERT INTO`student`(`name`,`password`, `sex`) VALUES (‘张三’, MD5(‘111111’), ‘男’) 如何校验： 将用户传递进来的密码，进行md5加密，然后对比加密后的值，如： SELECT * FROM `student` WHERE `name`=’张三’ and `password`=MD5(‘111111’) DQL查询数据（最重点） 注：顺序很重要 DQL：Data Query Language 数据查询语言 所有的查询都要用它 Select； 简单的查询，复杂的查询都能做； 数据库中最核心的语言，最重要的语句，使用频率最高的语句。 指定查询字段123456789101112-- 查询全部的学生 SELECT 字段 FROM 表SELECT * FROM student-- 查询指定字段SELECT `StudentNo`, `StudentName` FROM student -- 别名 给结果起一个名字 AS 可以给字段起别名，也可以给表起别名SELECT `StudentNo` AS 学号, `StudentName` AS 学生姓名 FROM student-- 函数 Concat(a,b) 连接字符串SELECT CONCAT('姓名：', StudentName) AS 新名字 FROM student 语法：SELECT 字段…. FROM 表名 有的时候，列名字不是那么的见名知意，可以起别名。语法：字段名/表名 AS 别名 去重：DISTINCT 作用：去除SELECT语句查询出来的结果中重复的数据，重复的数据只显示一条 12SELECT DISTINCT `StudentNo` FROM result -- 查询有哪些同学参加了考试，去重 数据库的列（表达式）： 1234567SELECT VERSION() -- 查询系统版本（函数）SELECT 100*3-1 AS 计算结果 -- 用来计算（表达式）SELECT @@auto_increment_increment -- 查询自增的步长（变量）-- 学员考试成绩+1分 查看SELECT `StudentNo`, `StudentResult`+1 AS '提分后' FROM result 数据库中的表达式：文本值，列，函数，null，计算表达式，系统变量… SELECT 查询表达式语法：SELECT 表达式 FROM 表 where条件子句作用：检索数据中符合条件的值。 搜索的条件由一个或多个表达式构成，返回值为布尔类型。 逻辑运算符：and(&amp;&amp;) or(||) not(!) 尽量使用英文； 模糊查询：比较运算符 is null – 如果操作符为null，结果为真； is not null – 如果操作符不为null，结果为真； between a and b – 如果值在a和b之间，结果为真； a like b – SQL匹配，如果a匹配b，则结果为真；like可以与%，_等符号结合（见例子）； a in (a1, a2..) – 假设a在a1，或者a2…中，则结果为真；in后面为具体的一个或多个值。 例子：– where的使用 1234567-- 查询考试成绩在95~100分之间的学生SELECT `StudentNo`, `StudentResult` FROM result WHERE `StudentResult`&gt;=95 AND `StudentResult`&lt;=100-- 查询姓张的同学-- like结合 %（代表0到任意个字符） _（一个字符） 类似与正则表达式SELECT `studentno`, `studentname` FROM `student` WHERE `studentname` LIKE '张%' 联表查询 JOIN … ON…例子：联表查询 多个表一起 JOIN 1234567891011121314151617181920212223242526272829-- 查询参加了考试的同学（学号，姓名，科目编号，分数）/* 思路：1.分析需求，分析查询的字段来自哪些表--student和result2.确定使用那种连接查询--七种3.确定交叉点（两个表中哪些数据是相同的）--studentno判断条件：student表中的studentno = result表中的studentno*/-- 注意，交叉处要具体指出查询的是哪个表，不然会出现模棱两可的错误，因此此处为s/r.`studentno`SELECT s.`studentno`, `studentname`, `subjectno`, `studentresult`FROM student AS s INNER JOIN result AS rON s.`studentno`=r.`studentno` SELECT s.`studentno`, `studentname`, `subjectno`, `studentresult`FROM student AS s RIGHT JOIN result AS rON s.`studentno`=r.`studentno`-- 此处不能左连接，会出现在s中不在r中的值被查询到-- SELECT r.`studentno`, `studentname`, `subjectno`, `studentresult`-- FROM student AS s LEFT JOIN result AS r-- ON s.`studentno`=r.`studentno`-- 查询缺考的同学（学号，姓名，科目编号，分数）SELECT r.`studentno`, `studentname`, `subjectno`, `studentresult`FROM student AS s LEFT JOIN result AS rON s.`studentno`=r.`studentno`WHERE `studentresult` IS NULL 总结： inner join：如果表中有一个匹配的值，就返回该值； left join：会从左表中返回所有的值，即使右表中没有匹配； right join：会从左表中返回所有的值，即使右表中没有匹配； 语法： – join on 连接查询；–join where 等值查询 多张表联表： 123456789101112131415161718192021-- 查询参加了考试的同学（学号，姓名，科目名，分数）/* 思路：1.分析需求，分析查询的字段来自哪些表--student和result和subject2.确定使用那种连接查询--七种3.确定交叉点（两个表中哪些数据是相同的）--studentno判断条件：student表中的studentno = result表中的studentno result表中的subjectno = subject表中的subjectno */SELECT s.`studentno`, `studentname`, `subjectname`, `studentresult`FROM student AS sRIGHT JOIN result AS rON s.`studentno` = r.`studentno`INNER JOIN `subject` AS subON r.`subjectno` = sub.`subjectno`-- 技巧-- 我要查询哪些数据 select ...-- 从哪几个表中查 from 表 XXX join 连接的表 on 交叉条件-- 假设存在多个表的查询，则先查询两张表再慢慢增加 自连接： 自己的表和自己的表连接，核心：一张表拆成两张一样的表即可 例子：– 联表查询 查询父子信息 1234SELECT a.`categoryName` AS '父栏目', b.`categoryName` AS '子栏目'FROM `category` AS a, `category` AS bWHERE a.`categoryid` = b.`pid` 分页LIMIT 和排序ORDER BY排序语法：– ORDER BY 通过哪个字段排序 怎么排 其中，排序方式为升序（ASC）和降序（DESC） 分页：为了缓解数据库压力，给人的体验更好 分页语法: LIMIT 起始值, 页面的大小 前端用： 第N页： LIMIT (N-1)*pagesize, pagesize 子查询子查询方式：多个SELECT嵌套，执行顺序为由里向外 例子：子查询 查询高等数学-1 的所有考试结果（学号，科目编号，成绩）降序排列 1234567891011121314151617-- 方式一：连接查询SELECT `studentno`, s.`subjectno`, `studentresult`FROM `result` AS rINNER JOIN `subject` AS sON s.`subjectno` = r.`subjectno`WHERE `subjectname` = '高等数学-1'ORDER BY `studentresult` DESC-- 方式二：子查询SELECT `studentno`, `subjectno`, `studentresult`FROM `result` WHERE `subjectno` = (SELECT `subjectno` FROM `subject`WHERE `subjectname` = '高等数学-1' )ORDER BY `studentresult` DESC MySQL函数123456789101112131415161718192021222324252627282930313233343536373839-- ------------ 常用函数 ---- ----------SELECT ABS(-8) -- 绝对值SELECT CEILING(9.4) -- 向上取整SELECT FLOOR(9.4) -- 向下取整SELECT RAND() -- 返回0-1随机数SELECT SIGN(-5) -- 返回参数的符号 0~0 负数~-1 正数~1-- 字符串函数SELECT CHAR_LENGTH('123456789')SELECT CONCAT('我','爱','你')SELECT INSERT('我爱编程', 2, 1, '超级热爱') -- 插入替换，从某个位置开始替换某个长度 --我超级热爱编程-- 时间和日期SELECT CURRENT_DATE() -- 获取当前日期SELECT NOW() -- 获取当前时间SELECT LOCALTIME() -- 获取本地时间SELECT SYSDATE() -- 获取系统时间-- ------------ 聚合函数 ---- ------------ COUNT()计数；SUM()求和；AVG()平均值；MAX()最大值… SELECT COUNT(`studentname`) FROM student -- COUNT(字段)，查询字段记录数 会忽略所有的nullSELECT COUNT(*) FROM student -- COUNT(*)，不会忽略所有的nullSELECT COUNT(1) FROM student -- COUNT(1)，不会忽略所有的null 分组和过滤 GROUP BY … [HAVING]123456789-- 查询不同课程的平均分，最高分，最低分，平均分大于80-- 核心：根据不同的课程分组SELECT `subjectname`, AVG(`studentresult`) AS average, MAX(`studentresult`), MIN(`studentresult`)FROM result AS rINNER JOIN `subject` AS subON r.`subjectno` = sub.`subjectno`GROUP BY r.`subjectno` -- 通过什么字段来分组HAVING average &gt; 80 -- 过滤分组后的记录必须满足的次要条件","link":"/2023/01/25/MySQL%E4%BA%8C/"},{"title":"MyBatis（四）","text":"本系列主要进行MyBatis框架的学习介绍，其中本篇文章介绍MyBatis中多对一和一对多的处理。 多对一处理举例说明： 多个学生，对应一个老师； 对于学生这边而言，关联… 多个学生，关联一个老师【多对一】； 对于老师而言，集合… 一个老师，有很多学生【一对多】 测试环境搭建 导入Lombok，实体类编写偷懒； 新建实体类 Teacher Studednt； 建立Mapper接口； 建立Mapper.xml文件； 在核心配置文件中绑定我们的Mapper接口或者文件； 测试查询是否能够成功。 实体类创建： 12345678910111213141516@Datapublic class Student{ private int id; private String name; //学生需要关联一个老师 private Teacher teacher;}@Datapublic class Teacher{//老师就是单纯的老师 private int id; private String name;} 按照查询嵌套处理1234567891011121314151617181920212223&lt;!--思路：1.查询所有的学生信息；2.根据查询出来学生的tid，寻找对应的老师；-类似于**子查询**--&gt;&lt;select id=&quot;getStudent&quot; resultMap=&quot;StudentTeacher&quot;&gt; select * from student&lt;/select&gt;&lt;resultMap id=&quot;StudentTeacher&quot; type=&quot;Student&quot;&gt; &lt;result property=&quot;id&quot; column=&quot;id&quot;/&gt; &lt;result property=&quot;name&quot; column=&quot;name&quot;/&gt; &lt;!--复杂的属性，需要单独处理对象：association集合：collection--&gt; &lt;!--嵌套了另一个select语句，实现联表查询--&gt; &lt;association property=&quot;teacher&quot; column=&quot;tid&quot; javaType=&quot;Teacher&quot; select=&quot;getTeacher&quot;/&gt;&lt;/resultMap&gt;&lt;select id=&quot;getTeacher&quot; resultType=&quot;Teacher&quot;&gt; select * from teacher where id=#{id}&lt;/select&gt; 按照结果嵌套处理123456789101112131415161718192021&lt;!--思路：1.查询所有的学生信息；2.根据查询出来学生的tid，寻找对应的老师；-类似于**联表查询**--&gt;&lt;select id=&quot;getStudent2&quot; resultMap=&quot;StudentTeacher2&quot;&gt; select s.id sid,s.names name,t.name tname from student s,teacher t where s.tid=t.id&lt;/select&gt;&lt;resultMap id=&quot;StudentTeacher2&quot; type=&quot;Student&quot;&gt; &lt;result property=&quot;id&quot; column=&quot;sid&quot;/&gt; &lt;result property=&quot;name&quot; column=&quot;sname&quot;/&gt; &lt;association property=&quot;teacher&quot; javaType=&quot;Teacher&quot;&gt; &lt;result property=&quot;name&quot; column=&quot;tname&quot;/&gt; &lt;/association&gt;&lt;/resultMap&gt; 推荐使用第二种，即按结果嵌套查询，变化sql实现复杂功能。 一对多处理比如：一个老师拥有多个学生，对于老师而言，就是一对多。 实体类创建： 1234567891011121314151617@Datapublic class Student{ private int id; private String name; //学生是单纯的学生 private int tid;}@Datapublic class Teacher{ private int id; private String name; //一个老师对应多个学生 private List&lt;Student&gt; students;} 按照查询嵌套处理12345678910111213&lt;!--按查询嵌套查询--&gt;&lt;select id=&quot;getTeacher&quot; resultMap=&quot;TeacherStudent&quot;&gt; select * from teacher where id=#{tid}&lt;/select&gt;&lt;resultMap id=&quot;TeacherStudent&quot; type=&quot;Teacher&quot;&gt; &lt;collection property=&quot;students&quot; column=&quot;id&quot; javaType=&quot;ArrayList&quot; ofType=&quot;Student&quot; select=&quot;getStudentByTeacherId&quot;/&gt;&lt;/resultMap&gt;&lt;select id=&quot;getStudentByTeacherId&quot; resultType=&quot;Student&quot;&gt; select * from student where tid=#{tid}&lt;/select&gt; 按照结果嵌套处理123456789101112131415161718&lt;select id=&quot;getTeacher2&quot; resultMap=&quot;TeacherStudent2&quot;&gt; select s.id sid,s.name sname,t.name tname,t.id tid from student s,teacher t where s.tid=t.id and t.id=#{tid}&lt;/select&gt;&lt;resultMap id=&quot;TeacherStudent2&quot; type=&quot;Teacher&quot;&gt; &lt;result property=&quot;id&quot; column=&quot;tid&quot;/&gt; &lt;result property=&quot;name&quot; column=&quot;tname&quot;/&gt; &lt;!--javaType=&quot;&quot;：指定属性的类型，对于集合中的泛型信息（此处为List&lt;Student&gt;），我们使用ofType获取--&gt; &lt;collection property=&quot;students&quot; ofType=&quot;Student&quot;&gt; &lt;result property=&quot;id&quot; column=&quot;sid&quot;/&gt; &lt;result property=&quot;name&quot; column=&quot;sname&quot;/&gt; &lt;result property=&quot;tid&quot; column=&quot;tid&quot;/&gt; &lt;/collection&gt;&lt;/resultMap&gt; 总结： 1.关联- association【多对一】； 2.集合- collection【一对多】; 3.javaType &amp; ofType javaType 用来指定实体类中属性的类型; ofType用来指定映射到List或者集合中的pojo类型，泛型中的约束类型! 注意点: 保证SQL的可读性，尽量保证通俗易懂； 注意一对多和多对一中，属性名和字段的问题! 如果问题不好排查错误，可以使用日志，建议使用Log4j","link":"/2023/02/03/MyBatis%E5%9B%9B/"},{"title":"MyBatis（一）","text":"本系列主要进行MyBatis框架的学习介绍，其中本篇文章介绍MyBatis的一些基本概念和基本操作，包括初识MyBatis，第一个MyBatis程序的搭建，和基本的增删改查操作等。 初识MyBatis什么是MyBatis MyBatis 是一款优秀的持久层框架； 它支持定制化 SQL、存储过程以及高级映射； MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集； MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的 POJO (Plain Old Javaobjects，普通老式 Java 对象）为数据库中的记录； MyBatis原本本是apache的一个开源项目iBatis，2010年这个项目由apache software foundation迁移到了google code，并且改名为MyBatis； 2013年11月迁移到Github。 持久化数据持久化： 持久化就是将程序的数据在持久状态和瞬时状态转化的过程； 内存：断电即失； 数据库(Jdbc)，io文件持久化； 生活案例：冷藏，罐头…。 为什么需要需要持久化？ 有一些对象，不能让他丢掉； 内存太贵了。 持久层 完成持久化工作的代码块； 层的界限十分明显。 为什么需要Mybatis 帮助程序猿将数据存入到数据库中； 方便； 传统的JDBC代码太复杂了。简化。框架。自动化； 不用Mybatis也可以。更容易上手。技术没有高低之分； 优点：简单易学。灵活； 实现了sql和代码的分离。提高了可维护性； 提供映射标签，支持对象与数据库的orm字段关系映射； 提供对象关系映射标签，支持对象关系组建维护； 提供xml标签，支持编写动态sql。 第一个MyBatis程序搭建环境新建项目： 新建一个普通的maven项目； 删除src目录； 导入maven依赖 创建一个模块 编写mybatis核心配置文件：mybatis-config.xml 1234567891011121314151617181920212223&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPEconfigurationPUBLIC&quot;-//mybatis.org//DTDConfig3.0//EN&quot;&quot;https://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;!--configuration核心配置文件--&gt;&lt;configuration&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transaction Managertype=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?useSSL=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=UTF-8&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=&quot;org/mybatis/example/BlogMapper.xml&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 编写mybatis工具类：MybatisUtils.class 12345678910111213141516171819202122//获取sqlSessionFactory对象-&gt;获取sqlSession实例public class MybatisUtils{ private static SqlSessionFactory sqlSessionFactory;//提升作用域，在方法下使用 //一初始就加载了 static{ try{ //使用Mybatis第一步：获取sqlSessionFactory对象 String resource = &quot;mybatis-config.xml&quot;; InputStreaminputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = newSqlSessionFactoryBuilder().build(inputStream); } catch(IOExceptione){ e.printStackTrace(); } } //从SqlSessionFactory中获得SqlSession的实例。 //SqlSession提供了在数据库执行SQL命令所需的所有方法 public static SqlSession getSqlSession(){ return sqlSessionFactory.openSession(); }} 编写代码 实体类：User.class Dao接口：UserDao.impl 1234public interface UserDao{ List&lt;User&gt; getUserList();} 接口实现类：由原来的UserDaoImpl转变为一个Mapper配置文件：UserMapper.xml` 123456789101112131415&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPEmapperPUBLIC&quot;-//mybatis.org//DTDMapper3.0//EN&quot;&quot;https://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;!--namespace=绑定一个对应的Dao/Mapper接口--&gt;&lt;mapper namespace=&quot;dao.UserDao&quot;&gt; &lt;!--select查询语句--&gt; &lt;select id=&quot;getUserList&quot; resultType=&quot;pojo.User&quot;&gt; select * from mybatis.user &lt;/select&gt;&lt;/mapper&gt; Junit测试注意点，一个报错： org.apache.ibatis.binding.BindingException: Type interface com.kuang.dao.UserDao is not known to the MapperRegistry. MapperRegistry是什么? 核心配置文件中注册mappers的文件。 测试文件：UserDaoTest.class 123456789101112131415161718@Testpublic void test(){ //1.获得sqlSession对象 SqlSession sqlSession = MybatisUtils.getSqlSession(); //2.执行SQL //方式一：getMapper UserDaomapper = sqlSession.getMapper(UserDao.class); List&lt;User&gt; userList = mapper.getUserList(); for(Useruser:userList){ System.out.println(user); } //关闭SqlSession sqlSession.close();} CRUD增删改查namespacenamespace中的包名要和Dao/mapper接口的包名一致。 如：namespace为dao.UserMapper，绑定了UserMapper接口。 select选择，查询语句； id：就是对应namespace中的方法名； resultType：SQL语句执行的返回值； parameterType：参数类型 具体步骤： 12345678910111213141516171819202122//1.编写接口//根据id查询用户User getUserById(int id);//2.编写xml配置文件，即对应mapper中的sql语句&lt;select id=&quot;getUserById&quot; parameterType=&quot;int&quot; resultType=&quot;pojo.User&quot;&gt; select * from mybatis.user where id=#{id}&lt;/select&gt;//3.测试@Testpublic void getUserById(){ SqlSession sqlSession = MybatisUtils.getSqlSession(); UserMapper mapper = sqlSession.getMapper(UserMapper.class); //查询id为1的用户 User userById = mapper.getUserById(1); System.out.println(userById); sqlSession.close();} insert123456&lt;!--对象中的属性可以直接取出来--&gt;&lt;insert id=&quot;addUser&quot; parameterType=&quot;pojo.User&quot;&gt; &lt;!--传递参数为对象时，语句中参数要和对象中的属性一一对应--&gt; insert into mybatis.user(id,name,pwd) values (#{id},#{name},#{pwd})&lt;/insert&gt; update1234&lt;update id=&quot;updateUser&quot; parameterType=&quot;pojo.User&quot;&gt; update mybatis.user set name=#{name}, pwd=#{pwd} where id=#{id}&lt;/update&gt; delete1234&lt;delete id=&quot;deleteUser&quot; parameterType=&quot;int&quot;&gt; delete from mybatis.user where id=#{id}&lt;/delete&gt; 注意：增删改需要提交事务！ 万能Map假设我们的实体类，或者数据库中的表，字段或者参数过多，我们应当考虑使用Map！ 例子：对addUser的修改：只插入有两个字段的对象 1234567891011121314151617181920212223242526272829303132//接口定义int addUser2(Map&lt;String,Object&gt; map);//配置文件&lt;!--传递参数为map时，语句中参数要和对象中的属性不需要对应，可以随意取名，对应为map的key--&gt;&lt;!--同时，参数可以仅为数据库字段的部分值--&gt;&lt;insert id=&quot;addUser2&quot; parameterType=&quot;map&quot;&gt; insert into mybatis.user(id,name) values(#{userId},#{userName})&lt;/insert&gt;//测试函数public void addUser2Test(){ SqlSession sqlSession = MybatisUtils.getSqlSession(); UserMapper mapper = sqlSession.getMapper(UserMapper.class); Map&lt;String,Object&gt; map = new HashMap&lt;String,Object&gt;(); //此处的名称userId和userName要与配置文件中key的名称一致 //设置插入内容 map.put(&quot;userId&quot;,5); map.put(&quot;userName&quot;,&quot;小明&quot;); intres = mapper.addUser2(map); if(res&gt;0){ System.out.println(&quot;插入成功！&quot;); } //提交事务 sqlSession.commit(); sqlSession.close();} 注意： Map传递参数，直接在sql中取出key即可（即sql语句中#{}中的参数与测试时map添加的参数保持一致即可）； 对象传递参数，直接在sql中取对象的属性即可（即sql语句中#{}中的参数要与对象属性一一对应）； 只有一个基本类型参数的情况下，可以直接在sql中取到，就不用再写parameterType了； 多个参数的话，用Map，或者注解。 模糊查询如：查找名字中带有”李”字的用户 123456&lt;!--java代码执行时，传递通配符&quot;% %&quot;&quot;--&gt;List&lt;User&gt; userList = mapper.getUserLike(&quot;%李%&quot;)；&lt;--!sql拼接中使用通配符&quot;% %&quot;--&gt;select * from mybatis.user where name like &quot;%&quot;#{value}&quot;%&quot; 一般情况下用不到，通常在业务中会遇到。","link":"/2023/02/03/MyBatis%E4%B8%80/"},{"title":"MyBatis（三）","text":"本系列主要进行MyBatis框架的学习介绍，其中本篇文章介绍MyBatis中ResultMap，日志的使用，和采用注解开发等知识。 ResultMap解析用于：解决属性名和字段名不一致的问题。 属性名：用户类（User）中声明的属性； 字段名：Mysql创建的表中的列名。 例如：在之前的例子中，类User中的属性名是passward而不是pwd，那么mapper配置文件应改为： 1234567891011121314151617&lt;!--结果集映射--&gt;&lt;resultMap id=&quot;UserMap&quot; type=&quot;User&quot;&gt; &lt;!--column: 数据库中的字段，property: 实体类中的属性--&gt; &lt;result column=&quot;id&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;name&quot; property=&quot;name&quot;/&gt; &lt;result column=&quot;pwd&quot; property=&quot;password&quot;/&gt;&lt;/resultMap&gt;&lt;select id=&quot;getUserById&quot; resultMap=&quot;UserMap&quot;&gt; select * from mybatis.user where id = #{id}&lt;/select&gt;&lt;!--代替了原来的:--&gt;&lt;select id=&quot;getUserById&quot; resultType=&quot;User&quot;&gt; select * from mybatis.user where id = #{id}&lt;/select&gt; 总结： resultMap元素是MyBatis中最重要最强大的元素； ResultMap的设计思想是，对于简单的语句根本不需要配置显式的结果映射，而对于复杂一点的语句只需要描述它们的关系就行了；（即：ResultMap只需要用于属性名和字段名不一致的情况，一致的情况就不需要使用了） ResultMap最优秀的地方在于，虽然你已经对它相当了解了，但是根本就不需要显式地用到他们。（即：使用ResultMap时，只需要列出不一致的属性） 日志日志工厂如果一个数据库操作，出现了异常，我们需要进行排错。 以前：sout，debug… 现在：日志工厂 使用方法：在resource中的配置文件中进行settings设置。 日志类型包含： SLF4J LOG4j【掌握】 LOG4j2 JDK_LOGGING COMMONS_LOGGING STDOUT_LOGGING【掌握】 NO_LOGGING STDOUT_LOGGING： 标准的日志类型，不需要进行配置。 12345&lt;settings&gt; &lt;!--标准的日志工厂实现--&gt; &lt;setting name=&quot;logImpl&quot; value=&quot;STDOUT_LOGGING&quot;/&gt;&lt;/settings&gt; Log4j什么是Log4j？ Log4j是Apache的一个开源项目，通过使用Log4j，我们可以控制日志信息输送的目的地是控制台、文件、GUI组件； 我们也可以控制每一条日志的输出格式； 通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程； 通过一个配置文件来灵活地进行配置，而不需要修改应用的代码。 配置方法： 导包 配置log4j.properties文件 配置为log4j为日志的实现（settings中的配置） 简单使用： 1.在要使用Log4j的类中，导入包 import org.apache.log4j.Logger； 2.设置日志对象，参数为当前类的class： ​ static Logger logger= Logger.getLogger(UserDaoTest.class)； 3.日志级别 info debug error….一般用info表示提示，如： ​ logger.info(“进入了log4jTest”); 注解开发使用注解开发使用注解开发实际上是面向接口编程。 面向接口的编程的优点：解耦，可拓展，提高复用… 具体步骤： 123456789101112//1.注解在接口上实现@select(&quot;select * from user&quot;)List&lt;User&gt; getUsers();//2.需要在核心配置文件中绑定接口!&lt;!--绑定接口--&gt;&lt;mappers&gt; &lt;mapper class=&quot;dao.userMapper&quot;/&gt;&lt;/mappers&gt;//3.测试 本质：反射机制；底层：动态代理 CRUD实现具体代码见代码文件，与之前类似。 注意：我们必须要讲接口注册绑定到我们的核心配置文件中！ 我们可以在工具类创建的时候实现自动提交事务！ 1234public static sqlSession getsqlSession(){ return sqlSessionFactory.openSession(true);} 关于@Param()注解： 基本类型的参数或者String类型，需要加上； 引用类型不需要加； 如果只有一个基本类型的话，可以忽略，但是建议大家都加上； 我们在SQL中引用的就是我们这里的@Param(“uid”)中设定的属性名。 Lombok用于省略实体类的一些通用操作，如get,set,toString方法等… 使用步骤： 1.安装lombok插件； 2.导入lombok的jar包； 3.在实体类上加注解即可。 常用的有： @Data: 无参构造get，set，toString，equals，hashcode @AllArgsConstructor：生成有参构造器 @NoArgsConstructor：无参构造器","link":"/2023/02/03/MyBatis%E4%B8%89/"},{"title":"MyBatis（二）","text":"本系列主要进行MyBatis框架的学习介绍，其中本篇文章介绍MyBatis的配置解析，包括核心配置文件，环境变量，属性，类型别名，映射器，生命周期和作用域等。 配置解析核心配置文件 mybatis-config.xml； mybatis的配置文件包含了会深深影响Mybatis行为的设置和属性信息； 环境变量（environments） MyBatis可以配置成适应多种环境； 不过要记住：尽管可以配置多个环境，但每个SqlSessionFactory实例只能选择一种环境； 要学会使用配置多套运行环境，用default进行环境的选择； Mybatis默认的事务管理器就是JDBC，连接池: POOLED 属性（properties）我们可以通过properties属性来实现引用配置文件； 这些属性可以在外部进行配置，并可以进行动态替换。你既可以在典型的 Java 属性文件中配置这些属性，也可以在 properties 元素的子元素中设置；（db.properties） 编写一个配置文件db.properties 123driver=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/mybatis?useSSL=false&amp;;useUnicode=true&amp;;characterEncoding=UTF-8 在核心配置文件中引入： 123456&lt;!--引入外部配置文件--&gt;&lt;properties resource=&quot;db.properties&quot;&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt;&lt;/properties&gt; 注意： 可以直接引入外部文件； 可以在其中增加一些属性配置； 如果两个文件有同一个字段，优先使用外部配置文件的。（即如果db.properties也写了username和password，以db中的为准） 类型别名（typeAliases） 类型别名可为 Java 类型设置一个缩写名字； 存在的意义仅在于用来降低全限定类名书写的冗余。 123456789101112&lt;!--方式一：直接给实体类起别名--&gt; &lt;typeAliases&gt; &lt;typeAliastype=&quot;pojo.User&quot;alias=&quot;User&quot;/&gt;&lt;/typeAliases&gt;&lt;!--方式二：指定一个包名MyBatis 会在包名下面搜索需要的Java Bean，比如：扫描实体类的包，它的默认别名就为这个类的类名，首字母小写。--&gt;&lt;typeAliases&gt; &lt;!--也可以通过包的方式起别名，名称为这个类的类名，首字母小写的结果，此处为user--&gt; &lt;packagename=&quot;pojo&quot;/&gt;&lt;/typeAliases&gt; 注意： 在实体类比较少的时候，使用第一种方式。如果实体类十分多，建议使用第二种； 第一种可以DIY别名，第二种不行，如果非要改，需要在实体类上加别名，例如： 12345@Alias(&quot;user&quot;) public class User{ ...} 映射器（mappers）MapperRegistry：注册绑定我们的Mapper文件。 有两种映射器的配置方法： 12345678910111213141516&lt;!--方式一：直接使用resource路径：[推荐使用方式一]--&gt;&lt;!--每一个Mapper.xml都需要在Mybatis核心配置文件中注册--&gt;&lt;mappers&gt; &lt;mapper resource=&quot;dao/UserMapper.xml&quot;/&gt;&lt;/mappers&gt;&lt;!--方式二：使用接口同名的类class进行配置--&gt;&lt;mappers&gt; &lt;mapper class=&quot;dao.UserMapper&quot;/&gt;&lt;/mappers&gt;&lt;!--方式三：使用扫描包package进行注入绑定--&gt;&lt;mappers&gt; &lt;package name=&quot;dao&quot;/&gt;&lt;/mappers&gt; 方法二和方法三注意点： 接口和他的Mapper配置文件必须同名； 接口和他的Mapper配置文件必须在同一个包下； 注意：class时为类名，用 . ，resource时为xml的路径，用 / 。 生命周期和作用域生命周期，和作用域，是至关重要的，因为错误的使用会导致非常严重的并发问题。 生命周期： SqlSessionFactoryBuilder: 一旦创建了SqlSessionFactory，就不再需要它了； 局部变量 SqlSessionFactory： 说白了就是可以想象为：数据库连接池； SqlSessionFactory一旦被创建就应该在应用的运行期间一直存在，没有任何理由丢弃它或重新创建另一个实例； 因此SqlSessionFactory的最佳作用域是应用作用域；（即全局变量） 最简单的就是使用单例模式或者静态单例模式。 SqlSession： 是连接到连接池的一个请求! SqlSession的实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。（创建实例时使用，实例使用完毕时关闭） 用完之后需要赶紧关闭，否则资源被占用！ SqlSessionFactory和SqlSession的关系：一个SqlSessionFactory工厂可以创建多个SqlSession类，每个类最多用于一个线程；一个sqlSession实例可以创建多个Mapper，用于执行指令。这里的每一个Mapper，就代表一个具体的业务。","link":"/2023/02/03/MyBatis%E4%BA%8C/"},{"title":"MyBatis（五）","text":"本系列主要进行MyBatis框架的学习介绍，其中本篇文章介绍MyBatis中动态SQL语句的实现，以及缓存的相关知识。 动态SQL什么是动态SQL：动态SQL就是指根据不同的条件生成不同的SQL语句。 如果你使用过 JDBC 或其它类似的框架，你应该能理解根据不同条件拼接 SQL 语句有多痛苦，例如拼接时要确保不能忘记添加必要的空格，还要注意去掉列表最后一个列名的逗号。利用动态 SQL，可以彻底摆脱这种痛苦。 动态SQL的元素主要包括： if –条件判断 choose (when, otherwise) –类似switch trim (where, set) –实现智能去and（where中） 和逗号（update语句的set中），trim为自动去除前后缀，具体使用见官网 foreach –用于SQL语句中使用了in的情况 所谓的动态SQL，本质上还是SQL语句，只是我们可以在SQL层面，去执行一个逻辑代码。 SQL片段： 有的时候，我们可能会将一些功能的部分抽取出来，方便复用。 采用&lt;sql&gt;进行定义，用&lt;include&gt;进行引用。 注意事项： 最好基于单表i来定义SQL片段； 不要存在&lt;where&gt;标签。 常用的动态SQL：if, where, set 动态SQL就是在拼接SQL语句，我们只要保证SQL的正确性，按照SQL的格式，去排列组合就可以了。 建议：先在Mysql中写出完整的SQL，再对应的去修改为动态SQL实现通用即可。 缓存简介通常，查询会连接数据库，耗资源。 一次查询的结果，给他暂存在一个可以直接取到的地方 –&gt;也就是 内存：缓存 我们再次查询相同数据的时候，直接走缓存，就不用走数据库了。 什么是缓存[Cache]？ 存在内存中的临时数据； 将用户经常查询的数据放在缓存（内存）中，用户去查询数据就不用从磁盘上（关系型数据库数据文件）查询，从缓存中查询，从而提高查询效率，解决了高并发系统的性能问题； 为什么使用缓存? 减少和数据库的交互次数，减少系统开销，提高系统效率。 什么样的数据能使用缓存? 经常查询并且不经常改变的数据。（也就是经常用于读操作的数据） 不经常查询或者经常改变的数据，不建议使用缓存。（也就是用于写操作的数据） Mybatis缓存 MyBatis包含一个非常强大的查询缓存特性，它可以非常方便地定制和配置缓存，缓存可以极大的提升查询效率； MyBatis系统中默认定义了两级缓存：一级缓存和二级缓存； 默认情况下，只有一级缓存开启。（SqlSession级别的缓存，也称为本地缓存）。二级缓存需要手动开启和配置，它是基于namespace级别的缓存； 为了提高扩展性，MyBatis定义了缓存接口Cache。我们可以通过实现Cache接口来自定义二级缓存。 一级缓存 一级缓存也叫本地缓存： 与数据库同一次会话期间查询到的数据会放在本地缓存中； 以后如果需要获取相同的数据，直接从缓存中拿，没必须再去查询数据库; 缓存失效的情况： 查询不同的东西 增删改操作，可能会改变原来的数据，所以必定会刷新缓存 查询不同的Mapper.xml 手动清理缓存 小结：一级缓存默认是开启的，只在一次SqlSession中有效，也即为拿到连接到关闭连接这个阶段。 一级缓存相当于一个Map。 二级缓存 二级缓存也叫全局缓存，一级缓存作用域太低了，所以诞生了二级缓存； 二级缓存是基于namespace级别的缓存，一个名称空间，对应一个二级缓存； 工作机制： 一个会话查询一条数据，这个数据就会被放在当前会话的一级缓存中； 如果当前会话关闭了，这个会话对应的一级缓存就没了；但是我们想要的是，会话关闭了，一级缓存中的数据被保存到二级缓存中; 当新的会话查询信息，就可以从二级缓存中获取内容； 不同的mapper查出的数据会放在自己对应的缓存(map)中; 使用步骤： 123456789101112131415161718&lt;!--1.开启全局缓存--&gt;&lt;!--显式的开启全局缓存，默认为开启--&gt;&lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;&lt;!--2.在要使用二级缓存的Mapper中开启--&gt;&lt;!--在当前的Mapper.xml中使用二级缓存--&gt;&lt;cache/&gt;&lt;!--也可以自定义参数--&gt;&lt;!--在当前的Mapper.xml中使用二级缓存--&gt;&lt;cache eviction=&quot;FIFO&quot; flushInterval=&quot;60000&quot; size=&quot;512&quot; readOnly=&quot;true&quot;/&gt;&lt;!--3.测试--&gt;&lt;!--问题：我们需要将实体类序列化，否则会报错。caused by: java.io.NotserializableException: pojo.User、序列化方法：public class User implements Serializable{…} --&gt; 小结: 只要开启了二级缓存，在同一个Mapper下就有效； 所有的数据都会先放在一级缓存中； 只有当会话提交，或者关闭的时候，才会提交到二级缓存中。（即一级缓存结束了，才会有二级缓存） 缓存原理 缓存顺序：当用户执行一个SQL语句时： 先看二级缓存有没有对应的缓存信息； 再看一级缓存有没有对应的缓存信息； 如果都没有，则查询数据库。","link":"/2023/02/04/MyBatis%E4%BA%94/"},{"title":"Spring（一）","text":"本系列主要进行Spring框架的学习介绍，Spring框架是一个轻量级的控制反转（IOC）和面向切面编程（AOP）的框架。其中本篇文章进行Spring的简介，包括Spring的介绍，IOC的推导和第一个Spring框架程序的搭建和IOC创建对象的方式等。 Spring简介spring理念：使现有的技术更加容易使用，本身是一个大杂烩，整合了现有的技术框架。 官网：https://spring.io/projects/spring-framework#overview 官方下载地址：http://repo.spring.io/release/org/springframework/spring GitHub：https://github.com/spring-projects/spring-framework 需要导的包： 1234567891011121314&lt;!-- https: //mvnrepository.com/artifact/org.springframework/spring-webmvc --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https: //mvnrepository.com/artifact/org.springframework/spring-jdbc--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 优点 spring是一个开源的免费的框架（容器）； spring是一个轻量级的、非入侵式的框架； 控制反转（IOC），面向切面编程（AOP）； 支持事务的处理，对框架整合的支持。 总结：Spring就是一个轻量级的控制反转（IOC）和面向切面编程（AOP）的框架。 缺点：发展了太久之后，违背了原来的理念，配置十分繁琐。 IOC理论推导代码架构： UserDao接口 UserDaoImpl实现类 UserService业务接口 UserServiceImpl业务实现类 在我们之前的业务中，用户的需求可能会影响我们原来的代码，我们需要根据用户的需求去修改原代码。如果程序代码量十分大，修改一次的成本代价十分昂贵。 我们使用一个set接口实现，已经发生了革命性的变化。 123456private userDao userDao;//利用set进行动态实现值的注入!public void set userDao(userDao userDao) { this.userDao = userDao;} 之前，程序是主动创建对象，控制权在程序猿手上； 在使用了set注入后，程序不再具有主动性，而是变成了被动的接受对象； 用户可以根据自身的需求，使用不同的情况，而不需要程序员在业务层上进行修改了。 这种思想，从本质上解决了问题，程序员不用再去管理对象的创建了，系统的耦合性大大降低，可以更加专注于业务的实现上。这是IOC的原型。 IOC本质： 控制反转loC(Inversion of Control)，是一种设计思想，DI(依赖注入)是实现loC的一种方法，也有人认为DI只是loC的另一种说法。没有loC的程序中，我们使用面向对象编程，对象的创建与对象间的依赖关系完全硬编码在程序中，对象的创建由程序自己控制，控制反转后将对象的创建转移给第三方，个人认为所谓控制反转就是：获得依赖对象的方式反转了。 控制反转是一种通过描述（XML或注解）并通过第三方去生产或获取特定对象的方式。在Spring中实现控制反转的是loC容器，其实现方法是依赖注入(Dependency Injection,Dl)。 Hello Spring1. 编写实体类Hello； 12345678910111213141516public class Hello{ private String str; public String getStr(){ return str; } public void setStr(Stringstr){ this.str=str; } @Override public String toString(){ return &quot;Hello{&quot;+&quot;str='&quot;+str+'\\''+'}'; }} 2.编写Spring配置文件beans.xml； 1234567891011&lt;!--使用Spring来创建对象，在Spring中这些都称为Bean类型变量名 = new 类型();Hello hello = new Hello();id=变量名class=new的对象property相当于给对象中的属性设置一个值--&gt;&lt;bean id=&quot;hello&quot; class=&quot;pojo.Hello&quot;&gt; &lt;property name=&quot;str&quot; value=&quot;Spring&quot;/&gt;&lt;/bean&gt; 3.编写测试函数 123456789public static void main(String[] args){ //获取Spring的上下文对象 ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); //我们的对象现在都在Spring中管理了，我们要使用，直接去里面取出来就可以了 Hello hello = (Hello)context.getBean(&quot;hello&quot;); System.out.println(hello.toString());} 总结： 1.Hello对象是由Spring创建的； 2.Hello对象的属性是由Spring容器设置的； 3.这个过程就叫控制反转： 控制：谁来控制对象的创建，传统应用程序的对象是由程序本身控制创建的，使用Spring后，对象是由Spring来创建的。 反转：程序本身不创建对象，而变成被动的接收对象。 依赖注入：就是利用set方法来进行注入的。 4.IOC是一种编程思想，由主动的编程变成被动的接收； 5.到了现在,我们彻底不用再程序中去改动了，要实现不同的操作，只需要在xmI配置文件中进行修改，所谓的IoC, 一句话搞定：对象由Spring来创建，管理，装配。 IOC创建对象的方式1.使用无参构造创建对象，默认！ 2.假设我们要用有参构造创建对象。 123456789101112131415&lt;!--有参构造器创建对象 下标赋值--&gt;&lt;bean id=&quot;hello&quot; class=&quot;pojo.Hello&quot;&gt; &lt;constructor-arg index=&quot;0&quot; value=&quot;Summer&quot;/&gt;&lt;/bean&gt;&lt;!--有参构造器创建对象 类型赋值--&gt;&lt;bean id=&quot;hello&quot; class=&quot;pojo.Hello&quot;&gt; &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;Summer&quot;/&gt;&lt;/bean&gt;&lt;!--有参构造器创建对象 参数名赋值--&gt;&lt;bean id=&quot;hello&quot; class=&quot;pojo.Hello&quot;&gt; &lt;constructor-arg name=&quot;str&quot; value=&quot;Autumn&quot;/&gt;&lt;/bean&gt; 在配置文件加载的时候，容器中管理的对象就已经初始化了。即：不管是否使用，都先初始化好了，用的时候直接拿来用就行。 （Spring容器可以看作婚庆公司，有很多人的名单，看中了谁就选谁）","link":"/2023/02/07/Spring%E4%B8%80/"},{"title":"Spring（五）","text":"本系列主要进行Spring框架的学习介绍，Spring框架是一个轻量级的控制反转（IOC）和面向切面编程（AOP）的框架。其中本篇文章将Spring与Mybatis进行整合，并介绍事务的有关内容。 整合MyBatis步骤： 1.导入相关jar包： junit、mybatis、mysql、spring、aop、mybatis-spring 2.编写配置文件 3.测试 回忆mybatis1.编写实体类 2.编写核心配置文件 3.编写接口 4.编写Mapper.xml 5.测试 Mybatis-spring1.编写数据源配置 2.sqlSessionFactory 3.sqlSessionTemplate 4.给接口加实现类 5.将自己写的实现类注入到spring中 6.测试使用 具体见代码，代码编写顺序（上面6点的拓展）： 1.导入依赖； 2.编写pojo下的实体类（如User）； 3.编写对应实体类在mapper下的接口（如UserMapper），以及配置文件（如UserMapper.xml）； 123456789101112//接口public interface UserMapper{List&lt;User&gt;selectUser();}//xml&lt;mapper namespace=&quot;mapper.UserMapper&quot;&gt; &lt;select id=&quot;selectUser&quot; resultType=&quot;user&quot;&gt; select * from user; &lt;/select&gt;&lt;/mapper&gt; 4.整合mybatis：编写mybatis配置文件，编写spring配置文件（包含了上面的1-3）； mybatis-config.xml: 12345678&lt;!--configuration核心配置文件--&gt;&lt;configuration&gt; &lt;!--其实可以完全省略了，但通常在mybatis配置文件中留下别名typeAliases和设置settings--&gt; &lt;typeAliases&gt; &lt;packagename=&quot;pojo&quot;/&gt; &lt;/typeAliases&gt;&lt;/configuration&gt; spring-dao.xml: 123456789101112131415161718192021222324&lt;!--DataSource:使用Spring的数据源替换Mybatis的配置我们这里使用spring提供的jdbc--&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?useSSL=false&amp;amp;useUnicode=true&amp;amp;characterEncoding=UTF-8&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt;&lt;/bean&gt;&lt;!--sqlSessionFactory的创建--&gt;&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!--绑定Mybatis配置文件--&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mapper/*.xml&quot;/&gt;&lt;/bean&gt;&lt;!--SqlSessionTemplate其实就是我们使用的sqlSession--&gt;&lt;bean id=&quot;sqlSession&quot; class=&quot;org.mybatis.spring.SqlSessionTemplate&quot;&gt; &lt;!--只能用构造器注入sqlSessionFactory，因为它没有set方法--&gt; &lt;constructor-argindex=&quot;0&quot; ref=&quot;sqlSessionFactory&quot;/&gt;&lt;/bean&gt; 5.编写实现类（如UserMapperImpl）； 123456789101112131415public class UserMapperImpl implements UserMapper{//在原来，我们的所有操作都使用sqlSession来执行//而现在，我们使用SqlSessionTemplate类private SqlSessionTemplate sqlSession;public void set SqlSession(SqlSessionTemplate sqlSession){ this.sqlSession=sqlSession;}//要实现的功能public List&lt;User&gt; selectUser(){ UserMapper mapper=sqlSession.getMapper(UserMapper.class); return mapper.selectUser();} 6.编写总的配置文件applicationContext.xml，即将实现类注入到spring中； 123456&lt;import resource=&quot;spring-dao.xml&quot;/&gt;&lt;bean id=&quot;useMapper&quot; class=&quot;mapper.UserMapperImpl&quot;&gt; &lt;property name=&quot;sqlSession&quot; ref=&quot;sqlSession&quot;/&gt;&lt;/bean&gt; 7.测试 声明式事务回顾事务 要么都成功，要么都失败； 事务在项目开发中，十分重要，涉及到数据的一致性问题； 确保完整性和一致性； 事务ACID原则：原子性，一致性，隔离性，持久性。 spring中的事务管理声明式事务管理：AOP实现 配置于spring-dao.xml中 123456789101112131415161718192021&lt;!--配置声明式事务--&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;&lt;/bean&gt;&lt;!--结合aop实现事务的织入--&gt;&lt;!--配置事务通知--&gt;&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;!--给哪些方法配置事务name--&gt; &lt;!--配置事务的传播特性propagation 可以不管，默认就是REQUIRED--&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;*&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!--配置事务切入--&gt;&lt;aop:config&gt; &lt;aop:point cutid=&quot;txPointCut&quot; expression=&quot;execution(*mapper.UserMapperImpl.*(..))&quot;/&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;txPointCut&quot;/&gt;&lt;/aop:config&gt; 编程式事务管理：需要在代码中，进行事务的管理 为什么需要事务？ 如果不配置事务，可能存在数据提交不一致的情况； 如果不在spring中配置声明式事务，就需要在代码中，手动进行配置； 事务能够保证数据安全，在项目开发中，十分重要，涉及到数据的一致性问题。 例子：假设delete的sql代码出现问题 1234567891011public List&lt;User&gt; selectUser(){ User user=new User(7,&quot;小田&quot;,&quot;777777&quot;); UserMapper mapper=sqlSession.getMapper(UserMapper.class); mapper.addUser(user); mapper.deleteUser(7); return mapper.selectUser();} 如果不处理事务，那么会导致使用add功能而不使用delete功能； 处理了事务之后，delete程序出问题了，add功能也不会成功使用，保证了数据的一致性。","link":"/2023/02/07/Spring%E4%BA%94/"},{"title":"Spring（三）","text":"本系列主要进行Spring框架的学习介绍，Spring框架是一个轻量级的控制反转（IOC）和面向切面编程（AOP）的框架。其中本篇文章进行对Spring的进一步讲解，包括Bean的自动装配，使用注解开发，使用java方式配置Spring等。 Bean的自动装配自动装配是Spring满足bean依赖的一种方式； Spring会在上下文种自动寻找，并自动给bean装配属性。 在Spring中有三种装配的方式： 在xml种进行显式的配置； 在java种显式的配置； 隐式的自动装配bean【重要】 测试环境搭建：一个人有两个宠物 12345678&lt;bean id=&quot;cat&quot; class=&quot;pojo.Cat&quot;/&gt;&lt;bean id=&quot;dog&quot; class=&quot;pojo.Dog&quot;/&gt;&lt;bean id=&quot;person&quot; class=&quot;pojo.Person&quot;&gt; &lt;property name=&quot;cat&quot; ref=&quot;cat&quot;/&gt; &lt;property name=&quot;dog&quot; ref=&quot;dog&quot;/&gt; &lt;property name=&quot;name&quot; value=&quot;张三&quot;/&gt;&lt;/bean&gt; 自动装配byName,byType自动装配： 123456789101112131415&lt;bean id=&quot;cat&quot; class=&quot;pojo.Cat&quot;/&gt;&lt;bean id=&quot;dog&quot; class=&quot;pojo.Dog&quot;/&gt;&lt;!--自动装配autowirebyName:会自动在容器上下文中查找，和自己对象set方法后面的值对应的beanid（需要id相同）byType:会自动在容器上下文中查找，和自己对象属性类型相同的的bean（需要类型唯一）--&gt;&lt;bean id=&quot;person&quot; class=&quot;pojo.Person&quot; autowire=&quot;byType&quot;&gt; &lt;!--bean id=&quot;person&quot; class=&quot;pojo.Person&quot; autowire=&quot;byName&quot;--&gt; &lt;!--&lt;property name=&quot;cat&quot; ref=&quot;cat&quot;/&gt;--&gt; &lt;!--&lt;property name=&quot;dog&quot; ref=&quot;dog&quot;/&gt;--&gt; &lt;property name=&quot;name&quot; value=&quot;张三&quot;/&gt;&lt;/bean&gt; 小结： byName的时候，需要保证所有的bean的id唯一，并且这个bean的id需要和自动注入的属性的set方法的值一致； byType的时候，需要保证所有的bean的class唯一，并且这个bean的class需要和自动注入的属性的类型一致。 使用注解实现自动装配要使用注解须知： 导入约束； 配置注解的支持。 @AutoWired：默认为byType方式，如果找不到就byName 直接在属性上使用即可，也可以在set方法上使用； 使用@AutoWired就不用编写set方法了，前提是你这个自动装配的属性在IOC（Spring）容器中存在，且符合名字byName； 科普：@Nullale：字段标记了这个注解，则该字段可以为空；@AutoWired(required=false)：若属性为false，则说明这个对象可以为空（null）。 如果@AutoWired自动装配的环境比较复杂，自动装配无法通过一个注解（@AutoWired）完成时，我们可以使用@Qualifier(value=”xxx”)去配合@AutoWired使用，指定唯一一个bean对象的注入。 @Resource：默认为byName方式，如果找不到就byType，不需要导入Spring，但效率稍微低一些 如果字段名id与属性名不同，如id=”cat123”，属性为cat，则使用方式为： 1234567@AutoWired@Qualifier(value=&quot;cat123&quot;)private Cat cat;@Resource(name=&quot;cat123&quot;)private Cat cat; 使用注解开发 在spring4之后，使用注解必须要导入aop包； 使用注解需要导入context约束，并配置注解的支持。 bean的创建和属性的注入： 12345678910//等价于&lt;bean id=&quot;user&quot; class=&quot;pojo.User&quot;/&gt;//@Component组件@Componentpublic class User{ //相当于&lt;property name=&quot;name&quot; value=&quot;秦疆&quot;/&gt; //@Value属性值，也可以作用于set方法上 @Value(&quot;秦疆&quot;) public String name;} 衍生的注解： @Component有几个衍生注解，我们在web开发中，会按照mvc三层架构分层： dao 【@Repository】 service 【@service】 controller 【@controller】 这四个注解功能都是一样的，都是代表将某个类注册到Spring中，并装配Bean。 作用域： 1234@scope(&quot;prototype&quot;)//相当于scope=&quot;prototype&quot;public class User{…} 小结： xml与注解： xml更加万能，适用于任何场合，维护简单方便； 注解不是自己类就使用不了，维护相对复杂。 xml与注解最佳实践： xml用来管理bean； 注解只负责完成属性的注入； 我们在使用的过程中，只需要注意一个问题：必须让注解生效，即需要开启注解的支持。 使用java方式配置Spring纯java，不再使用beans.xml配置文件了，而是采用了一个配置类。 实体类：User.class 配置文件：MyConfig.class，可以有多个，用@Import导入 12345678910111213141516//@Configuration也会被Spring容器托管，注册到容器中，因为这个本来就是一个Component//@Configuration代表这是一个配置类，等价于beans.xml@Configuration@ComponentScan(&quot;pojo&quot;)@Import(MyConfig2.class)public class MyConfig{ //注册一个bean，就相当于之前的bean标签 //这个方法的名字，就相当于bean标签的id属性 //这个方法的返回值，就相当于bean标签的class属性 //即等价于&lt;bean id=&quot;user&quot; class=&quot;pojo.User&quot;/&gt; @Bean public User user(){ return new User();//就是返回要注入到bean的对象 }} 测试类： 1234567public static void main(String[] args){ //如果完全使用了配置类去做，我们就只能通过AnnotationConfig上下文来获取容器，通过配置类的class对象加载 ApplicationContext context=new AnnotationConfigApplicationContext(MyConfig.class); User user=(User) context.getBean(&quot;user&quot;);//取配置类中的方法名 System.out.println(user.getName());}","link":"/2023/02/07/Spring%E4%B8%89/"},{"title":"Spring（四）","text":"本系列主要进行Spring框架的学习介绍，Spring框架是一个轻量级的控制反转（IOC）和面向切面编程（AOP）的框架。其中本篇文章进行具体AOP的讲解，首先会介绍代理模式，之后会进行AOP的具体介绍。 代理模式为什么学习代理模式，因为这是Spring AOP的底层。 角色分析： 抽象角色：一般会使用接口或者抽象类来解决； 真实角色：被代理的角色； 代理角色：代理真实角色，代理真实角色后，我们一般会做一些附属操作； 客户：访问代理对象的人。即main方法。 代理模式（静态代理）的好处: 可以使真实角色的操作更加纯粹!不用去关注一些公共的业务； 公共业务就交给代理角色，实现了业务的分工； 公共业务发生扩展的时候，方便集中管理。 （静态代理）缺点: 一个真实角色就会产生一个代理角色； 代码量会翻倍，开发效率会变低。 动态代理标准格式： 两个重要类： InvocationHandler：调用处理程序（invoke）并返回结果； Proxy：提供了创建动态代理类和实例的静态方法，用于生成动态代理实例。 代理模式（动态代理）的好处: 可以使真实角色的操作更加纯粹!不用去关注一些公共的业务； 公共业务就交给代理角色，实现了业务的分工； 公共业务发生扩展的时候，方便集中管理； 一个动态代理类代理的是一个接口，一般就是对应的一类业务； 一个动态代理类可以代理多个类，只要是实现了同一个接口即可。 AOP什么是AOP在不影响原始类的情况下，实现业务增强。 AOP(Aspect Oriented Programming)：面向切面编程，是通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 主要思想： aop在Spring中的作用提供声明式事务；允许用户自定义切面 几个概念： 横切关注点：跨越应用程序多个模块的方法或功能。即是，与我们业务逻辑无关的，但是我们需要关注的部分，就是横切关注点。如日志，安全，缓存，事务等等…. 可以将功能添加到主要功能的周围 切面(Aspect)：横切关注点被模块化的特殊对象。即，它是一个类，如日志类，； 通知(Advice)：切面必须要完成的工作。即，它是类中的一个方法； 目标(Target)：被通知对象，即为真实角色； 代理(Proxy)：向目标对象应用通知之后创建的对象，即为代理角色； 切入点(PointCut)：切面通知执行的“地点”的定义，即切入的位置； 连接点(JointPoint)：与切入点匹配的执行点。 AOP本质上是动态代理，只不过在Spring中，目标和代理Spring帮我们做了。 使用Spring实现AOP使用aop需要导依赖，和导包 方式一：使用Spring的API接口【主要是SpringAPI接口实现】 日志类： 12345678910//放日志，采用MethodBeforeAdvice接口public class Log implements MethodBeforeAdvice{ //method:要执行的目标对象的方法 //args:参数 //target:目标对象 public void before(Method method,Object[] args,Object target) throws Throwable{ System.out.println(target.getClass().getName()+&quot;的&quot;+method.getName()+&quot;被执行了&quot;); }} 配置文件： 12345678910111213141516&lt;!--注册beans--&gt;&lt;bean id=&quot;userService&quot; class=&quot;service.UserServiceImpl&quot;/&gt;&lt;bean id=&quot;log&quot; class=&quot;log.Log&quot;/&gt;&lt;bean id=&quot;afterLog&quot; class=&quot;log.AfterLog&quot;/&gt;&lt;!--方式一：使用原生API接口--&gt;&lt;!--配置aop，导入aop的配置--&gt;&lt;aop:config&gt; &lt;!--切入点：expression:表达式, execution(要执行的位置,***)--&gt; &lt;aop:pointcut id=&quot;pointcut&quot; expression=&quot;execution(*service.UserServiceImpl.*(..))&quot;/&gt; &lt;!--执行环绕增加，实现切面--&gt; &lt;aop:advisor advice-ref=&quot;log&quot; pointcut-ref=&quot;pointcut&quot;/&gt; &lt;aop:advisor advice-ref=&quot;afterLog&quot; pointcut-ref=&quot;pointcut&quot;/&gt;&lt;/aop:config&gt; 方式二：自定义类实现AOP【主要是切面定义】 自定义类： 12345678910//方式二：使用自定义日志类实现AOPpublic class DiyPointCut{ public void before(){ System.out.println(&quot;=============方法执行前==============&quot;); } public void after(){ System.out.println(&quot;=============方法执行后==============&quot;); }} 配置文件： 1234567891011121314&lt;!--方式二：自定义类--&gt;&lt;bean id=&quot;diy&quot; class=&quot;diy.DiyPointCut&quot;/&gt; &lt;aop:config&gt; &lt;!--自定义切面，ref要引用的类--&gt; &lt;aop:aspect ref=&quot;diy&quot;&gt; &lt;!--切入点--&gt; &lt;aop:pointcut id=&quot;point&quot; expression=&quot;execution(*service.UserServiceImpl.*(..))&quot;/&gt; &lt;!--通知--&gt; &lt;aop:before method=&quot;before&quot;pointcut-ref=&quot;point&quot;/&gt; &lt;aop:after method=&quot;after&quot;pointcut-ref=&quot;point&quot;/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 方式三：使用注解实现 自定义类： 12345678910111213141516171819202122//方式三：使用注解方式实现AOP@Aspect //标注这个类是一个切面public class AnnotationPointCut{ @Before(&quot;execution(*service.UserServiceImpl.*(..))&quot;) public void before(){ System.out.println(&quot;=============方法执行前==============&quot;); } @After(&quot;execution(*service.UserServiceImpl.*(..))&quot;) public void after(){ System.out.println(&quot;=============方法执行后==============&quot;); } //在环绕增强中，定义连接点 @Around(&quot;execution(*service.UserServiceImpl.*(..))&quot;) public void around(ProceedingJoinPoint jp) throws Throwable{ System.out.println(&quot;=============环绕前==============&quot;); Object proceed=jp.proceed(); System.out.println(&quot;=============环绕后==============&quot;); }} 配置文件： 123&lt;bean id=&quot;annotationPointCut&quot; class=&quot;diy.AnnotationPointCut&quot;/&gt;&lt;aop:aspectj-autoproxy/&gt; //使用注解配置","link":"/2023/02/07/Spring%E5%9B%9B/"},{"title":"Spring（二）","text":"本系列主要进行Spring框架的学习介绍，Spring框架是一个轻量级的控制反转（IOC）和面向切面编程（AOP）的框架。其中本篇文章进行Spring的配置介绍和依赖注入（DI）特性。 Spring配置别名（Alias）别名：取一个额外的名字，如果添加了别名，我们也可以使用别名获取到这个对象。此外，使用了别名后，原来的名字仍然可以使用。 12&lt;alias name=&quot;hello&quot; alias=&quot;helloNew&quot;/&gt; Bean的配置id : bean 的唯一标识符， 也就是相当于我们学的对象名； class：bean 对象所对应的全限定名：包名+类型； name：也是别名，而且name可以同时取多个别名，用逗号 分号 空格都可以隔开 import一般用于团队开发使用，可以将多个配置文件导入合并为一个 依赖注入构造器注入见第4章 Set方式注入【重点】 依赖注入：本质是Set注入 依赖：bean对象的创建依赖于容器； 注入：bean对象的所有属性，由容器来注入。 环境搭建： 1.构建复杂类 1234567891011public class Address{ private String address; public String getAddress(){ return address; } public void setAddress(Stringaddress){ this.address=address; }} 2.构建目标类 12345678910111213public class Student{ private String name; private Address address; private String[] books; private List&lt;String&gt; hobbies; private Map&lt;String,String&gt; card; private Set&lt;String&gt; games; private String wife; private Properties info; get set…} 3.beans.xml配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;bean id=&quot;address&quot; class=&quot;pojo.Address&quot;&gt; &lt;property name=&quot;address&quot; value=&quot;西安&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;student&quot; class=&quot;pojo.Student&quot;&gt; &lt;!--普通值注入，value--&gt; &lt;property name=&quot;name&quot; value=&quot;琴疆&quot;/&gt; &lt;!--Bean注入，ref--&gt; &lt;property name=&quot;address&quot; ref=&quot;address&quot;/&gt; &lt;!--数组注入--&gt; &lt;property name=&quot;books&quot;&gt; &lt;array&gt; &lt;value&gt;红楼梦&lt;/value&gt; &lt;value&gt;水浒传&lt;/value&gt; &lt;value&gt;三国演义&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;!--List--&gt; &lt;property name=&quot;hobbies&quot;&gt; &lt;list&gt; &lt;value&gt;听歌&lt;/value&gt; &lt;value&gt;看电影&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!--Map--&gt; &lt;property name=&quot;card&quot;&gt; &lt;map&gt; &lt;entry key=&quot;身份证&quot; value=&quot;123121231313123132&quot;/&gt; &lt;entry key=&quot;银行卡&quot; value=&quot;111111111111111111&quot;/&gt; &lt;/map&gt; &lt;/property&gt; &lt;!--Set--&gt; &lt;property name=&quot;games&quot;&gt; &lt;set&gt; &lt;value&gt;LOL&lt;/value&gt; &lt;value&gt;PUBG&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;!--null--&gt; &lt;property name=&quot;wife&quot;&gt; &lt;null/&gt; &lt;/property&gt; &lt;!--Properties--&gt; &lt;property name=&quot;info&quot;&gt; &lt;props&gt; &lt;prop key=&quot;driver&quot;&gt;20190525&lt;/prop&gt; &lt;prop key=&quot;url&quot;&gt;男&lt;/prop&gt; &lt;prop key=&quot;username&quot;&gt;root&lt;/prop&gt; &lt;prop key=&quot;password&quot;&gt;123456&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt; 4.测试 12345678910111213141516171819public static void main(String[]args){ ApplicationContext context=new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); Student student=(Student) context.getBean(&quot;student&quot;); System.out.println(student.toString()); /* Student{ name='琴疆', address=Address{address='西安'}, books=[红楼梦,水浒传,三国演义], hobbies=[听歌,看电影], card={身份证=123121231313123132,银行卡=111111111111111111}, games=[LOL,PUBG], wife='null', info={password=123456,url=男,driver=20190525,username=root} } */} 拓展方式注入我们可以使用p命名空间和c命名空间的方式进行注入。 1234567&lt;!--p命名空间注入，可以直接注入属性的值--&gt;&lt;!--p其实就是properties--&gt;&lt;bean id=&quot;user&quot; class=&quot;pojo.User&quot; p:name=&quot;秦疆&quot; p:age=&quot;18&quot;/&gt;&lt;!--c命名空间注入，可以直接注入属性的值--&gt;&lt;bean id=&quot;user2&quot; class=&quot;pojo.User&quot; c:name=&quot;狂神&quot; c:age=&quot;18&quot;/&gt; 注意点： p命名空间和c命名空间不能直接使用，需要导入xml约束； p命名空间需要存在无参构造器，而c命名空间需要存在有参构造器。 bean的作用域1.单例模式（默认） 每一个bean创建均为一个对象。 123456&lt;bean id=&quot;user&quot; class=&quot;pojo.User&quot; c:name=&quot;狂神&quot; c:age=&quot;18&quot; scope=&quot;singleton&quot;/&gt;User user1 = (User) context.getBean(&quot;user&quot;);User user2 = (User) context.getBean(&quot;user&quot;);即有：user1==user2 2.原型模式 每次从容器中getBean时，都会产生一个新的对象。 123456&lt;bean id=&quot;user&quot; class=&quot;pojo.User&quot; c:name=&quot;狂神&quot; c:age=&quot;18&quot; scope=&quot;prototype&quot;/&gt;User user1 = (User) context.getBean(&quot;user&quot;);User user2 = (User) context.getBean(&quot;user&quot;);即有：user1!=user2 3.其余的模式均为了解。 request，session，application，只能在web开发种使用到。","link":"/2023/02/07/Spring%E4%BA%8C/"},{"title":"SpringMVC（一）","text":"本系列主要进行SpringMVC框架的学习介绍，Spring MVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架。其中本篇文章进行SpringMVC的前端知识，包括MVC的介绍和Servlet的实现等。 回顾MVC什么是MVCMVC是模型(Model)、视图(View)、控制器(Controller)的简写，是一种软件设计规范。 是将业务逻辑、数据、显示分离的方法来组织代码。 MVC主要作用是降低了视图与业务逻辑间的双向偶合。 MVC不是一种设计模式，MVC是一种架构模式。当然不同的MVC存在差异。 Model（模型）：数据模型，提供要展示的数据，因此包含数据和行为，可以认为是领域模型或JavaBean组件（包含数据和行为），不过现在一般都分离开来：Value Object（数据Dao） 和 服务层（行为Service）。也就是模型提供了模型数据查询和模型数据的状态更新等功能，包括数据和业务。 View（视图）：负责进行模型的展示，一般就是我们见到的用户界面，客户想看到的东西。 Controller（控制器）：接收用户请求，委托给模型进行处理（状态改变），处理完毕后把返回的模型数据返回给视图，由视图负责展示。也就是说控制器做了个调度员的工作。 最典型的MVC就是JSP + servlet + javabean的模式。 MVC结构的主要框架： Model2时代 主要流程： 用户发请求； Servlet接收请求数据，并调用对应的业务逻辑方法； 业务处理完毕，返回更新后的数据给servlet； servlet转向到JSP，由JSP来渲染页面； 响应给前端更新后的页面。 职责分析： Controller：控制器 取得表单数据；调用业务逻辑；转向指定的页面 Model：模型 处理业务逻辑；保存数据的状态 View：视图 显示页面 回顾Servlet核心步骤： 1.新建一个Maven工程当做父工程，导入pom依赖；并建立一个Moudle，添加Web app的支持。 2.编写一个Servlet类，用来处理用户的请求 1234567891011121314151617181920212223242526272829//实现Servlet接口public class HelloServlet extends HttpServlet { @Override //继承了Servlet相关类，就需要重写doGet和doPost两种方法 protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { //接收请求，取得参数 String method = req.getParameter(&quot;method&quot;); if (method.equals(&quot;add&quot;)){ req.getSession().setAttribute(&quot;msg&quot;,&quot;执行了add方法&quot;); } if (method.equals(&quot;delete&quot;)){ req.getSession().setAttribute(&quot;msg&quot;,&quot;执行了delete方法&quot;); } //业务逻辑 // …..这里没有业务逻辑…. //视图跳转 req.getRequestDispatcher(&quot;/WEB-INF/jsp/page.jsp&quot;).forward(req,resp); //跳转到前端页面中，并继续传递请求 } @Override //实现复用，调用doGet中的方法 protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { doGet(req,resp); }} 3.编写page.jsp，在WEB-INF目录下新建一个jsp的文件夹，新建page.jsp 12345&lt;!--直接显示消息即可--&gt;&lt;body&gt; ${msg}&lt;/body&gt; 4.在web的配置文件：web.xml中注册Servlet 1234567891011&lt;servlet&gt;&lt;!--名称可以随便写，但要上下一致--&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;servlet.HelloServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;!--请求名称，即在路径中加入/hello就能进入Servlet类的请求中，并跳转到page.jsp页面--&gt; &lt;url-pattern&gt;/hello&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 5.配置Tomcat，并启动测试 http://localhost:8999/springmvc_01_servlet_war_exploded/hello?method=add http://localhost:8999/springmvc_01_servlet_war_exploded/hello?method=delete","link":"/2023/02/10/SpringMVC%E4%B8%80/"},{"title":"SpringMVC（三）","text":"本系列主要进行SpringMVC框架的学习介绍，Spring MVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架。其中本篇文章进行SpringMVC的各部分模块分析，包括控制器，结果跳转方式，数据处理方式，restful风格，乱码处理等。 模块分析控制器Controller 控制器复杂提供访问应用程序的行为，通常通过接口定义或注解定义两种方法实现； 控制器负责解析用户的请求并将其转换为一个模型（model）； 在Spring MVC中一个控制器类可以包含多个方法（但访问路径不能相同）。 实现Controller接口： Controller是一个接口，在org.springframework.web.servlet.mvc包下，接口中只有一个方法； 123456//实现该接口的类获得控制器功能public interface Controller { //处理请求且返回一个模型与视图对象 ModelAndView handleRequest(HttpServletRequest var1, HttpServletResponse var2) throws Exception;} 使用注解@Controller： @Controller注解类型用于声明Spring类的实例是一个控制器（在讲IOC时还提到了另外3个注解）； Spring可以使用扫描机制来找到应用程序中所有基于注解的控制器类，为了保证Spring能找到你的控制器，需要在配置文件中声明组件扫描。 注解@RequestMapping的介绍： @RequestMapping注解用于映射url到控制器类或一个特定的处理程序方法。可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。 结果跳转方式ModelAndView：（配置版代码就是使用这个） 设置ModelAndView对象 , 根据view的名称 , 和视图解析器跳到指定的页面。 页面 : {视图解析器前缀} + viewName +{视图解析器后缀} ServletAPI：（最开始的Servlet就是使用这个） 通过设置ServletAPI , 不需要视图解析器。 1、通过HttpServletResponse进行输出； 2、通过HttpServletResponse实现重定向； 3、通过HttpServletResponse实现转发。 SpringMVC：（注解版代码就是使用这个） 即使用注解+视图解析器（也可以不要，但需要采用完整路径） 4.3 数据处理–处理提交的数据提交的域名称和处理方法的参数名一致：直接提交 1234567//提交数据：http://localhost:8080/hello?name=kuangshen@RequestMapping(&quot;/hello&quot;)public String hello(String name){ System.out.println(name); return &quot;hello&quot;;} 提交的域名称和处理方法的参数名不一致：添加注解@RequestParam 12345678//@RequestParam(&quot;username&quot;) : username提交的域的名称//提交数据：http://localhost:8080/hello?username=kuangshen@RequestMapping(&quot;/hello&quot;)public String hello(@RequestParam(&quot;username&quot;) String name){ System.out.println(name); return &quot;hello&quot;;} 提交的是一个对象： 要求提交的表单域和对象的属性名一致，参数使用对象即可 1234567//提交数据：http://localhost:8080/hello?name=kuangshen&amp;id=1&amp;age=15@RequestMapping(&quot;/user&quot;)public String user(User user){ System.out.println(user); return &quot;hello&quot;;} 数据处理–数据显示到前端 通过ModelAndView – 配置版本 通过ModelMap – 与Model类似，继承了LinkedMap ，功能多一些 通过Model – 注解版本 restful风格Restful就是一个资源定位及资源操作的风格。不是标准也不是协议，只是一种风格。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。 风格介绍：用/来区分每一个响应，即使用路径变量。 使用路径变量的好处： 使路径变得更加简洁； 获得参数更加方便，框架会自动进行类型转换；同时可以约束访问参数，如果类型不一样，则访问不到对应的请求方法； 更加安全，不暴露后台函数的参数名称。 使用RESTful操作资源 ：可以通过不同的请求方式来实现不同的效果。 如下：请求地址一样，但是功能可以不同。（采用了不同的请求方式） http://127.0.0.1/item/1 查询，GET http://127.0.0.1/item 新增，POST http://127.0.0.1/item 更新，PUT http://127.0.0.1/item/1 删除，DELETE 在Spring MVC中可以使用 @PathVariable 注解，让方法参数的值对应绑定到一个URI模板变量上。 12345678910111213@Controllerpublic class RestFulController { //映射访问路径 @RequestMapping(&quot;/commit/{p1}/{p2}&quot;) public String index(@PathVariable int p1, @PathVariable int p2, Model model){ int result = p1+p2; //Spring MVC会自动实例化一个Model对象用于向视图中传值 model.addAttribute(&quot;msg&quot;, &quot;结果：&quot;+result); //返回视图位置 return &quot;test&quot;; }} 乱码问题SpringMVC给我们提供了一个过滤器 , 可以在web.xml中配置。 12345678910111213&lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;","link":"/2023/02/10/SpringMVC%E4%B8%89/"},{"title":"SpringMVC（二）","text":"本系列主要进行SpringMVC框架的学习介绍，Spring MVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架。其中本篇文章进行SpringMVC的基本知识讲解，初步介绍了SpringMVC及其实现原理，同时搭建了第一个SpringMVC程序。 什么是SpringMVC概述Spring MVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架。 Spring MVC的特点： 轻量级，简单易学； 高效 , 基于请求响应的MVC框架 与Spring兼容性好，无缝结合 约定优于配置 功能强大：RESTful、数据验证、格式化、本地化、主题等 简洁灵活 中心控制器Spring的web框架围绕DispatcherServlet设计，DispatcherServlet的作用是将请求分发到不同的处理器。**DispatcherServlet是一个实际的Servlet (它继承自HttpServlet 基类)**。 SpringMVC的原理如下图所示： 当发起请求时被前置的控制器拦截到请求，根据请求参数生成代理请求，找到请求对应的实际控制器，控制器处理请求，创建数据模型，访问数据库，将模型响应给中心控制器，控制器使用模型与视图渲染视图结果，将结果返回给中心控制器，再将结果返回给请求者。 SpringMVC执行原理（重要） 图为SpringMVC的一个较完整的流程图，实线表示SpringMVC框架提供的技术，不需要开发者实现，虚线表示需要开发者实现。 简要分析执行流程: 1.DispatcherServlet表示前置控制器，是整个SpringMVC的控制中心。用户发出请求，DispatcherServlet接收请求并拦截请求。我们假设请求的url为 : http://localhost:8080/SpringMVC/hello, 如上url拆分成三部分： http://localhost:8080: 服务器域名 SpringMVC: 部署在服务器上的web站点 hello: 表示控制器 通过分析，如上url表示为：请求位于服务器localhost:8080上的SpringMVC站点的hello控制器。 2.HandlerMapping为处理器映射。DispatcherServlet调用HandlerMapping,HandlerMapping根据请求url查找Handler。代码中为 ‘/‘ 表示能够查找所有的控制器。 3.HandlerExecution表示具体的Handler,其主要作用是根据url查找控制器，如上url被查找控制器为：hello。 4.HandlerExecution将解析后的信息传递给DispatcherServlet,如解析控制器映射等。 5.HandlerAdapter表示处理器适配器，其按照特定的规则去执行Handler。 6.Handler让具体的Controller执行。 7.Controller将具体的执行信息返回给HandlerAdapter,如ModelAndView。 8.HandlerAdapter将视图逻辑名或模型传递给DispatcherServlet。 9.DispatcherServlet调用视图解析器(ViewResolver)来解析HandlerAdapter传递的逻辑视图名。 10.视图解析器将解析的逻辑视图名传给DispatcherServlet。 11.DispatcherServlet根据视图解析器解析的视图结果，调用具体的视图。 12.最终视图呈现给用户。 第一个SpringMVC程序配置版1.新建一个Module， 添加web的支持，导入SpringMVC的依赖； 2.配置web.xml，注册DispatcherServlet： 12345678910111213141516171819202122&lt;!--配置DispatcherServlet：这个是SpringMVC的核心，即请求分发器--&gt;&lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--DispatcherServlet需要绑定一个springmvc的配置文件--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!--启动级别-1--&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;!--/匹配所有的请求；（不包括.jsp）--&gt;&lt;!--/*匹配所有的请求；（包括.jsp）--&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 3.编写SpringMVC 的配置文件springmvc-servlet.xml： 123456789101112131415161718192021&lt;!--处理器映射器--&gt;&lt;bean class=&quot;org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping&quot;/&gt;&lt;!--处理器适配器--&gt;&lt;bean class=&quot;org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter&quot;/&gt;&lt;!--视图解析器:DispatcherServlet给他的ModelAndView1.获取ModelAndView的数据(&quot;HelloSpringMVC&quot;);2.解析ModelAndView的视图名字(&quot;hello&quot;);3.拼接视图名字，找到对应的视图(&quot;/WEB-INF/jsp/hello.jsp&quot;);4.将数据渲染到这个视图上--&gt;&lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; id=&quot;InternalResourceViewResolver&quot;&gt; &lt;!--前缀--&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;!--后缀--&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;&lt;/bean&gt;&lt;!--Handler--&gt;&lt;!--BeanNameUrlHandlerMapping配置bean，其它处理器可能不需要配置--&gt;&lt;bean id=&quot;/hello&quot; class=&quot;controller.HelloController&quot;/&gt; 4.编写我们要操作业务Controller ，要么实现Controller接口，要么增加注解；需要返回一个ModelAndView： 123456789101112131415public class HelloController implements Controller{ public ModelAndView handleRequest(HttpServletRequest httpServletRequest,HttpServletResponse httpServletResponse) throws Exception{ //ModelAndView模型和视图 ModelAndViewmv=newModelAndView(); //封装对象，放在ModelAndView中 mv.addObject(&quot;msg&quot;,&quot;HelloSpringMVC!&quot;); //封装要跳转的视图，放在ModelAndView中 mv.setViewName(&quot;hello&quot;);//:/WEB-INF/jsp/hello.jsp return mv; }} 5.将自己的类交给SpringIOC容器，注册bean： 123&lt;!--Handler--&gt;&lt;bean id=&quot;/hello&quot; class=&quot;com.kuang.controller.HelloController&quot;/&gt; 6.编写要跳转的页面hello.jsp： 1234&lt;body&gt; ${msg}&lt;/body&gt; 7.配置Tomcat启动测试。 代码执行流程（自己理解的）: 用户请求http：//localhost:8080/SpringMVC/hello，DispatcherServlet接收请求并拦截请求，解析出hello满足我们的要求（我们的要求是’/‘，即所有的请求都能接收，执行的是web.xml的servlet-mapper配置），同时执行web.xml中DispatcherServlet的配置； DispatcherServlet的配置需要绑定springmvc的配置文件，因此接下来会进行处理器映射器BeanNameUrlHandlerMapping的配置，和处理器适配器SimpleControllerHandlerAdapter的配置，见springmvc-servlet.xml，对hello进行解析，并适配到对应的类中，即Controller； Controller代码执行，封装数据和要跳转的视图，返回ModelAndView类的对象，见HelloController.java； 视图解析器ViewResolver解析ModelAndView，得到对应的数据，同时拼接视图路径，将数据渲染到视图上，见springmvc-servlet.xml。 注解版1.新建一个Module， 添加web的支持，导入SpringMVC的依赖； 2配置web.xml，同上 3.配置springmvc-servlet.xml： 12345678910111213141516&lt;!--自动扫描包，让指定包下的注解生效,由IOC容器统一管理--&gt;&lt;context:component-scan base-package=&quot;controller&quot;/&gt;&lt;!--让SpringMVC不处理静态资源--&gt;&lt;mvc:default-servlet-handler/&gt;&lt;!--支持mvc注解驱动，免去了DefaultAnnotationHandlerMapping和AnnotationMethodHandlerAdapter实例的注入--&gt;&lt;mvc:annotation-driven/&gt;&lt;!--视图解析器--&gt;&lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; id=&quot;internalResourceViewResolver&quot;&gt; &lt;!--前缀--&gt; &lt;property name=&quot;prefix&quot;value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;!--后缀--&gt; &lt;property name=&quot;suffix&quot;value=&quot;.jsp&quot;/&gt;&lt;/bean&gt; 4.编写我们要操作业务Controller： 12345678910111213@Controllerpublic class HelloController{ //url：localhost:8999/hello @RequestMapping(&quot;/hello&quot;) public String sayHello(Model model){ //向模型中添加属性msg与值，可以在JSP页面中取出并渲染 model.addAttribute(&quot;msg&quot;,&quot;Hello,SpringMVC&quot;); //web-inf/jsp/test.jsp return&quot;test&quot;; }} 5.将自己的类交给SpringIOC容器，注册bean（省略）； 6.编写要跳转的页面hello.jsp，同上； 7.配置Tomcat启动测试。 注意：Controller 对应的类中： @Controller是为了让SpringIOC容器初始化时自动扫描到； @RequestMapping是为了映射请求路径，路径为/hello，若类上也有@RequestMapping，则路径需要叠加； 方法中声明Model类型的参数是为了把Action中的数据带到视图中； 方法返回的结果是视图的名称test，加上配置文件中的前后缀变成WEB-INF/jsp/test.jsp。 总结： 使用springMVC必须配置的三大件：处理器映射器、处理器适配器、视图解析器； 通常，我们只需要手动配置视图解析器，而处理器映射器和处理器适配器只需要开启注解驱动即可，而省去了大段的xml配置","link":"/2023/02/10/SpringMVC%E4%BA%8C/"},{"title":"SpringMVC（五）","text":"本系列主要进行SpringMVC框架的学习介绍，Spring MVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架。其中本篇文章进行SSM（Spring-SpringMVC-MyBatis）框架的整合，编写了一个书籍管理的代码，实现书籍的查询等功能。包括：准备工作，MyBatis层的搭建，Spring层的搭建，SpringMVC层的搭建，功能实现等五个步骤。 SSM框架整合准备工作1.创建数据库。创建一个存放数据库的表books，并让IDEA关联数据库。 1234567891011121314151617CREATE DATABASE `ssmbuild`;USE `ssmbuild`;DROP TABLE IF EXISTS `books`;CREATE TABLE `books` (`bookID` INT(10) NOT NULL AUTO_INCREMENT COMMENT '书id',`bookName` VARCHAR(100) NOT NULL COMMENT '书名',`bookCounts` INT(11) NOT NULL COMMENT '数量',`detail` VARCHAR(200) NOT NULL COMMENT '描述',KEY `bookID` (`bookID`)) ENGINE=INNODB DEFAULT CHARSET=utf8INSERT INTO `books`(`bookID`,`bookName`,`bookCounts`,`detail`)VALUES(1,'Java',1,'从入门到放弃'),(2,'MySQL',10,'从删库到跑路'),(3,'Linux',5,'从进门到进牢'); 2.基本环境搭建。 新建Maven项目 -&gt; 添加web支持 -&gt; 导入依赖（数据库相关mysql, c3p0；mybatis相关mybatis, mybatis-spring；spring相关spring-webmvc, spring-jdbc；servlet-jsp相关servlet-api, jsp-api, jstl；工具junit, lombok）-&gt; Maven资源过滤 -&gt; 建立基本框架（dao, pojo, service, controller） 解释：（自己理解的） dao层负责底层功能实现，如基本的增删改查操作，需要配置接口和对应的xml，编写sql语言； pojo层为对象类，即为要操作的对象，编写基本的属性和get set等方法； service层为业务层，对dao层的接口进行调用，需要配置相同的接口，以及实现类，同时进行set注入； controller层为控制层，用于前后端交互，对service层进行调用，接收前端的参数，进行后端功能的实现； Mybatis层1.编写数据库配置文件database.properties。 存储数据库基本信息。 12345jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/ssmbuild?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8jdbc.username=rootjdbc.password=123456 2.编写mybatis的核心配置文件mybatis-config.xml。 主要进行别名和设置的编写，以及mapper的配置，其余的交给spring的配置文件。 123456789&lt;configuration&gt; &lt;typeAliases&gt; &lt;package name=&quot;com.kuang.pojo&quot;/&gt; &lt;/typeAliases&gt; &lt;mappers&gt; &lt;mapper resource=&quot;BookMapper.xml&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 3.编写pojo层的实体类Books。 12345678910@Data@AllArgsConstructor@NoArgsConstructorpublic class Books { private int bookID; private String bookName; private int bookCounts; private String detail;} 4.编写dao层对应接口BookMapper及其配置文件BookMapper.xml。 这里以查询所有书籍为例，具体的见原代码。 1234567891011121314//接口public interface BookMapper { //查询全部Book,返回list集合 List&lt;Books&gt; queryAllBook();}//配置文件&lt;mapper namespace=&quot;com.kuang.dao.BookMapper&quot;&gt;&lt;!--查询全部Book--&gt; &lt;select id=&quot;queryAllBook&quot; resultType=&quot;Books&quot;&gt; SELECT * from ssmbuild.books &lt;/select&gt;&lt;/mapper&gt; 5.编写service层的对应接口BookService和实现类BookServiceImpl。 对dao层进行调用，供controller层实现。 123456789101112131415161718//接口public interface BookService { List&lt;Books&gt; queryAllBook();}//实现类public class BookServiceImpl implements BookService { //调用dao层的操作，设置一个set接口，方便Spring管理 private BookMapper bookMapper; public void setBookMapper(BookMapper bookMapper) { this.bookMapper = bookMapper; } public List&lt;Books&gt; queryAllBook() { return bookMapper.queryAllBook(); }} Spring层1.spring层整合mybatis层，编写配置文件spring-dao.xml。 主要流程： 配置数据库底层（数据库文件、连接池配置）； sqlSessionFactory对象的创建（注入连接池、关联mybatis配置文件）； dao层接口注入（采用MapperScannerConfigurer，直接进行Factory的注入和mapper的配置，就不用通过sqlSession对象的创建进行mapper 的配置了） 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!-- 配置整合mybatis --&gt;&lt;!-- 1.关联数据库文件 --&gt;&lt;context:property-placeholder location=&quot;classpath:database.properties&quot;/&gt;&lt;!-- 2.数据库连接池 --&gt;&lt;!--数据库连接池 dbcp 半自动化操作 不能自动连接 c3p0 自动化操作（自动的加载配置文件 并且设置到对象里面）--&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;!-- 配置连接池属性 --&gt; &lt;property name=&quot;driverClass&quot; value=&quot;${jdbc.driver}&quot;/&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;${jdbc.url}&quot;/&gt; &lt;property name=&quot;user&quot; value=&quot;${jdbc.username}&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot;/&gt; &lt;!-- c3p0连接池的私有属性 --&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;30&quot;/&gt; &lt;property name=&quot;minPoolSize&quot; value=&quot;10&quot;/&gt; &lt;!-- 关闭连接后不自动commit --&gt; &lt;property name=&quot;autoCommitOnClose&quot; value=&quot;false&quot;/&gt; &lt;!-- 获取连接超时时间 --&gt; &lt;property name=&quot;checkoutTimeout&quot; value=&quot;10000&quot;/&gt; &lt;!-- 当获取连接失败重试次数 --&gt; &lt;property name=&quot;acquireRetryAttempts&quot; value=&quot;2&quot;/&gt;&lt;/bean&gt;&lt;!-- 3.配置SqlSessionFactory对象 --&gt;&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!-- 注入数据库连接池 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!-- 配置MyBaties全局配置文件:mybatis-config.xml --&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt;&lt;/bean&gt;&lt;!-- 4.配置扫描Dao接口包，动态实现Dao接口注入到spring容器中 --&gt;&lt;!--解释 ：https://www.cnblogs.com/jpfss/p/7799806.html--&gt;&lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;!-- 注入sqlSessionFactory --&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt; &lt;!-- 给出需要扫描Dao接口包 --&gt; &lt;property name=&quot;basePackage&quot; value=&quot;dao&quot;/&gt;&lt;/bean&gt; 2.spring层整合service层，编写配置文件spring-service.xml。 主要流程： 扫描service层的bean； 进行service层类的注入； 事务配置（需要注入数据库连接池）。 123456789101112131415&lt;!-- 扫描service相关的bean --&gt;&lt;!--自动扫描包，让指定包下的注解生效,由IOC容器统一管理--&gt;&lt;context:component-scan base-package=&quot;service&quot; /&gt;&lt;!--BookServiceImpl注入到IOC容器中--&gt;&lt;bean id=&quot;BookServiceImpl&quot; class=&quot;service.BookServiceImpl&quot;&gt; &lt;property name=&quot;bookMapper&quot; ref=&quot;bookMapper&quot;/&gt;&lt;/bean&gt;&lt;!-- 配置事务管理器 --&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;!-- 注入数据库连接池 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt; SpringMVC层1.编写配置文件web.xml。 主要包括DispatcherServlet的配置，和MVC过滤器的配置。 1234567891011121314151617181920212223242526272829303132333435&lt;!--DispatcherServlet--&gt;&lt;servlet&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!--一定要注意:我们这里加载的是总的配置文件，之前被这里坑了！--&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;!--encodingFilter--&gt;&lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;!--Session过期时间--&gt;&lt;session-config&gt; &lt;session-timeout&gt;15&lt;/session-timeout&gt;&lt;/session-config&gt; 2.编写springmvc的配置文件spring-mvc.xml。 主要流程： 开启注解驱动和静态资源默认配置（省去了适应期和映射器的配置）； 配置视图解析器（这个一定要配）； 扫描controller层相关bean。 123456789101112131415161718&lt;!-- 配置SpringMVC --&gt;&lt;!-- 1.开启SpringMVC注解驱动 --&gt;&lt;mvc:annotation-driven /&gt;&lt;!-- 2.静态资源默认servlet配置--&gt;&lt;mvc:default-servlet-handler/&gt;&lt;!-- 3.配置jsp 显示ViewResolver视图解析器 --&gt;&lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot; /&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;&lt;/bean&gt;&lt;!-- 4.扫描web相关的bean --&gt;&lt;!--自动扫描包，让指定包下的注解生效,由IOC容器统一管理--&gt;&lt;context:component-scan base-package=&quot;controller&quot;/&gt; 3.Spring配置整合文件，applicationContext.xml 1234&lt;import resource=&quot;spring-dao.xml&quot;/&gt;&lt;import resource=&quot;spring-service.xml&quot;/&gt;&lt;import resource=&quot;spring-mvc.xml&quot;/&gt; 功能实现1.编写BookController类。 123456789101112131415@Controller@RequestMapping(&quot;/book&quot;)public class BookController { @Autowired @Qualifier(&quot;BookServiceImpl&quot;) private BookService bookService; @RequestMapping(&quot;/allBook&quot;) public String list(Model model) { List&lt;Books&gt; list = bookService.queryAllBook(); model.addAttribute(&quot;list&quot;, list); return &quot;allBook&quot;; }} 2.编写首页index.jsp，编写展示所有书籍的页面allBook.jsp，此处省略。 3.编写其它功能，如增删改等。最后配置Tomcat服务器进行运行（导入lib，配置Tomcat）。结束！","link":"/2023/02/10/SpringMVC%E4%BA%94/"},{"title":"SpringMVC（四）","text":"本系列主要进行SpringMVC框架的学习介绍，Spring MVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架。其中本篇文章进行SpringMVC的一些拓展内容和前后端分离的知识介绍，包括Json，Ajax，拦截器，文件等。 JSONjson的有关内容具体见：https://mp.weixin.qq.com/s/RAqRKZJqsJ78HRrJg71R1g 什么是JSON JSON(JavaScript Object Notation, JS 对象标记) 是一种轻量级的数据交换格式，目前使用特别广泛； 采用完全独立于编程语言的文本格式来存储和表示数据； 简洁和清晰的层次结构使得 JSON 成为理想的数据交换语言； 易于人阅读和编写，同时也易于机器解析和生成，并有效地提升网络传输效率。 在 JavaScript 语言中，一切都是对象。因此，任何JavaScript 支持的类型都可以通过 JSON 来表示，例如字符串、数字、对象、数组等。看看他的要求和语法格式： 对象表示为键值对，数据由逗号分隔 花括号保存对象 方括号保存数组 JSON 键值对是用来保存 JavaScript 对象的一种方式，和 JavaScript 对象的写法也大同小异，键/值对组合中的键名写在前面并用双引号 “” 包裹，使用冒号 : 分隔，然后紧接着值： {“name”: “QinJiang”} {“age”: “3”} {“sex”: “男”} 很多人搞不清楚 JSON 和 JavaScript 对象的关系，甚至连谁是谁都不清楚。其实，可以这么理解： JSON 是 JavaScript 对象的字符串表示法，它使用文本表示一个 JS 对象的信息，本质是一个字符串。 JSON 和 JavaScript 对象互转要实现从JSON字符串转换为JavaScript 对象，使用 JSON.parse() 方法： 1234567var obj = JSON.parse('{&quot;a&quot;: &quot;Hello&quot;, &quot;b&quot;: &quot;World&quot;}');//结果是 {a: 'Hello', b: 'World'}//要实现从JavaScript 对象转换为JSON字符串，使用 JSON.stringify() 方法：var json = JSON.stringify({a: 'Hello', b: 'World'});//结果是 '{&quot;a&quot;: &quot;Hello&quot;, &quot;b&quot;: &quot;World&quot;}' Controller返回JSON数据为什么要这样做？为了得到JSON格式的数据，并交给前端使用。 Controller类： 12345678910111213141516171819@RestController //直接返回字符串，不走视图管理器public class UserController { //produces:指定响应体返回类型和编码 @RequestMapping(value = &quot;/json1&quot;) public String json1() throws JsonProcessingException { //创建一个jackson的对象映射器，用来解析数据 ObjectMapper mapper = new ObjectMapper(); //创建一个对象 User user = new User(&quot;秦疆1号&quot;, 3, &quot;男&quot;); //将我们的对象解析成为json格式 String str = mapper.writeValueAsString(user); //由于@ResponseBody注解，这里会将str转成json格式返回；十分方便 return str; }} springmvc-servlet.xml：添加防止json乱码的部分 123456789101112131415&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters register-defaults=&quot;true&quot;&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;constructor-arg value=&quot;UTF-8&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt; &lt;property name=&quot;objectMapper&quot;&gt; &lt;bean class=&quot;org.springframework.http.converter.json.Jackson2ObjectMapperFactoryBean&quot;&gt; &lt;property name=&quot;failOnEmptyBeans&quot; value=&quot;false&quot;/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 注意：要记得导依赖，同时防乱码（springmvc配置文件中），具体见代码。 Ajax研究Ajax介绍 AJAX = Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）； AJAX 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术； 传统的网页(即不用AJAX技术的网页)，想要更新内容或者提交一个表单，都需要重新加载整个网页； 使用AJAX技术的网页，通过在后台服务器进行少量的数据交换，就可以实现异步局部更新。 jQuery实现Ajax例子1：检测ajax请求： 1.配置AjaxController 123456789101112@Controllerpublic class AjaxController { @RequestMapping(&quot;/a1&quot;) public void ajax1(String name , HttpServletResponse response) throws IOException { if (&quot;admin&quot;.equals(name)){ response.getWriter().print(&quot;true&quot;); }else{ response.getWriter().print(&quot;false&quot;); } }} 2.编写测试文件index.jsp，需要script导包 123456789101112131415161718192021&lt;head&gt; &lt;title&gt;$Title$&lt;/title&gt; &lt;script src=&quot;https://code.jquery.com/jquery-3.1.1.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; function a1(){ $.post({ url:&quot;${pageContext.request.contextPath}/a1&quot;, data:{'name':$(&quot;#txtName&quot;).val()}, success:function (data,status) { alert(data); alert(status); } }); } &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;%--onblur：失去焦点触发事件--%&gt; 用户名:&lt;input type=&quot;text&quot; id=&quot;txtName&quot; onblur=&quot;a1()&quot;/&gt;&lt;/body&gt; 3.启动Tomcat测试，打开浏览器的控制台，当我们鼠标离开输入框的时候，可以看到发出了一个ajax的请求，即为后台返回给我们的结果 例子2：输入框提示功能： 1.配置AjaxController 12345678910111213141516171819202122232425@RestControllerpublic class AjaxController { @RequestMapping(&quot;/a3&quot;) public String ajax3(String name,String pwd){ String msg = &quot;&quot;; //模拟数据库中存在数据 if (name!=null){ if (&quot;admin&quot;.equals(name)){ msg = &quot;OK&quot;; }else { msg = &quot;用户名输入错误&quot;; } } if (pwd!=null){ if (&quot;123456&quot;.equals(pwd)){ msg = &quot;OK&quot;; }else { msg = &quot;密码输入有误&quot;; } } return msg; //由于@RestController注解，将msg转成json格式返回 }} 2.编写测试文件login.jsp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;head&gt; &lt;title&gt;ajax&lt;/title&gt; &lt;script src=&quot;${pageContext.request.contextPath}/statics/js/jquery-3.1.1.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; &lt;!--Ajax监测--&gt; function a1(){ $.post({ url:&quot;${pageContext.request.contextPath}/a3&quot;, data:{'name':$(&quot;#name&quot;).val()}, success:function (data) { if (data.toString()=='OK'){ $(&quot;#userInfo&quot;).css(&quot;color&quot;,&quot;green&quot;); }else { $(&quot;#userInfo&quot;).css(&quot;color&quot;,&quot;red&quot;); } $(&quot;#userInfo&quot;).html(data); } }); } function a2(){ $.post({ url:&quot;${pageContext.request.contextPath}/a3&quot;, data:{'pwd':$(&quot;#pwd&quot;).val()}, success:function (data) { if (data.toString()=='OK'){ $(&quot;#pwdInfo&quot;).css(&quot;color&quot;,&quot;green&quot;); }else { $(&quot;#pwdInfo&quot;).css(&quot;color&quot;,&quot;red&quot;); } $(&quot;#pwdInfo&quot;).html(data); } }); } &lt;/script&gt;&lt;/head&gt;&lt;!--页面显示--&gt;&lt;body&gt; &lt;p&gt; 用户名:&lt;input type=&quot;text&quot; id=&quot;name&quot; onblur=&quot;a1()&quot;/&gt; &lt;span id=&quot;userInfo&quot;&gt;&lt;/span&gt; &lt;/p&gt; &lt;p&gt; 密码:&lt;input type=&quot;text&quot; id=&quot;pwd&quot; onblur=&quot;a2()&quot;/&gt; &lt;span id=&quot;pwdInfo&quot;&gt;&lt;/span&gt; &lt;/p&gt;&lt;/body&gt; 3.Tomcat服务器连接，网页测试 测试结果：能够实现动态请求响应，局部刷新。 鼠标离开输入框后，会判断输入内容是否满足要求，如果不满足，会进行提示。 拦截器和文件拦截器SpringMVC的处理器拦截器类似于Servlet开发中的过滤器Filter，用于对处理器进行预处理和后处理。 开发者可以自己定义一些拦截器来实现特定的功能。 过滤器与拦截器的区别：拦截器是AOP思想的具体应用。 过滤器： servlet规范中的一部分，任何java web工程都可以使用 在url-pattern中配置了/*之后，可以对所有要访问的资源进行拦截 拦截器： 拦截器是SpringMVC框架自己的，只有使用了SpringMVC框架的工程才能使用 拦截器只会拦截访问的控制器方法， 如果访问的是jsp/html/css/image/js是不会进行拦截的 自定义拦截器：实现 HandlerInterceptor 接口。 1.定义拦截器类： 1234567891011121314151617181920public class MyInterceptor implements HandlerInterceptor { //在请求处理的方法之前执行 //如果返回true执行下一个拦截器 //如果返回false就不执行下一个拦截器 public boolean preHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o) throws Exception { System.out.println(&quot;------------处理前------------&quot;); return true; } //在请求处理方法执行之后执行 public void postHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, ModelAndView modelAndView) throws Exception { System.out.println(&quot;------------处理后------------&quot;); } //在dispatcherServlet处理后执行,做清理工作. public void afterCompletion(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) throws Exception { System.out.println(&quot;------------清理------------&quot;); }} 2.在springmvc的配置文件中配置拦截器： 123456789101112&lt;!--关于拦截器的配置--&gt;&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!--/** 包括路径及其子路径--&gt; &lt;!--/admin/* 拦截的是/admin/add等等这种 , /admin/add/user不会被拦截--&gt; &lt;!--/admin/** 拦截的是/admin/下的所有--&gt; &lt;mvc:mapping path=&quot;/**&quot;/&gt; &lt;!--bean配置的就是拦截器--&gt; &lt;bean class=&quot;interceptor.MyInterceptor&quot;/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 3.编写Controller： 1234567891011//测试拦截器的控制器@Controllerpublic class InterceptorController { @RequestMapping(&quot;/interceptor&quot;) @ResponseBody public String testFunction() { System.out.println(&quot;控制器中的方法执行了&quot;); return &quot;hello&quot;; }} 前端index.jsp 12&lt;a href=&quot;${pageContext.request.contextPath}/interceptor&quot;&gt;拦截器测试&lt;/a&gt; 文件 如果想使用Spring的文件上传功能，则需要在上下文中配置MultipartResolver； 前端表单要求：为了能上传文件，必须将表单的method设置为POST，并将enctype设置为multipart/form-data。只有在这样的情况下，浏览器才会把用户选择的文件以二进制数据发送给服务器。 文件上传的具体流程： 1.配置bean 123456789&lt;!--文件上传配置--&gt;&lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt; &lt;!-- 请求的编码格式，必须和jSP的pageEncoding属性一致，以便正确读取表单的内容，默认为ISO-8859-1 --&gt; &lt;property name=&quot;defaultEncoding&quot; value=&quot;utf-8&quot;/&gt; &lt;!-- 上传文件大小上限，单位为字节（10485760=10M） --&gt; &lt;property name=&quot;maxUploadSize&quot; value=&quot;10485760&quot;/&gt; &lt;property name=&quot;maxInMemorySize&quot; value=&quot;40960&quot;/&gt;&lt;/bean&gt; 2.编写前端界面 12345&lt;form action=&quot;&quot; enctype=&quot;multipart/form-data&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;file&quot; name=&quot;file&quot;/&gt; &lt;input type=&quot;submit&quot;&gt;&lt;/form&gt; 3.Controller控制器 12345678910111213141516171819202122232425262728293031323334353637383940414243@Controllerpublic class FileController { //@RequestParam(&quot;file&quot;) 将name=file控件得到的文件封装成CommonsMultipartFile 对象 //批量上传CommonsMultipartFile则为数组即可 @RequestMapping(&quot;/upload&quot;) public String fileUpload(@RequestParam(&quot;file&quot;) CommonsMultipartFile file , HttpServletRequest request) throws IOException { //获取文件名 : file.getOriginalFilename(); String uploadFileName = file.getOriginalFilename(); //如果文件名为空，直接回到首页！ if (&quot;&quot;.equals(uploadFileName)){ return &quot;redirect:/index.jsp&quot;; } System.out.println(&quot;上传文件名 : &quot;+uploadFileName); //上传路径保存设置 String path = request.getServletContext().getRealPath(&quot;/upload&quot;); //如果路径不存在，创建一个 File realPath = new File(path); if (!realPath.exists()){ realPath.mkdir(); } System.out.println(&quot;上传文件保存地址：&quot;+realPath); InputStream is = file.getInputStream(); //文件输入流 OutputStream os = new FileOutputStream(new File(realPath,uploadFileName)); //文件输出流 //读取写出 int len=0; byte[] buffer = new byte[1024]; while ((len=is.read(buffer))!=-1){ os.write(buffer,0,len); os.flush(); } os.close(); is.close(); return &quot;redirect:/index.jsp&quot;; }} 文件下载的具体流程： 1、设置 response 响应头 2、读取文件 – InputStream 3、写出文件 – OutputStream 4、执行操作 5、关闭流 （先开后关） 1234567891011121314151617181920212223242526272829303132333435@RequestMapping(value=&quot;/download&quot;)public String downloads(HttpServletResponse response ,HttpServletRequest request) throws Exception{ //要下载的图片地址 String path = request.getServletContext().getRealPath(&quot;/upload&quot;); String fileName = &quot;基础语法.jpg&quot;; //1、设置response 响应头 response.reset(); //设置页面不缓存,清空buffer response.setCharacterEncoding(&quot;UTF-8&quot;); //字符编码 response.setContentType(&quot;multipart/form-data&quot;); //二进制传输数据 //设置响应头 response.setHeader(&quot;Content-Disposition&quot;,&quot;attachment;fileName=&quot;+URLEncoder.encode(fileName, &quot;UTF-8&quot;)); File file = new File(path,fileName); //2、读取文件--输入流 InputStream input=new FileInputStream(file); //3、写出文件--输出流 OutputStream out = response.getOutputStream(); byte[] buff =new byte[1024]; int index=0; //4、执行 写出操作 while((index= input.read(buff))!= -1){ out.write(buff, 0, index); out.flush(); } out.close(); input.close(); return null;} 前端页面： 1&lt;a href=&quot;/download&quot;&gt;点击下载&lt;/a&gt;","link":"/2023/02/10/SpringMVC%E5%9B%9B/"},{"title":"SpringBoot（一）","text":"本系列主要进行SpringBoot框架的学习介绍，SpringBoot是一种基于Spring的框架，能够开箱即用，提供各种默认配置来简化项目配置，来对Spring进行简化。其中本篇文章进行SpringBoot的简介和有关配置文件的介绍，同时会讲解SpringBoot的自动装配原理并搭建第一个SpringBoot程序。 SpringBoot简介回顾SpringSpring是一个轻量级的Java开发框架。Spring是为了解决企业级应用开发的复杂性而创建的，简化开发。 Spring是如何简化Java开发的： 为了降低Java开发的复杂性，Spring采用了以下4种关键策略： 基于POJO的轻量级和最小侵入性编程，所有东西都是bean； 通过IOC，依赖注入（DI）和面向接口实现松耦合； 基于切面（AOP）和惯例进行声明式编程； 通过切面和模版减少样式代码，SqlSessionTemplate，RedisTemplate，xxxTemplate… SpringBoot的主要优点： 为所有Spring开发者更快的入门； 开箱即用，提供各种默认配置来简化项目配置； 内嵌式容器简化Web项目； 没有冗余代码生成和XML配置的要求。 了解微服务微服务（或微服务架构）是一种云原生架构方法，其中单个应用程序由许多松散耦合且可独立部署的较小组件或服务组成。这些服务通常： 有自己的堆栈，包括数据库和数据模型； 通过REST API，事件流和消息代理的组合相互通信； 它们是按业务能力组织的，分隔服务的线通常称为有界上下文。 尽管有关微服务的许多讨论都围绕体系结构定义和特征展开，但它们的价值可以通过相当简单的业务和组织收益更普遍地理解： 可以更轻松地更新代码。 团队可以为不同的组件使用不同的堆栈。 组件可以彼此独立地进行缩放，从而减少了因必须缩放整个应用程序而产生的浪费和成本，因为单个功能可能面临过多的负载。 spring带来了构建大型分布式微服务的全套，全程产品： 构建一个个功能独立的微服务应用单元，可以使用spring boot，快速帮我们构建一个应用； 大型分布式网络服务的调用，这部分由spring cloud完成，实现分布式； 在分布式中间，进行流式数据计算、批处理，我们用spring cloud data flow。 第一个SpringBoot程序直接在IDEA中进行创建，主要步骤： 1.环境配置 创建Spring Initializr项目 -&gt; url选择custom：https://start.springboot.io/ -&gt; Type改为Maven，java版本改为8 -&gt; 勾选Java web依赖，设置SpringBoot版本2.7.8（超过3的版本默认使用jdk17） 会自动进行导包和web的配置。 2.编写一个http接口 在主程序（即启动文件）的同级目录下，新建一个controller包，一定要在同级目录下，否则识别不到； 在包中新建一个HelloController类： 12345678@RestControllerpublic class HelloController { @RequestMapping(&quot;/hello&quot;) public String hello() { return &quot;Hello World&quot;; } } 3.在springboot的默认配置文件（application.properties）中修改端口号：（默认为8080） server.port=8999 自动装配机制源码分析（从启动类的注解开始分析）：1.主启动类的注解@SpringBootApplication： 作用：标注在某个类上说明这个类是SpringBoot的主配置类 ， SpringBoot就应该运行这个类的main方法来启动SpringBoot应用； 2.进入这个注解：可以看到上面还有很多其他注解 @SpringBootConfiguration , @EnableAutoConfiguration, @ComponentScan ComponentScan 这个注解在Spring中很重要，它对应XML配置中的元素。 作用：自动扫描并加载符合条件的组件或者bean，将这个bean定义加载到IOC容器中 @SpringBootConfiguration 作用：SpringBoot的配置类，标注在某个类上，表示这是一个SpringBoot的配置类； 上面有注解@Configuration，说明这是一个配置类 ，配置类就是对应Spring的xml 配置文件； 还有@Component，说明，启动类本身也是Spring中的一个组件。 @EnableAutoConfiguration 作用：开启自动配置功能。以前我们需要自己配置的东西，而现在SpringBoot可以自动帮我们配置 ；@EnableAutoConfiguration告诉SpringBoot开启自动配置功能，这样自动配置才能生效； 3.找到了有关AutoConfiguration的字样，进入@EnableAutoConfiguration注解继续查看： @AutoConfigurationPackage：自动配置包 @Import({AutoConfigurationImportSelector.class})：给容器导入组件。会导入哪些组件呢？ 4.继续进入AutoConfigurationImportSelector查看类和方法，找到了getCandidateConfigurations方法： 作用：获取组件的配置； 5.继续查看下面调用的方法，继续发现了loadFactoryNames()和loadSpringFactories()方法； 6.在loadSpringFactories()中发现了spring.factories，全局搜索它，看到了很多自动配置的文件，这就是自动配置根源所在。 SpringBoot自动装配原理： （从启动类的注解@SpringBootApplication开始进行源码分析，最后找到了自动装配的路径/META-INF/spring.factories） springboot在启动的时候，会从类路径下/META-INF/spring.factories获取EnableAutoConfiguration指定的值； 将这些值作为自动配置的类导入容器，自动配置就会生效，帮我进行自动配置工作； 整个javaEE的解决方案和自动配置的东西都在springboot-autoconfigure的jar包中； 这个包会给容器中导入非常多的自动配置类（xxxAutoConfiguration），就是这些类给容器中导入了这个场景需要的所有组件，并配置好这些组件; 有了自动配置类，免去了我们手动编写配置注入功能组件等的工作。 结论：springboot所有自动配置都是在启动的时候扫描并加载spring.factories文件，所有的自动配置类都在这里面，但是不一定生效，需要判断条件是否成立。只要导入了对应的start，就有对应的启动器了，有了启动器，我们自动装配就会生效，然后就配置成功。 源码分析（从SpringApplication.run方法开始分析）：SpringApplication类主要做了以下四件事情： 推断应用的类型是普通的项目还是Web项目； 查找并加载所有可用初始化器，设置到initializers属性中； 找出所有的应用程序监听器，设置到listeners属性中； 推断并设置main方法的定义类，找到运行的主类。（这一点最重要，找到主类） 面试问题：关于SpringBoot，谈谈你的理解： 讲一讲自动装配（重点）； 讲一讲run()方法： 能够推断应用的类型是普通的项目还是Web项目（web项目会一直启动，普通项目不行）； 推断并设置main方法的定义类，找到运行的主类（找不到主类，就无法加载运行）； run方法的执行中，会有一些全局存在的监听器，能够获取上下文并处理bean。 SpringBoot配置文件yaml语法SpringBoot使用一个全局的配置文件，配置文件名称是固定的，可以用properties文件或yaml文件进行配置，配置文件名称必须为application。 application.properties：语法结构 ：key=value application.yaml：语法结构 ：key：空格 value 配置文件的作用：修改SpringBoot自动配置的默认值，因为SpringBoot在底层都给我们自动配置好了。 yaml语法要求： 空格不能省略； 以缩进来控制层级关系，只要是左边对齐的一列数据都是同一个层级的； 属性和值的大小写都是十分敏感的。 yaml注入配置文件1.编写配置文件application.yaml，实现注入： 123456789101112131415person: name: qinjiang age: 3 happy: false birth: 2000/01/01 maps: {k1:v1,k2:v2} lists: -code -girl -music dog: name: 旺财 age: 1 2.编写用于测试的Person类： 123456789101112@Component //声明为Spring组件，注册bean到容器中@ConfigurationProperties(prefix=&quot;person&quot;) //等同于在每个属性上设置@Valuepublic class Person{ private String name; private Integer age; private Boolean happy; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog;} @ConfigurationProperties作用： 将配置文件中配置的每一个属性的值，映射到这个组件中； 告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； 参数prefix=”person”：将配置文件中的person下面的所有属性一一对应。 3.进行单元测试： 12345678910@SpringBootTestclass Springboot02 ConfigApplicationTests{ @Autowired Person person;//将person自动注入进来 @Test void context Loads(){ System.out.println(person); }} yaml配置文件进行注入（即通过@ConfigurationProperties）与@Value方式的区别： @ConfigurationProperties只需要写一次即可 ， @Value则需要每个字段都添加； @ConfigurationProperties支持松散绑定，而@Value不支持。松散绑定：比如我的yml中写的last-name，这个和lastName是一样的效果； @ConfigurationProperties支持JSR303数据校验，而@Value不支持。数据校验：这个就是我们可以在字段使用前增加一层过滤器验证，以保证数据的合法性； 复杂类型封装，yaml中可以封装对象（如上例中的Dog）， 使用value就不支持。 结论： 配置yml和配置properties都可以获取到值，强烈推荐 yml； 如果我们在某个业务中，只需要获取配置文件中的某个值，可以使用一下@value； 如果说，我们专门编写了一个JavaBean来和配置文件进行一一映射，就直接使用@configurationProperties，不要犹豫！ 多环境切换1.使用多配置文件实现环境切换： 我们在主配置文件编写的时候，文件名可以是 application-{profile}.properties/yml，用来指定多个环境版本； 例如： application-test.properties 代表测试环境配置 application-dev.properties 代表开发环境配置 但是Springboot并不会直接启动这些配置文件，它默认使用application.properties主配置文件； 我们需要通过一个配置来选择需要激活的环境： 1234#比如在配置文件中指定使用dev环境，我们可以通过设置不同的端口号进行测试；#我们启动SpringBoot，就可以看到已经切换到dev下的配置了spring.profiles.active=dev 2.使用单一配置文件实现环境切换： 和properties配置文件中一样，但是使用yml去实现不需要创建多个配置文件。在主配置文件application.yaml下创建即可： 1234567891011121314151617181920212223server: port: 8081 #选择要激活哪个环境块spring: profiles: active: prod---server: port: 8083spring: profiles: dev #配置环境的名称---server: port: 8084spring: profiles: prod #配置环境的名称 注意：如果yml和properties同时都配置了端口，并且没有激活其他环境 ， 默认会使用properties配置文件的配置。 配置文件位置与优先级的关系： springboot启动会扫描以下位置的application.properties或者application.yml文件作为SpringBoot的默认配置文件： 优先级1：项目路径下的config文件夹中的配置文件； 优先级2：项目路径下的配置文件； 优先级3：资源路径下的config文件夹的配置文件； 优先级4：资源路径下配置文件。 说明SpringBoot默认创建的配置文件位置优先级最低。","link":"/2023/02/17/SpringBoot%E4%B8%80/"},{"title":"SpringBoot（三）","text":"本系列主要进行SpringBoot框架的学习介绍，SpringBoot是一种基于Spring的框架，能够开箱即用，提供各种默认配置来简化项目配置，来对Spring进行简化。其中本篇文章会对将SpringBoot与数据库进行整合，包括SpringBoot与JDBC的整合，SpringBoot与Mybatis的整合，以及druid数据源的学习。 SpringBoot整合数据库整合JDBCSpring Boot 底层都是采用 Spring Data 的方式进行统一处理各种数据库。 例子1：查看JDBC默认的数据源和连接池1.新建项目，需引入jdbc模块和mysql驱动 2.编写配置文件，设置数据源 12345678spring:datasource: username: root password: 123456 #serverTimezone=UTC解决时区的报错 url: jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8 driver-class-name: com.mysql.cj.jdbc.Driver 3.测试 1234567891011121314151617@SpringBootTestclass SpringbootDataJdbcApplicationTests { //DI注入数据源 @Autowired DataSource dataSource; @Test public void contextLoads() throws SQLException { //看一下默认数据源 System.out.println(dataSource.getClass()); //获得连接 Connection connection = dataSource.getConnection(); System.out.println(connection); //关闭连接 connection.close(); }} 可以看到默认数据源为：HikariDataSource 数据源的所有自动配置都在：DataSourceAutoConfiguration文件： 1234567@Import( {Hikari.class, Tomcat.class, Dbcp2.class, Generic.class, DataSourceJmxConfiguration.class})protected static class PooledDataSourceConfiguration { protected PooledDataSourceConfiguration() { }} HikariDataSource 号称 Java WEB 当前速度最快的数据源，相比于传统的 C3P0 、DBCP、Tomcat jdbc 等连接池更加优秀；可以使用 spring.datasource.type 指定自定义的数据源类型，值为：要使用的连接池实现的完全限定名。 例子2：CURD增删改查操作JdbcTemplate类： 有了数据源(com.zaxxer.hikari.HikariDataSource)，然后可以拿到数据库连接(java.sql.Connection)，有了连接，就可以使用原生的 JDBC 语句来操作数据库； 即使不使用第三方第数据库操作框架，如MyBatis等，Spring和Spring Boot本身也对原生的 JDBC 做了轻量级的封装，即JdbcTemplate； 数据库操作的所有 CRUD 方法都在 JdbcTemplate 中，程序员只需自己注入即可使用； JdbcTemplate的自动配置是依赖 org.springframework.boot.autoconfigure.jdbc 包下的 JdbcTemplateConfiguration类。 JdbcTemplate主要提供以下几类方法： execute方法：可以用于执行任何SQL语句，一般用于执行DDL语句； update方法及batchUpdate方法：update方法用于执行新增、修改、删除等语句；batchUpdate方法用于执行批处理相关语句； query方法及queryForXXX方法：用于执行查询相关语句； call方法：用于执行存储过程、函数相关语句。 测试CRUD： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@RestControllerpublic class JDBCController{ /** *SpringBoot默认提供了数据源，默认提供了org.springframework.jdbc.core.JdbcTemplate *JdbcTemplate中会自己注入数据源，用于简化JDBC操作 *还能避免一些常见的错误,使用起来也不用再自己来关闭数据库连接 */ @Autowired JdbcTemplate jdbcTemplate; //查询user表中所有数据 //List中的1个Map对应数据库的1行数据 //Map中的key对应数据库的字段名，value对应数据库的字段值 @GetMapping(&quot;/list&quot;) public List&lt;Map&lt;String,Object&gt;&gt; userList(){ String sql = &quot;select * from mybatis.user&quot;; List&lt;Map&lt;String,Object&gt;&gt; mapList = jdbcTemplate.queryForList(sql); return mapList; } //新增一个用户 @GetMapping(&quot;/add&quot;) public String addUser(){ //插入语句，注意时间问题 String sql = &quot;insert into mybatis.user(id,name,pwd)&quot;+&quot;values(7,'小红','123456789')&quot;; //需要进行更新 jdbcTemplate.update(sql); //查询 return &quot;addOk&quot;; } //修改用户信息 @GetMapping(&quot;/update/{id}&quot;) public String updateUser(@PathVariable(&quot;id&quot;) int id){ //更新语句 String sql=&quot;update mybatis.user set name=?, pwd=? where id=&quot;+id; //数据 Object[] objects=newObject[2]; objects[0]=&quot;秦疆&quot;; objects[1]=&quot;7654321&quot;; jdbcTemplate.update(sql,objects); //查询 return &quot;updateOk&quot;; } //删除用户 @GetMapping(&quot;/delete/{id}&quot;) public String delUser(@PathVariable(&quot;id&quot;) int id){ //删除语句 String sql=&quot;delete from mybatis.user where id=?&quot;; jdbcTemplate.update(sql,id); //查询 return &quot;deleteOk&quot;; }} Druid数据源 Druid 是阿里巴巴开源平台上一个数据库连接池实现，结合了 C3P0、DBCP 等 DB 池的优点，同时加入了日志监控； Druid 可以很好的监控 DB 池连接和 SQL 的执行情况，天生就是针对监控而生的 DB 连接池； Druid 数据源具有监控的功能，并提供了一个 web 界面方便用户查看 使用时需要在配置文件中设置 type: com.alibaba.druid.pool.DruidDataSource，同时进行参数设置 使用方法： 现在需要程序员自己为 DruidDataSource 绑定全局配置文件中的参数，再添加到容器中，而不再使用SpringBoot的自动生成了（因为不是自带的包）；我们需要自己添加 DruidDataSource 组件到容器中，并绑定属性。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@Configurationpublic class DruidConfig{ /* 将自定义的Druid数据源添加到容器中，不再让SpringBoot自动创建 绑定全局配置文件中的druid数据源属性到com.alibaba.druid.pool.DruidDataSource从而让它们生效 @ConfigurationProperties(prefix=&quot;spring.datasource&quot;)：作用就是将全局配置文件中 前缀为spring.datasource的属性值注入到com.alibaba.druid.pool.DruidDataSource的同名参数中 */ //创建druid数据源 @ConfigurationProperties(prefix=&quot;spring.datasource&quot;) @Bean public DataSource druidDataSource(){ return new DruidDataSource(); } //配置Druid监控管理后台的Servlet； //内置Servlet容器时没有web.xml文件，所以使用SpringBoot的注册Servlet方式 @Bean public ServletRegistrationBean statViewServlet(){ ServletRegistrationBean bean=new ServletRegistrationBean&lt;&gt;(new StatusManagerServlet(),&quot;/druid/*&quot;); //这些参数可以在StatViewServlet的父类ResourceServlet中找到 //loginUsername和loginPassword是不能改的 Map&lt;String,String&gt; InitParams=newHashMap&lt;&gt;(); initParams.put(&quot;loginUsername&quot;,&quot;admin&quot;);//后台管理界面的登录账号 initParams.put(&quot;loginPassword&quot;,&quot;123456&quot;);//后台管理界面的登录密码 //后台允许谁可以访问 //initParams.put(&quot;allow&quot;,&quot;localhost&quot;)：表示只有本机可以访问 initParams.put(&quot;allow&quot;,&quot;&quot;); //允许所有访问 //设置初始化参数 bean.setInitParameters(initParams); return bean; } //设置过滤器 //WebStatFilter：用于配置Web和Druid数据源之间的管理关联监控统计 @Bean public FilterRegistrationBean webStatFilter(){ FilterRegistrationBean bean=new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); //exclusions：设置哪些请求进行过滤排除掉，从而不进行统计 Map&lt;String,String&gt;initParams=new HashMap&lt;&gt;(); initParams.put(&quot;exclusions&quot;,&quot;*.js,*.css,/druid/*,/jdbc/*&quot;); bean.setInitParameters(initParams); // &quot;/*&quot;表示过滤所有请求 bean.setUrlPatterns(Arrays.asList(&quot;/*&quot;)); return bean; }} 整合Mybatis需要在配置文件中添加mybatis的配置： 12345#整合mybatismybatis: type-aliases-package: com.tian.pojo mapper-locations: classpath:mybatis/mapper/*.xml 主要步骤：与之前类似 1.连接数据库，编写配置文件 2.写mapper接口和xml，需要添加@Mapper注解 12345678//@Mapper:表示本类是一个MyBatis的Mapper@Mapper@Repositorypublic interface UserMapper{ //查找所有用户 List&lt;User&gt;queryUserList();} 3.写Controller 123456789101112@RestControllerpublic class UserController{ @Autowired UserMapper userMapper; @RequestMapping(&quot;/queryAll&quot;) public List&lt;User&gt; queryUserList(){ List&lt;User&gt; users=userMapper.queryUserList(); return users; }} 注意： 连接数据库时，记得配置时区，因为springboot默认使用mysql8的包； springboot会帮我们自动提交以及处理事务； 配置接口时需要添加@Mapper，表示本类是一个MyBatis的Mapper； 每个需要扫描的类都应添加注解@Component（不同包下形式可以不同），声明为Spring组件","link":"/2023/02/17/SpringBoot%E4%B8%89/"},{"title":"SpringBoot（二）","text":"本系列主要进行SpringBoot框架的学习介绍，SpringBoot是一种基于Spring的框架，能够开箱即用，提供各种默认配置来简化项目配置，来对Spring进行简化。其中本篇文章会对自动装配机制进行进一步解释，同时将SpringBoot应用到web开发中。 自动装配机制再理解进入spring.factories，可以看到很多配置类（以AutoConfiguation结尾），以 HttpEncodingAutoConfiguration（Http编码自动配置）为例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//表示这是一个配置类，和以前编写的配置文件一样，也可以给容器中添加组件；@Configuration//启动指定类的ConfigurationProperties功能；//进入这个HttpProperties查看，将配置文件中对应的值和HttpProperties绑定起来；//并把HttpProperties加入到ioc容器中@EnableConfigurationProperties({HttpProperties.class})//Spring底层@Conditional注解 //根据不同的条件判断，如果满足指定的条件，整个配置类里面的配置就会生效； //这里的意思就是判断当前应用是否是web应用，如果是，当前配置类生效@ConditionalOnWebApplication(type = Type.SERVLET)//判断当前项目有没有这个类CharacterEncodingFilter；SpringMVC中进行乱码解决的过滤@ConditionalOnClass({CharacterEncodingFilter.class}) //判断配置文件中是否存在某个配置：spring.http.encoding.enabled；//如果不存在，判断也是成立的 //即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的；@ConditionalOnProperty( prefix = &quot;spring.http.encoding&quot;, value = {&quot;enabled&quot;}, matchIfMissing = true)public class HttpEncodingAutoConfiguration { //他已经和SpringBoot的配置文件映射了 private final Encoding properties; //只有一个有参构造器的情况下，参数的值就会从容器中拿 public HttpEncodingAutoConfiguration(HttpProperties properties) { this.properties = properties.getEncoding(); } //给容器中添加一个组件，这个组件的某些值需要从properties中获取 @Bean @ConditionalOnMissingBean //判断容器没有这个组件？ public CharacterEncodingFilter characterEncodingFilter() { CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(org.springframework.boot.autoconfigure. http.HttpProperties.Encoding.Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce (org.springframework.boot.autoconfigure. http.HttpProperties.Encoding.Type.RESPONSE)); return filter; } //…..} 一句话总结 ：根据当前不同的条件判断，决定这个配置类是否生效。 一但这个配置类AutoConfiguation生效，这个配置类就会给容器中添加各种组件； 这些组件的属性是从对应的Properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的； 所有在配置文件中能配置的属性都是在xxxxProperties类中封装着； 配置文件能配置什么就可以参照某个功能对应的这个属性类。（配置文件就是application.yaml/properties） 如HttpEncodingAutoConfiguration对应的Properties类HttpProperties ： 12345//从配置文件中获取指定的值和bean的属性进行绑定//即：配置文件可以通过修改spring.http.xxx的值更改HttpProperties 类中的属性@ConfigurationProperties(prefix=&quot;spring.http&quot;)public class HttpProperties { // .....} 精髓： SpringBoot启动会加载大量的自动配置类； 我们看我们需要的功能有没有在SpringBoot默认写好的自动配置类当中；（如果没有，就要自己写） 我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件存在在其中，我们就不需要再手动配置了） 给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们只需在配置文件中指定这些属性的值即可。 xxxxAutoConfigurartion：自动配置类；给容器中添加组件 xxxxProperties:封装配置文件中相关属性； 了解：@Conditional 自动配置类必须在一定的条件下才能生效，必须是@Conditional指定的条件成立，才给容器中添加组件，配置类里面的所有内容才生效。 那么多的自动配置类，必须在一定的条件下才能生效；也就是说，我们加载了这么多的配置类（一般导入了对应依赖就能加载），但不是所有的都生效了。我们怎么知道哪些自动配置类生效？ 我们可以通过启用debug=true属性，让控制台打印自动配置报告，可以很方便的知道哪些自动配置类生效； 123#开启springboot的调试类debug=true 其中：Positive matches:（自动配置类启用的：正匹配） Negative matches:（没有启动，没有匹配成功的自动配置类：负匹配） Unconditional classes: （没有条件的类） SpringBoot Web开发静态资源导入探究在springboot中，我们可以使用以下方式处理静态资源： webjars。对应访问网站为localhost:8080/webjars/1.7.1/1.js 将静态资源放入classpath下的public（在resources下新建一个public文件夹），static（默认就有），/**（即直接放在在resources中），resources（在resources下再建一个resources）文件夹中。对应访问网站为localhost:8080/1.js 优先级: resources&gt;static(默认)&gt;public Thymeleaf模板引擎SpringBoot不支持jsp文件显示前端界面，如果要直接使用纯页面方式，会给开发带来巨大的麻烦，因此需要使用模板引擎。 模板引擎的作用：将后台封装的一些数据（如动态表达式）进行解析，并填充到提供的页面模板中指定的位置，然后最终生成一个新的页面并进行显示。 Thymeleaf的自动配置类：12345678910111213@ConfigurationProperties(prefix = &quot;spring.thymeleaf&quot;)public class ThymeleafProperties { private static final Charset DEFAULT_ENCODING; public static final String DEFAULT_PREFIX = &quot;classpath:/templates/&quot;; public static final String DEFAULT_SUFFIX = &quot;.html&quot;; private boolean checkTemplate = true; private boolean checkTemplateLocation = true; private String prefix = &quot;classpath:/templates/&quot;; private String suffix = &quot;.html&quot;; private String mode = &quot;HTML&quot;; private Charset encoding;} 我们可以在其中看到默认的前缀和后缀，因此我们只需要把我们的html页面放在类路径下的templates下，thymeleaf就可以帮我们自动渲染了。 例子： 123456789@Controllerpublic class TestController { @RequestMapping(&quot;/t1&quot;) public String test1(){ //classpath:/templates/test.html return &quot;test&quot;; } } 即：访问localhost:8080/t1，会进入到test.html页面中。 html页面设置（Thymeleaf语法）：*{…}：选择表达式：和${}在功能上是一样； #{…}：获取国际化内容 @{…}：定义URL； ~{…}：片段引用表达式 同时需要将html中的关键字修改为 th：的形式，如： 12345678910111213141516171819&lt;body&gt; &lt;h1&gt;测试页面&lt;/h1&gt; &lt;div th:text=&quot;${msg}&quot;&gt;&lt;/div&gt; &lt;!--不转义--&gt; &lt;div th:utext=&quot;${msg}&quot;&gt;&lt;/div&gt; &lt;!--遍历数据--&gt; &lt;!--th:each每次遍历都会生成当前这个标签--&gt; &lt;h4 th:each=&quot;user :${users}&quot; th:text=&quot;${user}&quot;&gt;&lt;/h4&gt; &lt;!--行内写法--&gt; &lt;h4&gt; &lt;span th:each=&quot;user:${users}&quot;&gt;[[${user}]]&lt;/span&gt; &lt;/h4&gt; &lt;/body&gt; 页面国际化见此网站： https://mp.weixin.qq.com/s/e4Jd3xIMF4C4HBzPQfakvg","link":"/2023/02/17/SpringBoot%E4%BA%8C/"},{"title":"SpringBoot（五）","text":"本系列主要进行SpringBoot框架的学习介绍，SpringBoot是一种基于Spring的框架，能够开箱即用，提供各种默认配置来简化项目配置，来对Spring进行简化。其中本篇文章会介绍开发中常见的三个任务（异步任务，定时任务，邮件任务），同时会介绍分布式开发的一些理论知识。 异步、定时、邮件任务异步任务当我们在网站上发送邮件时，后台会去发送邮件，此时前台会造成响应不动，直到邮件发送完毕，响应才会成功，所以我们一般会采用多线程的方式去处理这些任务。 例子：假装正在处理数据，使用线程设置一些延时，模拟同步等待的情况。 1.创建一个类AsyncService 123456789101112@Servicepublic class AsyncService { public void hello(){ try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;业务进行中....&quot;); }} 2.编写AsyncController类 1234567891011@RestControllerpublic class AsyncController { @Autowired AsyncService asyncService; @GetMapping(&quot;/hello&quot;) public String hello(){ asyncService.hello(); return &quot;success&quot;; }} 访问http://localhost:8080/hello进行测试，3秒后出现success，这是同步等待的情况。 问题：我们如果想让用户直接得到消息，就在后台使用多线程的方式进行处理即可，但是每次都需要自己手动去编写多线程的实现的话，太麻烦了，我们只需要用一个简单的办法，在我们的方法上加一个简单的注解即可，如下： 3.直接给hello方法添加注解 123456//告诉Spring这是一个异步方法@Asyncpublic void hello(){ …} SpringBoot就会自己开一个线程池，进行调用！但是要让这个注解生效，我们还需要在主程序上添加一个注解@EnableAsync ，开启异步注解功能: 12345678@EnableAsync //开启异步注解功能@SpringBootApplicationpublic class SpringbootTaskApplication { public static void main(String[] args) { SpringApplication.run(SpringbootTaskApplication.class, args); }} 定时任务项目开发中经常需要执行一些定时任务，比如需要在每天凌晨的时候，分析一次前一天的日志信息，Spring为我们提供了异步执行任务调度的方式，提供了两个接口和两个注解。 TaskExecutor接口 TaskScheduler接口 @EnableScheduling @Scheduled 例子：在固定时间从控制台打印一个提示信息 1.创建一个ScheduledService 1234567891011@Servicepublic class ScheduledService{ //秒 分 时 日 月 周几 //0 * * * * MON-FRI //注意cron表达式的用法 @Scheduled(cron=&quot;0 * * * * 0-7&quot;) //在任意时刻的第0秒执行hello() public void hello(){ System.out.println(&quot;hello.....&quot;); }} 2.这里写完定时任务之后，同样的，需要在主程序上增加@EnableScheduling，以开启定时任务功能。 邮件任务在我们的日常开发中，也经常使用邮件任务，Springboot也帮我们做了支持。 要点： 邮件发送需要引入spring-boot-start-mail SpringBoot 自动配置MailSenderAutoConfiguration 定义MailProperties内容，配置在application.yml中 自动装配JavaMailSender 测试邮件发送 例子：qq自己给自己发邮件 1.导包spring-boot-starter-mail，并添加配置文件 123456spring.mail.username=24736743@qq.comspring.mail.password=你的qq授权码spring.mail.host=smtp.qq.com# qq需要配置sslspring.mail.properties.mail.smtp.ssl.enable=true 2.进行单元测试 123456789101112131415161718192021222324252627282930@AutowiredJavaMailSenderImpl mailSender;@Testpublic void contextLoads() { //邮件设置1：一个简单的邮件 SimpleMailMessage message = new SimpleMailMessage(); message.setSubject(&quot;通知-明天来狂神这听课&quot;); message.setText(&quot;今晚7:30开会&quot;); message.setTo(&quot;24736743@qq.com&quot;); message.setFrom(&quot;24736743@qq.com&quot;); mailSender.send(message);}@Testpublic void contextLoads2() throws MessagingException { //邮件设置2：一个复杂的邮件 MimeMessage mimeMessage = mailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(mimeMessage, true); helper.setSubject(&quot;通知-明天来狂神这听课&quot;); helper.setText(&quot;&lt;b style='color:red'&gt;今天 7:30来开会&lt;/b&gt;&quot;,true); //发送附件 helper.addAttachment(&quot;1.jpg&quot;,new File(&quot;&quot;)); helper.addAttachment(&quot;2.jpg&quot;,new File(&quot;&quot;)); helper.setTo(&quot;24736743@qq.com&quot;); helper.setFrom(&quot;24736743@qq.com&quot;); mailSender.send(mimeMessage);} 分布式理论分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是利用更多的机器，处理更多的数据。 RPC（Remote Procedure Call）：指远程过程调用，是一种进程间通信方式，他是一种技术的思想，而不是规范。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的调用代码基本相同。 也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。为什么要用RPC呢？就是无法在一个进程内，甚至一个计算机内通过本地调用的方式完成的需求，比如不同的系统间的通讯，甚至不同的组织间的通讯，由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用。RPC就是要像调用本地的函数一样去调远程函数； Dubbo：一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。 核心框架： 服务提供者（Provider）：暴露服务的服务提供方，服务提供者在启动时，向注册中心注册自己提供的服务； 服务消费者（Consumer）：调用远程服务的服务消费方，服务消费者在启动时，向注册中心订阅自己所需的服务，服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用； 注册中心（Registry）：注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者； 监控中心（Monitor）：服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 调用关系说明： 服务容器负责启动，加载，运行服务提供者； 服务提供者在启动时，向注册中心注册自己提供的服务； 服务消费者在启动时，向注册中心订阅自己所需的服务； 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者； 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用； 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 zookeeper： 是一个分布式应用程序协调服务软件，通过开启zookeeper服务，能够实现远程的连接和调用。 它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 ZooKeeper包含一个简单的原语集，提供java和C的接口。 通过SpringBoot + Dubbo + zookeeper，就能够实现分布式系统的开发了。 具体代码见原文链接 https://mp.weixin.qq.com/s/sKu9-vH7NEpUd8tbxLRLVQ","link":"/2023/02/17/SpringBoot%E4%BA%94/"},{"title":"SpringBoot（四）","text":"本系列主要进行SpringBoot框架的学习介绍，SpringBoot是一种基于Spring的框架，能够开箱即用，提供各种默认配置来简化项目配置，来对Spring进行简化。其中本篇文章会介绍两个与SpringBoot相关的工具，分别为安全工具SpringSecurity和日志工具Swagger。 Spring SecurityWeb安全开发：主要使用工具（市面上存在比较有名的）：Shiro，Spring Security Spring Security 是针对Spring项目的安全框架，也是Spring Boot底层安全模块默认的技术选型，他可以实现强大的Web安全控制，我们仅需引入 spring-boot-starter-security 模块，进行少量的配置，即可实现强大的安全管理。 重要类： WebSecurityConfigurerAdapter：自定义Security策略 AuthenticationManagerBuilder：自定义认证策略 @EnableWebSecurity：开启WebSecurity模式 Spring Security的两个主要目标是 “认证” 和 “授权”（访问控制）。 “认证”（Authentication） 身份验证是关于验证您的凭据，如用户名/用户ID和密码，以验证您的身份。 身份验证通常通过用户名和密码完成，有时与身份验证因素结合使用。 “授权” （Authorization） 授权发生在系统成功验证您的身份后，最终会授予您访问资源（如信息，文件，数据库，资金，位置，几乎任何内容）的完全权限。 这个概念是通用的，而不是只在Spring Security 中存在。 例子：主要功能：对于指定的登录用户，只能访问指定的页面 1.controller跳转 12345678910111213141516171819202122232425262728@Controllerpublic class RouterController { @RequestMapping({&quot;/&quot;,&quot;/index&quot;}) public String index(){ return &quot;index&quot;; } @RequestMapping(&quot;/toLogin&quot;) public String toLogin(){ return &quot;views/login&quot;; } @RequestMapping(&quot;/level1/{id}&quot;) public String level1(@PathVariable(&quot;id&quot;) int id){ return &quot;views/level1/&quot;+id; } @RequestMapping(&quot;/level2/{id}&quot;) public String level2(@PathVariable(&quot;id&quot;) int id){ return &quot;views/level2/&quot;+id; } @RequestMapping(&quot;/level3/{id}&quot;) public String level3(@PathVariable(&quot;id&quot;) int id){ return &quot;views/level3/&quot;+id; }} 2.编写SpringSecurity配置类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//使能WebSecurity@EnableWebSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter{ //定制请求的授权规则 //一、授权功能 @Override protected void configure(HttpSecurity http) throws Exception{ http.authorizeRequests().antMatchers(&quot;/&quot;).permitAll() .antMatchers(&quot;/level1/**&quot;).hasRole(&quot;vip1&quot;) .antMatchers(&quot;/level2/**&quot;).hasRole(&quot;vip2&quot;) .antMatchers(&quot;/level3/**&quot;).hasRole(&quot;vip3&quot;); //只有vip3的角色科研访问level3下的页面 //开启自动配置的登录功能：如果没有权限，就会跳转到登录页面！ // /login请求来到登录页 // /login?error重定向到这里表示登录失败 http.formLogin() .usernameParameter(&quot;username&quot;) .passwordParameter(&quot;password&quot;) .loginPage(&quot;/toLogin&quot;) .loginProcessingUrl(&quot;/login&quot;);//登陆表单提交请求 //开启自动配置的注销的功能 // /logout注销请求 // .logoutSuccessUrl(&quot;/&quot;);注销成功来到首页 http.csrf().disable();//关闭csrf功能:跨站请求伪造,默认只能通过post方式提交logout请求 http.logout().logoutSuccessUrl(&quot;/&quot;); //记住我 http.rememberMe().rememberMeParameter(&quot;remember&quot;); } //定义认证规则 //二、认证功能 @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception{ //在内存中定义，也可以在jdbc中去拿 //Springsecurity5.0中新增了多种加密方式，也改变了密码的格式。 //要想我们的项目还能够正常登陆，需要修改一下configure中的代码。我们要将前端传过来的密码进行某种方式加密 //springsecurity官方推荐的是使用bcrypt加密方式。 auth.inMemoryAuthentication().passwordEncoder(newBCryptPasswordEncoder()) .withUser(&quot;kuangshen&quot;).password(newBCryptPasswordEncoder().encode(&quot;123456&quot;)).roles(&quot;vip2&quot;,&quot;vip3&quot;) .and() //给用户名为kuangshen，密码为123456的用户，vip2和vip3的权限 .withUser(&quot;root&quot;).password(newBCryptPasswordEncoder().encode(&quot;123456&quot;)).roles(&quot;vip1&quot;,&quot;vip2&quot;,&quot;vip3&quot;) .and() .withUser(&quot;guest&quot;).password(newBCryptPasswordEncoder().encode(&quot;123456&quot;)).roles(&quot;vip1&quot;,&quot;vip2&quot;); }} SwaggerSwagger简介在目前的前后端集成开发方法中，前端或者后端无法做到“及时协商，尽早解决”，最终导致问题集中爆发。 解决方案：定义schema [ 计划的提纲 ]，并实时跟踪最新的API，降低集成风险。 Swagger： 号称世界上最流行的API框架； Restful Api文档在线自动生成器 =&gt; API 文档 与API 定义同步更新； 直接运行，在线测试API； 支持多种语言（如：Java，PHP等） 简单的说，swagger就是给代码写注释的，不过可以共享编辑，同步更新。 SpringBoot集成Swagger由于是外部导入的包，需要自己编写配置类： 123456789101112131415161718192021222324252627282930313233343536@Configuration@EnableSwagger2public class SwaggerConfig{ //配置swagger的docket的bean实例 //docket实例上关联apiInfo @Bean public Docket docket(){ return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() //RequestHandlerSelectors：配置扫描接口的方式 //basePackage：指定要扫描的包 //any：全部 //none：不扫描 .apis(RequestHandlerSelectors.basePackage(&quot;com.tian.controller&quot;)) //过滤 //.paths(PathSelectors.ant(&quot;/tian/**&quot;)) .build(); } //配置swagger信息--&gt;apiInfo private ApiInfo apiInfo(){ Contact contact = new Contact(&quot;秦将&quot;,&quot;http://blog.kuangstudy.com/&quot;,&quot;123456789@qq.com&quot;); return new ApiInfo( &quot;Swagger学习&quot;,//标题 &quot;学习演示如何配置Swagger&quot;,//描述 &quot;v1.0&quot;,//版本 &quot;http://terms.service.url/组织链接&quot;,//组织链接 contact,//联系人信息 &quot;Apach2.0许可&quot;,//许可 &quot;许可链接&quot;,//许可连接 newArrayList&lt;&gt;()//扩展 ); }} 实体类配置 1、新建一个实体类 123456789@ApiModel(&quot;用户实体&quot;)public class User { @ApiModelProperty(&quot;用户名&quot;) public String username; @ApiModelProperty(&quot;密码&quot;) public String password;} 2、只要这个实体在请求接口的返回值上（即使是泛型），都能映射到实体项中： 12345@RequestMapping(&quot;/getUser&quot;)public User getUser(){ return new User();} 3、给接口配置一些注释 1234567@ApiOperation(&quot;狂神的接口&quot;)@PostMapping(&quot;/kuang&quot;)@ResponseBodypublic String kuang(@ApiParam(&quot;这个名字会被返回&quot;)String username){ return username;} 总结： 我们可以通过Swagger给一些比较难理解的属性或接口，增加注释信息； 接口文档实时更新； 可以在线测试。 注意点：在正式发布的时候，关闭Swagger，处理安全考虑，而且节省运行内存。","link":"/2023/02/17/SpringBoot%E5%9B%9B/"},{"title":"Redis","text":"本系列主要进行Redis的学习介绍，Redis（Remote Dictionary Server)，即远程字典服务，是一个开源的支持网络、可基于内存亦可持久化的日志型、Key-Value方式储存数据、并提供多种语言的API的非关系型数据库；与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave（主从）同步。 1. Nosql概述1.1 为什么要有Nosql 数据量增加到一定程度，单机数据库就放不下了； 数据的索引（B+ Tree），一个机器内存也存放不下； 访问量变大后（读写混合），一台服务器承受不住。 网站80%的情况都是在读，每次都要去查询数据库的话就十分的麻烦。于是出现了缓存cache：通过在数据库和数据库访问层之间加上一层缓存，第一次访问时查询数据库，将结果保存到缓存，后续的查询先检查缓存，若有直接拿去使用，效率显著提升。 如今信息量井喷式增长，各种各样的数据出现（用户定位数据，图片数据等），大数据的背景下关系型数据库（RDBMS）无法满足大量数据要求。Nosql数据库就能轻松解决这些问题。 1.2 什么是NosqlNoSQL = Not Only SQL（不仅仅是SQL） Not Only Structured Query Language 关系型数据库：列+行，同一个表下数据的结构是一样的。 非关系型数据库：数据存储没有固定的格式，并且可以进行横向扩展。 NoSQL泛指非关系型数据库，NoSQL在当今大数据环境下发展的十分迅速，Redis是发展最快的。 1.3 Nosql特点 方便扩展（数据之间没有关系，很好扩展！） 大数据量高性能（Redis一秒可以写8万次，读11万次，NoSQL的缓存记录级，是一种细粒度的缓存，性能会比较高！） 数据类型是多样型的！（不需要事先设计数据库，随取随用） 没有固定的查询语言 1.4 Nosql的四大分类 KV键值对 新浪：Redis 美团：Redis + Tair 阿里、百度：Redis + Memcache 文档型数据库（bson数据格式）： MongoDB(掌握) 基于分布式文件存储的数据库。C++编写，用于处理大量文档。 MongoDB是RDBMS和NoSQL的中间产品。MongoDB是非关系型数据库中功能最丰富的，NoSQL中最像关系型数据库的数据库。 ConthDB 列存储数据库 HBase(大数据必学) 分布式文件系统 图关系数据库 用于广告推荐，社交网络 Neo4j、InfoGrid 分类 KV键值对 文档型数据库（bson数据格式） 列存储数据库 应用场景 内容缓存，主要用于处理大量数据的高访问负载，也用于一些日志系统等等。 Web应用（与Key-Value类似，Value是结构化的，不同的是数据库能够了解Value的内容） 分布式的文件系统 数据模型 Key 指向 Value 的键值对，通常用hash table来实现 Key-Value对应的键值对，Value为结构化数据 以列簇式存储，将同一列数据存在一起 优点 查找速度快 数据结构要求不严格，表结构可变，不需要像关系型数据库一样需要预先定义表结构 查找速度快，可扩展性强，更容易进行分布式扩展 缺点 数据无结构化，通常只被当作字符串或者二进制数据 查询性能不高，而且缺乏统一的查询语法。 功能相对局限 2. Redis入门2.1 什么是Redis Redis（Remote Dictionary Server)，即远程字典服务。 是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave（主从）同步。 2.2 Redis能该干什么 内存存储、持久化，内存是断电即失的，所以需要持久化（RDB、AOF） 高效率、用于高速缓冲 发布订阅系统 地图信息分析 计时器、计数器(eg：浏览量) 2.3 Redis特性 多样的数据类型 持久化 集群 事务 Redis是单线程的，Redis是基于内存操作的。 所以Redis的性能瓶颈不是CPU,而是机器内存和网络带宽。 Redis为什么单线程还这么快？ Redis是将所有的数据放在内存中的，所以说使用单线程去操作效率就是最高的，多线程（CPU上下文会切换：耗时的操作！），对于内存系统来说，如果没有上下文切换效率就是最高的，多次读写都是在一个CPU上的，在内存存储数据情况下，单线程就是最佳的方案。 3. Redis支持的五大类型Redis是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持字符串、哈希表、列表、集合、有序集合，位图，hyperloglogs等数据类型。内置复制、Lua脚本、LRU收回、事务以及不同级别磁盘持久化功能，同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。 3.1 Redis-key 在redis中无论什么数据类型，在数据库中都是以key-value形式保存，通过对Redis-key的操作，来完成对数据库中数据的操作。 exists key：判断键是否存在 del key：删除键值对 move key db：将键值对移动到指定数据库 RENAME key newkey: 修改 key 的名称 ↓↓↓↓以下内容的类型都是指redis中, 值的类型 ↓↓↓↓ 3.2 String 在redis中, 通常键和值都是字符串, 当值为字符串时, 能够进行字符串的一系列操作 set key value: 设置键值对, 键存在就更新, 不存在就插入 get key: 得到键对应的值 APPEND key value: 在key对应的值后追加字符串value DECR/INCR key: 将指定key的value数值进行+1/-1(仅对于数字) 3.3 List(列表) Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边） LPUSH/RPUSH key value1[value2..]: 从左边/右边向列表中PUSH值(一个或者多个)。 LRANGE key start end: 获取list 起止元素（索引从左往右 递增） list实际上是一个链表，before Node after , left, right 都可以插入值 如果key不存在，则创建新的链表 如果key存在，新增内容 如果移除了所有值，空链表，也代表不存在 在两边插入或者改动值，效率最高！修改中间元素，效率相对较低 3.4 Set(集合) Redis的Set是string类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。 Redis 中 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 SADD key member1[member2..]: 向集合中无序增加一个/多个成员 SISMEMBER key member: 返回集合中所有的成员 SRANDMEMBER key [count]: 查询member元素是否是集合的成员,结果是无序的 3.5 Hash（哈希） Redis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。 Set就是一种简化的Hash, 只变动Hash的key, 而value使用默认值填充。可以将一个Hash表作为一个对象进行存储，表中存放对象的信息。 HSET key field value: 将哈希表 key 中的字段 field 的值设为 value 。重复设置同一个field会覆盖, 返回0 3.6 Zset（有序集合） 不同的是每个元素都会关联一个double类型的分数（score）。redis正是通过分数来为集合中的成员进行从小到大的排序。 score相同：按字典顺序排序 有序集合的成员是唯一的,但分数(score)却可以重复。 ZADD key score member1 [score2 member2]: 向有序集合添加一个或多个成员，或者更新已存在成员的分数 3.7 三大特殊类型Geospatial(地理位置) 使用经纬度定位地理坐标并用一个有序集合zset保存，所以zset命令也可以使用 Hyperloglog(基数统计) Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。 花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。 因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 其底层使用string数据类型 什么是基数？ 数据集中不重复的元素的个数。 应用场景： 网页的访问量（UV）：一个用户多次访问，也只能算作一个人。 传统实现，存储用户的id,然后每次进行比较。当用户变多之后这种方式及其浪费空间，而我们的目的只是计数，Hyperloglog就能帮助我们利用最小的空间完成。 BitMaps(位图) 使用位存储，信息状态只有 0 和 1 Bitmap是一串连续的2进制数字（0或1），每一位所在的位置为偏移(offset)，在bitmap上可执行AND,OR,XOR,NOT以及其它位操作。 应用场景 签到统计、状态统计 5. 事务5.1 Redis事务介绍Redis的单条命令是保证原子性的，但是redis事务不能保证原子性 Redis事务本质：一组命令的集合。 —————– 队列 set set set 执行 ——————- 事务中每条命令都会被序列化，执行过程中按顺序执行，不允许其他命令进行干扰。 一次性 顺序性 排他性 Redis事务没有隔离级别的概念 Redis单条命令是保证原子性的，但是事务不保证原子性！ 5.2 Redis事务操作过程 开启事务（multi） 命令入队 执行事务（exec） 所以事务中的命令在加入时都没有被执行，直到提交时才会开始执行(Exec)一次性完成。 5.3 事务错误 代码语法错误（编译时异常）时, 所有的命令都不执行 而代码逻辑错误 (运行时异常) 时, **其他命令可以正常执行 ** &gt;&gt;&gt; 所以不保证事务原子性 5.4 监控悲观锁： 很悲观，认为什么时候都会出现问题，无论做什么都会加锁 乐观锁： 很乐观，认为什么时候都不会出现问题，所以不会上锁！更新数据的时候去判断一下，在此期间是否有人修改过这个数据 获取version 更新的时候比较version 使用乐观锁时, 若想要加锁, 则: 使用watch key监控指定数据，相当于乐观锁加锁。 注意：每次提交执行exec后都会自动释放锁，不管是否成功 6. SpringBoot整合6.1 Jedis使用Java来操作Redis，Jedis是Redis官方推荐使用的Java连接redis的客户端。 6.2 SpringBoot整合Redis 导入依赖 org.springframework.boot spring-boot-starter-data-redis 能够在spring.factories中找到自动装配类RedisConfiguation, 和存放自动装配属性的类RedisProperty RedisConfiguation, 有两个重要的Bean: RedisTemplate StringRedisTemplate 当看到xxTemplate时可以对比RestTemplat、SqlSessionTemplate, 通过使用这些Template来间接操作组件。那么这俩也不会例外。分别用于操作Redis和Redis中的String数据类型; RedisProperty中有一些可以配置的属性: 如database, url, host, password, port, ssl…. 编写配置文件: 123# 配置redisspring.redis.host=39.99.xxx.xxspring.redis.port=6379 使用RedisTemplate: 12345678910111213141516171819202122232425@SpringBootTestclass Redis02SpringbootApplicationTests { @Autowired private RedisTemplate redisTemplate; @Test void contextLoads() { // redisTemplate 操作不同的数据类型，api和我们的指令是一样的 // opsForValue 操作字符串 类似String // opsForList 操作List 类似List // opsForHah // 除了基本的操作，我们常用的方法都可以直接通过redisTemplate操作，比如事务和基本的CRUD // 获取连接对象 //RedisConnection connection = redisTemplate.getConnectionFactory().getConnection(); //connection.flushDb(); //connection.flushAll(); redisTemplate.opsForValue().set(&quot;mykey&quot;,&quot;kuangshen&quot;); System.out.println(redisTemplate.opsForValue().get(&quot;mykey&quot;)); }} 实际应用中, 通常放Json字符串, 采用RedisTemplate.opsForValue().get(“json字符串”) 7. 持久化–RDBRDB：Redis Databases 7.1 什么是RDB 在指定时间间隔后，将内存中的数据集快照写入数据库 ；在恢复时候，直接读取快照文件，进行数据的恢复 ； 默认情况下， Redis 将数据库快照保存在名字为 dump.rdb的二进制文件中。文件名可以在配置文件中进行自定义。 7.2 工作原理 在进行 RDB 的时候，**redis** 的主线程是不会做 io 操作的，主线程会 fork 一个子线程来完成该操作； Redis 调用forks。同时拥有父进程和子进程。 子进程将数据集写入到一个临时 RDB 文件中。 当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。 这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益(因为是使用子进程进行写操作，而父进程依然可以接收来自客户端的请求。) 7.3 触发机制 save的规则满足的情况下，会自动触发rdb原则 执行flushall命令，也会触发我们的rdb原则 退出redis，也会自动产生rdb文件 save使用 save 命令，会立刻对当前内存中的数据进行持久化 ,但是会阻塞，也就是不接受其他操作了； 由于 save 命令是同步命令，会占用Redis的主进程。若Redis数据非常多时，save命令执行速度会非常慢，阻塞所有客户端的请求。 bgsavebgsave 是异步进行，进行持久化的时候，redis 还可以将继续响应客户端请求 ； bgsave和save对比 命令 save bgsave IO类型 同步 异步 是否会redis阻塞 是 否(阻塞发生在fock(), 通常非常快) 复杂度 O(n) O(n) 优点 不会消耗其它的内存 不阻塞客户端命令 缺点 阻塞客户端命令 需要fock子进程,消耗内存 7.4 RDB优缺点优点： 适合大规模的数据恢复 对数据的完整性要求不高 缺点： 需要一定的时间间隔进行操作，如果redis意外宕机了，这个最后一次修改的数据就没有了。 fork进程的时候，会占用一定的内容空间。 8. 持久化–AOFAppend Only File 将我们所有的命令都记录下来，history，恢复的时候就把这个文件全部再执行一遍 以日志的形式来记录每个写的操作，将Redis执行过的所有指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 8.1 什么是AOF 快照功能（RDB）并不是非常耐久（durable）： 如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、以及未保存到快照中的那些数据。 从 1.1 版本开始， Redis 增加了一种完全耐久的持久化方式：AOF 持久化。 AOF 默认是不开启的，我们需要手动配置，然后重启redis，就可以生效了！ 8.2 AOF优缺点优点 每一次修改都会同步，文件的完整性会更加好 每秒同步一次，可能会丢失一秒的数据 从不同步，效率最高 缺点 相对于数据文件来说，aof远远大于rdb，修复速度比rdb慢！ Aof运行效率也要比rdb慢，所以我们redis默认的配置就是rdb持久化 8.3 如何选择使用哪种持久化方式？ 一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。 有很多用户都只使用 AOF 持久化， 但并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。 9. Redis主从复制9.1 概念 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点（Master/Leader）,后者称为从节点（Slave/Follower）， 数据的复制是单向的！只能由主节点复制到从节点（主节点以写为主、从节点以读为主）。 默认情况下，每台Redis服务器都是主节点，一个主节点可以有0个或者多个从节点，但每个从节点只能由一个主节点。 9.2 作用 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余的方式。 故障恢复：当主节点故障时，从节点可以暂时替代主节点提供服务，是一种服务冗余的方式 负载均衡：在主从复制的基础上，配合读写分离，由主节点进行写操作，从节点进行读操作，分担服务器的负载；尤其是在多读少写的场景下，通过多个从节点分担负载，提高并发量。 高可用基石：主从复制还是哨兵和集群能够实施的基础。 9.3 为什么使用集群 单台服务器难以负载大量的请求 单台服务器故障率高，系统崩坏概率大 单台服务器内存容量有限。 9.4 使用规则 从机只能读，不能写，主机可读可写但是多用于写。 当主机断电宕机后，默认情况下从机的角色不会发生变化 ，集群中只是失去了写操作，当主机恢复以后，又会连接上从机恢复原状。 当从机断电宕机后，若不是使用配置文件配置的从机，再次启动后作为主机是无法获取之前主机的数据的，若此时重新配置称为从机，又可以获取到主机的所有数据。这里就要提到一个同步原理。 第二条中提到，默认情况下，主机故障后，不会出现新的主机，有两种方式可以产生新的主机： 从机手动执行命令slaveof no one, 这样执行以后从机会独立出来成为一个主机 使用哨兵模式（自动选举） 9.5 哨兵模式相对于主从模式, 当主机宕机时, 有更好的解决办法, 能够自动确定一台主机. 哨兵的作用： 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。 哨兵模式优缺点 优点： 哨兵集群，基于主从复制模式，所有主从复制的优点，它都有 主从可以切换，故障可以转移，系统的可用性更好 哨兵模式是主从模式的升级，手动到自动，更加健壮 缺点： Redis不好在线扩容，集群容量一旦达到上限，在线扩容就十分麻烦 实现哨兵模式的配置其实是很麻烦的，里面有很多配置项 10. 缓存穿透与雪崩10.1 缓存穿透（查不到） 概念 在默认情况下，用户请求数据时，会先在缓存(Redis)中查找，若没找到即缓存未命中，再在数据库中进行查找，数量少可能问题不大，可是一旦大量的请求数据（例如秒杀场景）缓存都没有命中的话，就会全部转移到数据库上，造成数据库极大的压力，就有可能导致数据库崩溃。网络安全中也有人恶意使用这种手段进行攻击被称为洪水攻击。 解决方案 布隆过滤器 对所有可能查询的参数以Hash的形式存储，以便快速确定是否存在这个值，在控制层先进行拦截校验，校验不通过直接打回，减轻了存储系统的压力。 缓存空对象 一次请求若在缓存和数据库中都没找到，就在缓存中方一个空对象用于处理后续这个请求。 10.2 缓存击穿（量太大，缓存过期） 概念 相较于缓存穿透，缓存击穿的目的性更强，一个存在的key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。这就是缓存被击穿，只是针对其中某个key的缓存不可用而导致击穿，但是其他的key依然可以使用缓存响应。 比如热搜排行上，一个热点新闻被同时大量访问就可能导致缓存击穿。 解决方案 设置热点数据永不过期 这样就不会出现热点数据过期的情况，但是当Redis内存空间满的时候也会清理部分数据，而且此种方案会占用空间，一旦热点数据多了起来，就会占用部分空间。 加互斥锁(分布式锁) 在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。保证同时刻只有一个线程访问。这样对锁的要求就十分高。 10.3 缓存雪崩 概念 大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。 解决方案 redis高可用 这个思想的含义是，既然redis有可能挂掉，那我多增设几台redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群 限流降级 这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 数据预热 数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。","link":"/2023/02/24/Redis/"},{"title":"SpringCloud","text":"本系列主要进行SpringCloud框架的学习介绍，Spring Cloud是一个微服务框架的规范，注意，只是规范，他不是任何具体的框架。所以说SpringCloud是各个微服务架构落地技术的集合体, 俗称微服务全家桶；Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。 1. 微服务概述1.1 什么是微服务？ 微服务(Microservice Architecture) 是近几年流行的一种架构思想, 或者说是一种架构风格， 将单一的应用程序划分成一组小的服务，每个服务运行在其独立的自己的进程内，服务之间互相协调，互相配置，为用户提供最终价值; 服务之间采用轻量级的通信机制(HTTP)互相沟通，每个服务都围绕着具体的业务进行构建，并且能够被独立的部署到生产环境中; 对具体的一个服务而言，应该根据业务上下文，选择合适的语言，工具(Maven), 对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。 微服务化的核心就是将传统的一站式应用，根据业务拆分成一个一个的服务，彻底地去耦合，每一个微服务提供单个业务功能的服务，一个服务做一件事情，从技术角度看就是一种小而独立的处理过程，类似进程的概念，能够自行单独启动或销毁，拥有自己独立的数据库。 1.2 微服务与微服务架构微服务: 微服务关注的是某一个点，是具体解决某一个问题/提供落地对应服务的一个服务应用，狭义的看，可以看作是IDEA中的一个个微服务工程，或者Moudle。IDEA 工具里面使用Maven开发的一个个独立的小Moudle，它具体是使用SpringBoot开发的一个小模块，专业的事情交给专业的模块来做，一个模块就做着一件事情。强调的是一个个的个体，每个个体完成一个具体的任务或者功能。 微服务架构: 微服务架构是一种架构模式，即将各个微服务结合到一起的架构模式。具体的, 将单一应用程序划分成一组小的服务，服务之间相互协调，互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务之间采用轻量级的通信机制(如HTTP)互相协作，每个服务都围绕着具体的业务进行构建，并且能够被独立的部署到生产环境中，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具(如Maven)对其进行构建。 1.3 微服务优缺点优点: 单一职责原则； 每个服务足够内聚，足够小，代码容易理解，这样能聚焦一个指定的业务功能或业务需求； 开发简单，开发效率高，一个服务可能就是专一的只干一件事； 微服务能够被小团队单独开发，这个团队只需2-5个开发人员组成, 易于修改和维护； 微服务是松耦合的，是有功能意义的服务，无论是在开发阶段或部署阶段都是独立的； 微服务只是业务逻辑的代码，不会和HTML，CSS，或其他的界面混合; 每个微服务都有自己的存储能力，可以有自己的数据库，也可以有统一的数据库. 缺点: 开发人员要处理分布式系统的复杂性； 多服务运维难度，随着服务的增加，运维的压力也在增大； 系统部署依赖问题； 服务间通信成本问题； 数据一致性问题； 系统集成测试问题； 性能和监控问题. 1.4 微服务技术栈有那些？ 微服务技术条目 落地技术 服务开发 Spring、SpringMVC、SpringBoot等 服务配置与管理 Netfix公司的Archaius、阿里的Diamond等 服务注册与发现 Eureka、Consul、Zookeeper等 服务熔断器 Hystrix、Envoy等 服务调用 Rest、PRC、gRPC 负载均衡 Ribbon、Nginx等 消息队列 Kafka、RabbitMQ、ActiveMQ等 服务路由(API网关) Zuul等 服务部署 Docker、OpenStack、Kubernetes等 服务配置中心管理 SpringCloudConfig、Chef等 1.5 为什么选择SpringCloud作为微服务架构 完整的微服务框架 支持Rest 支持多语言(Rest形式) 负载均衡(服务端zuul+客户端Ribbon) 配置服务(Netfix Archaius，Spring Cloud Config Server 集中配置) 服务调用链监控(zuul提供边缘服务，API网关) 高可用/容错(服务端Hystrix+客户端Ribbon) 2. SpringCloud入门2.1 什么是SpringCloud Spring Cloud是一个微服务框架的规范，注意，只是规范，他不是任何具体的框架。所以说SpringCloud是各个微服务架构落地技术的集合体, 俗称微服务全家桶。 Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。 2.2 SpringCloud五大组件 服务注册与发现——Netflix Eureka 负载均衡： 客户端负载均衡——Netflix Ribbon 服务端负载均衡：——Feign(其也是依赖于Ribbon，只是将调用方式RestTemplete 更改成Service 接口) 断路器——Netflix Hystrix 服务网关——Netflix Zuul 分布式配置——SpringCloud Config 2.3 SpringCloud和SpringBoot的关系 SpringBoot专注于开发, 方便的开发单个个体微服务；SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务，整合并管理起来，为各个微服务之间提供各种集成服务； SpringBoot可以离开SpringCloud独立使用，开发项目，但SpringCloud离不开SpringBoot，属于依赖关系； 2.4 Spring Cloud和Dubbo的关系 Dubbo是基于RPC调用的，而Spring Cloud是基于HTTP的REST方式，所以效率上是Dubbo更快; 但REST避免了原生RPC的问题, 同时相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖; Dubbo的组件不是很齐全，很多功能比如服务注册与发现, 需要借助于类似Zookeeper等组件才能实现，而Spring Cloud则是提供了一站式解决方案。 2.5 SpringCloud工程搭建方式 两种方式: 创建一个父工程SpringCloud, 在其中创建 服务器Server模块 和 各个微服务Client模块; 创建一个Project为Server, 其余的Client为Moudule, 但其实Server与Client模块也是独立的, 即创建Client的Moudule没有父工程. 使用RestTemplete先需要放入Spring容器中 3. Eureka服务中心3.1 什么是Eureka作用：进行微服务的注册与发现。 Eureka是Netflix的一个子模块，也是核心模块之一。Eureka是基于REST的服务，用于定位服务，以实现云端中间件层服务发现和故障转移，服务注册与发现对于微服务来说是非常重要的，有了服务注册与发现，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了，功能类似于Dubbo的注册中心，比如Zookeeper。 3.2 Eureka的原理Eureka基本架构 Springcloud 封装了Netflix公司开发的Eureka模块来实现服务注册与发现 (对比Zookeeper)； Eureka采用了C-S的架构设计，EurekaServer作为服务注册功能的服务器，他是服务注册中心； 而系统中的其他微服务，使用Eureka的客户端连接到EurekaServer并维持心跳连接。这样系统的维护人员就可以通过EurekaServer来监控系统中各个微服务是否正常运行，Springcloud 的一些其他模块 (比如Zuul) 就可以通过EurekaServer来发现系统中的其他微服务，并执行相关的逻辑. Eureka组件说明 Eureka 包含两个组件：Eureka Server 和 Eureka Client； Eureka Server 提供服务注册，各个节点启动后，回在EurekaServer中进行注册，这样Eureka Server中的服务注册表中将会储存所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到； Eureka Client 是一个Java客户端，用于简化EurekaServer的交互，客户端同时也具备一个内置的，使用轮询负载算法的负载均衡器。在应用启动后，将会向EurekaServer发送心跳 (默认周期为30秒) 。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除掉 (默认周期为90s)。 3.3 对比Dubbo Dubbo架构： 三大角色 Eureka Server：提供服务的注册与发现 Service Provider：服务生产方，将自身服务注册到Eureka中，从而使服务消费方能狗找到 Service Consumer：服务消费方，从Eureka中获取注册服务列表，从而找到消费服务 3.4 Eureka自我保护机制 内容：某时刻某一个微服务不可用，eureka不会立即清理，依旧会对该微服务的信息进行保存！ 使用场景：默认情况下，当eureka server在一定时间内没有收到实例的心跳，便会把该实例从注册表中删除（默认是90秒），但是，如果短时间内丢失大量的实例心跳，便会触发eureka server的自我保护机制，比如在开发测试时，需要频繁地重启微服务实例，但是我们很少会把eureka server一起重启（因为在开发过程中不会修改eureka注册中心），当一分钟内收到的心跳数大量减少时，会触发该保护机制。 3.5 Eureka使用方法对于服务端，在主启动类上添加注解@EnableEurekaServer 对于客户端，在主启动类上添加注解@EnableEurekaClient 3.6 对比ZooKeeperCAP是什么? C (Consistency) 强一致性 A (Availability) 可用性 P (Partition tolerance) 分区容错性 CAP的三进二：CA、AP、CP CAP理论的核心一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，根据CAP原理，将NoSQL数据库分成了满足CA原则，满足CP原则和满足AP原则三大类： CA：单点集群，满足一致性，可用性的系统，通常可扩展性较差 CP：满足一致性，分区容错的系统，通常性能不是特别高 AP：满足可用性，分区容错的系统，通常可能对一致性要求低一些 Eureka和ZookeeperZookeeper 保证的是 CP —&gt; 满足一致性，分区容错的系统，通常性能不是特别高 当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接收服务直接down掉不可用。也就是说，服务注册功能对可用性的要求要高于一致性。但zookeeper会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30-120s，且选举期间整个zookeeper集群是不可用的，这就导致在选举期间注册服务瘫痪。 Eureka 保证的是 AP —&gt; 满足可用性，分区容错的系统，通常可能对一致性要求低一些 Eureka看明白了这一点，因此在设计时就优先保证可用性。Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册时，如果发现连接失败，则会自动切换至其他节点，只要有一台Eureka还在，就能保住注册服务的可用性，只不过查到的信息可能不是最新的，除此之外，Eureka还有之中自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障。 总结Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪 4. Ribbon：负载均衡(基于客户端)4.1 负载均衡以及Ribbon Ribbon 是 Netflix 发布的开源项目，主要功能是提供客户端的软件负载均衡算法，将 Netflix 的中间层服务连接在一起； Ribbon 的客户端组件提供一系列完整的配置项，如：连接超时、重试等。通过设置配置文件，Ribbon 会自动的帮助你基于某种规则 (如简单轮询，随机连接等等) 去连接这些机器； LB，即负载均衡 (LoadBalancer) ，在微服务或分布式集群中经常用的一种应用。负载均衡简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的HA (高用)。 大多用于多集群服务的情况下（即Eureka集群的情况，拥有多个服务提供者）。 集群服务如： 12# 从三个注册中心中随机取一个去访问eureka.client.service-url.defaultZone = http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 4.2 负载均衡实现流程图 5. Feign：负载均衡(基于服务端)5.1 Feign简介 Feign是声明式Web Service客户端，它让微服务之间的调用变得更简单，类似controller调用service。SpringCloud集成了Ribbon和Eureka，可以使用Feigin提供负载均衡的http客户端； 只需要创建一个接口，然后添加注解即可~ Feign，主要是社区版，大家都习惯面向接口编程。这个是很多开发人员的规范。调用微服务访问两种方法： 微服务名字 【ribbon】 接口和注解 【feign】 5.2 Feign能干什么 Feign旨在使编写Java Http客户端变得更容易； 前面在使用Ribbon + RestTemplate时，利用RestTemplate对Http请求的封装处理，形成了一套模板化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一个客户端类来包装这些依赖服务的调用。所以，Feign在此基础上做了进一步的封装，由他来帮助我们定义和实现依赖服务接口的定义，在Feign的实现下，我们只需要创建一个接口并使用注解的方式来配置它 (类似以前Dao接口上标注Mapper注解，现在是一个微服务接口上面标注一个Feign注解)，即可完成对服务提供方的接口绑定，简化了使用Spring Cloud Ribbon 时，自动封装服务调用客户端的开发量。 Feign默认集成了Ribbon； 利用Ribbon维护了MicroServiceCloud-Dept的服务列表信息，并且通过轮询实现了客户端的负载均衡，而与Ribbon不同的是，通过Feign只需要定义服务绑定接口且以声明式的方法，优雅而简单的实现了服务调用。 举例说明： 123456789101112131415161718192021//controller类//原来，使用Ribbon + RestTemplate@Autowiredprivate RestTemplate restTemplate; //调用RestTemplate类的对象@RequestMapping(&quot;/consumer/dept/add&quot;)public boolean add(Dept dept) { // postForObject(服务提供方地址(接口),参数实体,返回类型.class) return restTemplate.postForObject(REST_URL_PREFIX + &quot;/dept/add&quot;, dept, Boolean.class);}//------------------------------------------------//现在，使用Feign@Autowiredprivate DeptClientService deptClientService; //调用上一层，即service层@RequestMapping(&quot;/consumer/dept/add&quot;)public boolean add(Dept dept) { return deptClientService.addDept(dept); //只需要在对应要使用的方法（接口）上添加注解即可} 5.3 Feign和Ribbon如何选择？ 两种风格罢了，都可以； 根据个人习惯而定，如果喜欢REST风格使用Ribbon；如果喜欢社区版的面向接口风格使用Feign； Feign 本质上也是实现了 Ribbon，只不过后者是在调用方式上，为了满足一些开发者习惯的接口调用习惯！ 6. Hystrix：服务熔断 分布式系统面临的问题 复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免失败！ 6.1 服务雪崩 多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其他的微服务，这就是所谓的“扇出”，如果扇出的链路上某个微服务的调用响应时间过长，或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的 “雪崩效应”； 对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几十秒内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障，这些都表示需要对故障和延迟进行隔离和管理，以达到单个依赖关系的失败而不影响整个应用程序或系统运行; 我们需要，弃车保帅！ 6.2 什么是Hystrix？Hystrix是一个应用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时，异常等，Hystrix 能够保证在一个依赖出问题的情况下，不会导致整个体系服务失败，避免级联故障，以提高分布式系统的弹性。 “断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控 (类似熔断保险丝) ，向调用方返回一个服务预期的，可处理的备选响应 (FallBack) ，而不是长时间的等待或者抛出调用方法无法处理的异常，这样就可以保证了服务调用方的线程不会被长时间，不必要的占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。 6.3 Hystrix能干嘛？ 服务降级 服务熔断 服务限流 接近实时的监控 6.4 服务熔断 熔断机制是赌赢雪崩效应的一种微服务链路保护机制。 当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阀值缺省是5秒内20次调用失败，就会启动熔断机制。熔断机制的注解是：@HystrixCommand。 服务熔断解决如下问题： 当所依赖的对象不稳定时，能够起到快速失败的目的； 快速失败后，能够根据一定的算法动态试探所依赖对象是否恢复。 6.5 服务降级服务降级是指： 当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理，或换种简单的方式处理，从而释放服务器资源以保证核心业务正常运作或高效运作； 说白了，就是尽可能的把系统资源让给优先级高的服务。 6.6 服务熔断和降级的区别服务熔断—&gt;服务端：某个服务超时或异常，引起熔断，类似于保险丝(自我熔断)服务降级—&gt;客户端：从整体网站请求负载考虑，当某个服务熔断或者关闭之后，服务将不再被调用，此时在客户端，我们可以准备一个 FallBackFactory ，返回一个默认的值(缺省值)。会导致整体的服务下降，但是好歹能用，比直接挂掉强。 触发原因不太一样： 服务熔断一般是某个服务（下游服务）故障引起； 而服务降级一般是从整体负荷考虑； 管理目标的层次不太一样： 熔断其实是一个框架级的处理，每个微服务都需要（无层级之分）； 而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 实现方式不太一样： 服务降级具有代码侵入性(由控制器完成/或自动降级)； 熔断一般称为自我熔断 总结一下，出现服务雪崩时，对应的下游服务进行服务熔断慢慢停止掉，同时对该服务进行服务降级，返回i一个缺省的值，交给再下面的服务。不会导致整体性能的崩掉。 7. Zull路由网关 Zull包含了对请求的路由（用来跳转的）和过滤两个最主要功能： 其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础； 而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验，服务聚合等功能的基础； Zuul和Eureka进行整合，将Zuul自身注册为Eureka服务治理下的应用，同时从Eureka中获得其他服务的消息，也即以后的访问微服务都是通过Zuul跳转后获得。 注意：Zuul 服务最终还是会注册进 Eureka 提供：代理 + 路由 + 过滤 三大功能！ 代理功能： 没有经过Zull路由网关配置时，服务接口访问的路由，可以看出是直接用微服务(服务提供方)名称去访问，这样不安全，不能将微服务名称暴露！ 而经过了网关配置，微服务名称被替换并隐藏，换成了我们自定义的微服务名称mydept，同时加上了前缀haust，这样就做到了对路由fan访问的加密处理！ 8. SpringCloudConfig 分布式配置SpringCloudConfig为分布式系统中的外部配置提供服务器和客户端支持，是对所有微服务的一套集中式的配置管理设施。使用Config Server，您可以在所有环境中管理应用程序的外部属性。客户端和服务器上的概念映射与Spring Environment和PropertySource抽象相同，因此它们与Spring应用程序非常契合，但可以与任何以任何语言运行的应用程序一起使用。 8.1 分布式系统面临的配置文件问题微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务，由于每个服务都需要必要的配置信息才能运行，所以一套集中式的，动态的配置管理设施是必不可少的。spring cloud提供了configServer来解决这个问题，我们每一个微服务自己带着一个application.yml，那上百个的配置文件修改起来，令人头疼！ 8.2 SpringCloudConfig结构 SpringCloudConfig 为微服务架构中的微服务提供集中化的外部支持，配置服务器为各个不同微服务应用的所有环节提供了一个中心化的外部配置； SpringCloudConfig 分为服务端和客户端两部分： 服务端也称为 分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密，解密信息等访问接口； 客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息。配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理。并且可用通过git客户端工具来方便的管理和访问配置内容。 8.3 SpringCloudConfig作用 集中式管理配置文件； 不同环境，不同配置，动态化的配置更新，分环境部署，比如 /dev /test /prod /beta /release； 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息； 当配置发生变动时，服务不需要重启，即可感知到配置的变化，并应用新的配置； 将配置信息以REST接口的形式暴露","link":"/2023/02/24/SpringCloud/"},{"title":"java方法","text":"本篇文章讲解了java中各个数据结构的常用方法与实现，包括：列表list，字符串，链表，队列，栈，树，堆等，同时还包括部分算法的实现。 数组一维数组定义： int[] arr = new int[5]; //此时初始值为0，初始化方式如: arr[0]=1 int[] arr = new int[]{3,5,1,7}; //创建并初始化 int[] arr = {3,5,1,7}; //创建并初始化 二维数组定义： int[][] arr = new int[5][5]; //此时初始值为0，初始化方式如: arr[0][0]=1 二维数组的行：arr.length 二维数组的列：arr[0].length 注意：数组非空，才能计算列，不然会越界，即没有arr[0] 判断数组是否为空：if(arr.length!=0) Arrays类常用方法： Arrays.fill(arr, 1); //将数组的所有元素变为1 注：Boolean类型的数组，需要为Arrays.fill(arr, Boolean.FALSE); Arrays.sort(arr); //数组从小到大排序 Arrays.copyOfRange(arr, left, right); //数组的切片操作，[left, right) 字符串字符串定义： String str = new String(); StringBuilder str = new StringBuilder(); 字符串无法直接进行遍历，需要转化为char型数组: char[] strList = str.toCharArray(); 也可以将char型数组转化为字符串： String newStr = new String(strList, startIndex, endIndex); char字符转字符串：String.valueOf(charData); int转字符串：String.valueOf(intData); //均返回String Integer.toString(intData); intData+””; 字符串转int：Integer.valueOf(str); //必须是纯数字组成的字符串 常用方法： 计算字符串长度：str.length(); 替换字符：str.replace(oldStr, newStr); //替换第一个 ​ str.replaceAll(oldStr, newStr); //替换所有 返回某索引处的字符：str.charAt(index); //返回char 切割字符串：String.substring(startIndex, endIndex); //返回String 添加元素：StringBuilder：str.append(newStr); ​ String：str.concat(newStr); //返回String ArrayList定义：ArrayList&lt;Object&gt; array = new ArrayList&lt;Object&gt;(); 基本方法： 添加元素：array.add(num); 取出下标为index的元素：value = array.get(index); 替换下标为index的元素为value：array.set(index, value); 长度：array.size(); 注意：对List进行插入或取出等长度修改后，size会随时发生变化，因此在循环之前，如果想要开始时的长度，需要先将其取出。 ArrayList转化为数组Array：array.toArray(new int[array.size()]); 二维ArrayList的定义： List&lt;List&lt;Object&gt;&gt; array = new List&lt;ArrayList&lt;Object&gt;&gt;(); ArrayList&lt;ArrayList&lt;Object&gt;&gt; array = new ArrayList&lt;ArrayList&lt;Object&gt;&gt;(); 第二维为数组： List&lt;int[]&gt; array = new ArrayList&lt;int[]&gt;(); 二维ArrayList转数组： array.toArray(new int[array.size()][array.get(0).size()]); 如果第二维可变，则array.toArray(new int[array.size()][]); 判断java的Collection和Map是否为空：if(array.isEmpty()) LinkedList定义：LinkedList&lt;Object&gt; deque = new LinkedList&lt;Object&gt;(); ​ 或 Deque&lt;Integer&gt; deque = new LinkedList&lt;Integer&gt;(); 双端队列，能够从头部或者从尾部添加节点。 基本方法： 添加节点（正常的为从尾部插入）：deque.add(num); //等同于addLast 从头部添加节点：deque.addFirst(num); //可以理解为从头部插入 使用LinkedList独有的方法的话（如addLast，addFirst），就必须声明为LinkedList&lt;Object&gt; linkedList或者Queue，而不能是List&lt;Object&gt; linkedList。 此外还有： deque.offerLast(num); //从尾部插入元素 deque.offerFirst(num); //从头部插入元素 deque.pollLast(); //从尾部弹出元素 deque.pollFirst(num); //从头部弹出元素 deque.peekLast(); //从尾部取出元素 deque.peekFirst(num); //从头部取出元素 链表单链表节点定义方法： 12345public class ListNode { int val; ListNode next; ListNode(int x) { val = x; }} 栈栈和队列都是操作受限的线性表。 定义：Stack&lt;Object&gt; stack = new Stack&lt;Object&gt;(); 基本方法： 入栈：stack.push(num); 出栈：stack.pop(); //返回栈顶元素值 查看栈顶元素：stack.peek(); 队列定义：Queue&lt;Object&gt; queue = new LinkedList&lt;Object&gt;(); 基本方法： 入队：queue.add(num);（或者queue.offer(num)） 出队：queue.poll(); 优先队列（堆）： PriorityQueue&lt;Integer&gt; queue = new PriorityQueue&lt;Integer&gt;(new Comparator&lt;Integer&gt;() { ​ public int compare(Integer num1, Integer num2) { ​ return num2 - num1; //num2-num1表示堆顶为最大值 ​ } ​ }); 取堆顶：queue.peek() HashSet定义：Set&lt;Object&gt; set = new HashSet&lt;Object&gt;(); 添加元素：set.add(num); 添加成功返回true，添加失败返回false 判断一个值是否存在于集合中：set.contains(num); 移除元素num：set.remove(num); HashMap定义： HashMap&lt;Object, Object&gt; hashmap = new HashMap&lt;Object, Object&gt;(); 常用方法： 插入元素：hashmap.put(key, value); 查询元素：hashmap.get(key); 移除元素：hashmap.remove(key); //返回key对应的value 长度计算：hashmap.size(); 某个键key是否存在：if(hashmap.containsKey(key)); 某个键对应的值加一：hashmap.put(key, hashmap.get(key)+1)****; 树二叉树的节点定义方法： 1234567public class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int x) { val = x; } } 工具栏重要运算符： /：除法：整数之间做除法时，只保留整数部分而舍弃小数部分。如：12/5=2 (double)12/5=2.4 %：取模：对负数取模，可以把模数负号忽略不记， 与被模数符号相同。如：12%5=2; (-12)%5=-2; (-12)%(-5)=-2 求最大最小值：Math.max(); Math.min(); //只能两两比较，否则需要嵌套 求平方：Math.pow(a,b); //a的b次方 语言特性： java语言会出现大数越界问题，因此有时候需要定义long类型，而不是int类型 A 哈希表存储12345678910111213public HashMap&lt;Character, Integer&gt; getFrequent(String s) { //哈希表存储字符串中每个字符出现频数 HashMap&lt;Character, Integer&gt; hashMap = new HashMap&lt;Character, Integer&gt;(); for(char str:s.toCharArray()){ if(!hashMap.containsKey(str)){ hashMap.put(str, 1); } else{ hashMap.put(str, hashMap.get(str)+1); } } return hashMap; B 二分查找1234567891011121314151617181920//查找成功，返回truepublic boolean binarySearch(int[] nums, int target){ int left = 0; int right = nums.length-1; int mid; while(left &lt;= right){ mid = (left+right)/2; if(nums[mid] == target){ return true; } else if(nums[mid] &lt; target){ left = mid + 1; } else{ right = mid - 1; } } return false;} C 回溯12345678910111213141516171819202122232425//存放结果List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;List&lt;Integer&gt;&gt;();public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int target) { traversal(root, target, new ArrayList&lt;Integer&gt;()); return ans;}public void traversal(TreeNode root, int target, ArrayList&lt;Integer&gt; path){ if(root==null){ return; } if(root.left==null &amp;&amp; root.right==null &amp;&amp; target==root.val){ path.add(root.val); ans.add(new ArrayList&lt;Integer&gt;(path)); //类似python中的path[:]，深拷贝 path.remove(path.size()-1); } //递归 path.add(root.val); traversal(root.left, target-root.val, path); traversal(root.right, target-root.val, path); //移除最后一个元素，回溯 path.remove(path.size()-1);} D 快速排序1234567891011121314151617181920212223242526272829303132333435363738public int[] quickSort(int[] arr){ return onceQuickSort(arr, 0, arr.length-1)}public int[] onceQuickSort(int[] arr, int left, int right){ if(left&gt;=right){ return arr; } int i = left, j = right; //确定一个数的位置（即哨兵对应的数） while(i&lt;j){ //从右往左找到找到第一个比哨兵小的数 //一定是先j--，再i++，来保证两个while执行完，ij都指向一个值小于哨兵的数 while(i&lt;j &amp;&amp; arr[j]&gt;=arr[left]){ j--; } //从左往右找到第一个比哨兵（默认为第一个数）大的数 while(i&lt;j &amp;&amp; arr[i]&lt;=arr[left]){ i++; } //交换 swap(arr, i, j); } swap(arr, left, i); //左右两部分继续快排 quickSort(arr, k, left, i-1); quickSort(arr, k, i+1, right); return arr;}public void swap(int[] arr, int i, int j){ int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;}","link":"/2023/02/24/java%E6%96%B9%E6%B3%95/"},{"title":"数据结构基础","text":"本篇文章进行了数据结构的学习，包括：复杂度的计算，重要的排序算法学习，哈希表查找的方法，以及链表，队列，栈，树等的基本概念的学习。 算法复杂度时间复杂度(Time Complexity)定义：算法的时间复杂度T(n)=O(f(n))当且仅当存在正常数c和自然数N，对所有的n(n≥N)满足0≤T(n)≤c×f(n). 假设一个算法是由n条指令序列所构成的集合，则： ​ 算法的执行时间 = 指令序列(i)的执行次数×指令序列(i)的执行时间 空间复杂度(Space Complexity)定义：空间复杂度是对一个算法在运行过程中临时占用存储空间大小的量度，记做S(n)=O(f(n))，其中n为问题的规模。 程序运行所需的存储空间包括：固定空间需求(Fixed Space Requirement)[与所处理问题规模无关，主要包含算法本身的程序代码、常量、变量所占的空间]和可变空间需求(Variable Space Requirement)[与所处理问题规模有关，主要包含输入数据元素所含的存储空间和程序运行时所需要的临时空间]。 例子：对于一般的递归算法，会有O(n)的空间复杂度了，因为每次递归都要存储返回信息。递归算法一般都比较简短，算法本身所占用的存储空间较少，但运行时需要一个附加堆栈，从而占用较多的临时工作单元；若写成非递归算法，一般可能比较长，算法本身占用的存储空间较多，但运行时将可能需要较少的存储单元。 常用算法的时间复杂度和空间复杂度数据结构常见操作： 注：list查找是O(n) dict键的查找是O(1)，值的查找是O(n) set查找是O(1) 数据排序算法： 重要排序算法排序：将一组‘无序’的记录序列调整为‘有序’的记录序列的一种操作。通常待排序的记录有多个数据项，把用于作为排序依据的数据项称为关键字。 快速排序：[——平均速度下最快的一种算法]​ 快速排序算法通过多次比较和交换来实现排序，其排序流程如下： ​ (1) 首先设定一个分界值，通过该分界值将数组分成左右两部分； ​ (2) 将大于或等于分界值的数据集中到数组右边，小于分界值的数据集中到数组的左边。此时，左边部分中各元素都小于分界值，而右边部分中各元素都大于或等于分界值； ​ (3) 然后，左边和右边的数据可以独立排序。对于左侧的数组数据，又可以取一个分界值，将该部分数据分成左右两部分，同样在左边放置较小值，右边放置较大值。右侧的数组数据也可以做类似处理。 ​ 代码示例： ​ 复杂度分析： ​ 空间复杂度：快速排序在系统内部需要用一个栈实现递归，每层递归调用时的指针和参数需要用栈来存放。快速排序的递归过程可以用一个二叉树来表示。若每次划分较为均匀，则其递归树的高度为O(log2n)，故所需空间为O(log2n)。最坏情况下，即递归树是一个单树树，树的高度为O(n)时，所需的栈空间也为O(n)。 ​ 时间复杂度：平均情况O(nlog2n)[最优情况也为O(nlog2n)，每次划分等长]，最坏情况O(n2)[关键字序列基本有序时，变为冒泡排序]。 ​ 快速排序的优点：快速排序是目前基于比较的内部排序中被认为是最好的一种排序算法，当待排序的关键字是随机分布时，快速排序的平均时间最短。 冒泡法复杂度分析：​ 空间复杂度：冒泡排序仅用了一个辅助单元，空间复杂度为O(1)。 ​ 时间复杂度：最坏情况下[逆序]，在第i趟排序中，比较次数为n-i，移动次数为3(n-i)，总次数分别为1/2*n平均情况O(nlog2n)[最优情况也为O(nlog2n)，每次划分等长]，最坏情况O(n2)[关键字序列基本有序时，变为冒泡排序]。 各种排序算法总结： 哈希表查找查找：在由一组记录组成的集合中寻找出关键字等于给定值的某个记录，或是寻找属性值符合给定条件的某些记录。 一些查找方法：基于线性表的查找法：顺序查找，折半查找；基于树的查找法：二叉排序树，平衡二叉树；特点：记录在表中的位置和关键字间不存在确定关系，查找的过程为给定值依次和各个关键字比较，查找的效率取决进行比较的关键字个数。这类查找法，平均查找长度(ASL)都不为零。 哈希查找：若希望ASL=0，可以预先知道所查关键字在表中的位置，即：记录在表中位置和其关键字之间的确定关系。在一般情况下，需在关键字与记录在表中的存储位置之间建立一个函数关系，以f(key)作为关键字为key的记录在表中的位置，通常称这个函数f(key)为哈希函数。通过哈希函数建立的查找表即为哈希表****。 哈希函数构造方法：[原则：1. 函数本身便于计算 2.计算出来的地址分布均匀] ①直接定址法：取关键字的某个线性函数值为散列地址。 ②数字分析法：假设关键字集合中的每个关键字都是由s位数字组成(u1, u2,…，u(s))，分析关键字集中的全体，并从中提取分布均匀的若干位或它们的组合作为地址。 ③平方取中法：以关键字的平方值的中间几位作为存储地址。 ④折叠法：将关键字分割成若干部分，然后取它们的叠加和为哈希地址。 此外，还有除留余数法，随机数法等。 哈希处理冲突方法：[在哈希表中，尽管构造性能良好的哈希函数可以减少冲突，但实际上冲突是不可避免的。”处理冲突”是为产生冲突的地址寻找下一个哈希地址。] ①开放定址法：开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。 ②再散列函数法：准备多个散列函数。 ③链地址法：将冲突的关键字存放在对应地址下的链表中。 ④公共溢出区法：将冲突的关键字存放溢出表中。 在查找时，对给定值通过散列函数计算出散列地址后，先与基本表的相应位置进行比对，如果相等则查找成功；如果不相等，则到溢出表去进行顺序查找。 链表与数组相似，链表也是一种线性数据结构。链表中的每个元素实际上是一个单独的对象，而所有对象都通过每个元素中的引用字段链接在一起。链表分为单链表和双链表。 https://leetcode.cn/leetbook/read/linked-list/x6ybqh/ 单链表： 单链表中的每个结点不仅包含值，还包含链接到下一个结点的引用字段。通过这种方式，单链表将所有结点按顺序组织起来。在大多数情况下，我们将使用头结点(第一个结点)来表示整个单链接列表。 单链表的两个字段：value next ①单链表的访问操作：与数组不同，我们无法在常量时间内访问单链表中的随机元素。 如果我们想要获得第 i 个元素，我们必须从头结点逐个遍历。 我们按索引来访问元素平均要花费 O(N) 时间，其中 N 是链表的长度。 例如，在上面的示例中，头结点是 23。访问第 3 个结点的唯一方法是使用头结点****head中的“next”字段到达第 2 个结点（结点 6）; 然后使用结点 6 的“next”字段，我们能够访问第 3 个结点。 ②单链表的插入操作：（让新来的节点有所指向） 插入链表中间：初始化新结点-&gt;将该结点链接到后一结点-&gt;将前一结点链接到该结点 插入头部：初始化新结点-&gt;将该节点链接到之前的头结点-&gt;将该结点指定为新的头结点 已知给定节点和待插入节点，插入操作的时间和空间复杂度均为O(1) ③单链表的删除操作： 找到删除结点的上一个结点和下一个结点-&gt;链接上一个结点到下一个结点 给定删除结点，删除操作的时间复杂度为O(N)，因为需要遍历找到前一个结点，空间复杂度为O(1)，因为只需要常量空间存储指针。 双链表： 双链表的工作方式与单链表相似，但比单链表多一个引用字段，称作‘prev’字段，有了这个额外的字段，就能知道当前节点的前一个结点。双链接列表同样使用头结点head来表示整个列表。 ①双链表的访问操作：与单链表完全相同。 ②双链表的插入操作：（让新来的结点两个指针都有所指向） 在已知结点pre后插入新结点cur：初始化新结点(cur)-&gt;将该结点链接到前一结点(cur.prev=pre)和后一结点(cur.next=pre.next)-&gt;用新结点重新链接前一结点(pre.next=cur)和后一结点(pre.next.next.prev=cur)。 已知给定结点和待插入结点，插入操作的时间和空间复杂度均为O(1) ③双链表的删除操作： 从双链表中删除一个现有的结点cur：与单链表不同，双链表可以使用prev字段简单的找到该结点的前一个结点，因此不再需要遍历链表。时间和空间复杂度均为O(1). 具体方法：链接上一个结点到下一个结点(cur.prev.next=cur.next, cur.next.prev=cur.prev) 删除头节点：cur.next=head; head.prev=null; 删除尾结点：cur.prev.next=null 队列在 FIFO 数据结构中，将首先处理添加到队列中的第一个元素。 如上图所示，队列是典型的 FIFO 数据结构。插入（insert）操作也称作入队（enqueue），新元素始终被添加在队列的末尾。 删除（delete）操作也被称为出队（dequeue)。 你只能移除第一个元素。尾进头出 常用方法：.peek()：得到第一个结点；.offer(x): 插入新节点; .poll(): 出队 .push(x)：将x推到队列的末尾；.empty()：队列为空，返回true 若不导入自带的队列库，则将队列看作数组list，设置一个头指针和一个尾指针，通过指针的移动来实现操作，通常包含的属性有：data, head, tail, size 栈在 LIFO 数据结构中，将首先处理添加到队列中的最新元素。 与队列不同，栈是一个 LIFO 数据结构。通常，插入操作在栈中被称作入栈 push 。与队列类似，总是在堆栈的末尾添加一个新元素。但是，删除操作，退栈 pop ，将始终删除队列中相对于它的最后一个元素。尾进尾出 树树的遍历： 1) 前序遍历: 首先访问根节点，然后遍历左子树，最后遍历右子树。F-B-A-D-C-E-G-I-H 2) 中序遍历: 首先遍历左子树，然后访问根节点，然后遍历右子树。A-B-C-D-E-F-G-H-I 3) 后序遍历: 首先遍历左子树，然后遍历右子树，最后访问根节点。A-C-E-B-D-H-I-G-F 通常来说，对于二叉搜索树，我们可以通过中序遍历得到一个递增的有序序列。 我们将在另一张卡片（数据结构介绍 – 二叉搜索树）中再次提及。 值得注意的是，当你删除树中的节点时，删除过程将按照后序遍历的顺序进行。 也就是说，当你删除一个节点时，你将首先删除它的左节点和它的右边的节点，然后再删除节点本身。 **4)**层序遍历：逐层遍历树结构。F-B-G-A-D-I-C-E-H 广度优先搜索是一种广泛运用在树或图这类数据结构中，遍历或搜索的算法。 该算法从一个根节点开始，首先访问节点本身。 然后遍历它的相邻节点，其次遍历它的二级邻节点、三级邻节点，以此类推。当我们在树中进行广度优先搜索时，我们访问的节点的顺序是按照层序遍历顺序的。","link":"/2023/02/24/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"算法","text":"本篇文章进行了一些基本算法的学习和实现，这里主要是基于python语言，java语言的见java板块，包括：哈希集合、哈希表的使用，位运算巧解，动态规划算法，贪心算法，KMP算法，双指针算法，递归、回溯算法等。 Set( )函数​ set( ) 函数用于创建一个无序不重复元素集，可进行关系测试，删除重复数据，还可以计算交集、差集、并集等。 ​ 语法：class set([iterable]) 其中：iterable – 可迭代对象； 例如：数组、字符串等 ​ 例子：x = set(‘runoob’) y = set(‘google’) &gt;&gt;&gt; x, y ：(set([‘b’, ‘r’, ‘u’, ‘o’, ‘n’]), set([‘e’, ‘o’, ‘g’, ‘l’])) # 重复的被删除 &gt;&gt;&gt; x &amp; y # 交集：set([‘o’]) &gt;&gt;&gt; x | y # 并集：set([‘b’, ‘e’, ‘g’, ‘l’, ‘o’, ‘n’, ‘r’, ‘u’]) &gt;&gt;&gt; x - y # 差集：set([‘r’, ‘b’, ‘u’, ‘n’]) 集合添加元素：.add() 应用：去除数组重复元素 优势：检查数字是否在集合中需要 O(1) 的时间（’a’ in myset），而对于其他数据结构[向量、列表、数组]，则需要 O(n)的时间。 集合举例：[leetcode217：存在重复元素。给你一个整数数组 nums 。如果任一值在数组中出现 至少两次 ，返回 true ；如果数组中每个元素互不相同，返回 false。] 解决方法： 123def containsDuplicate(self, nums): return len(nums) != len(set(nums)) 哈希表实现​ 基于python，采用字典实现哈希表。将键(keys)作为哈希表的地址，将值(values)作为哈希表的关键字内容。 补充：python字典的实现和操作： 创建字典：mydict = {‘a’: 1, ‘b’: 2} nulldict = {} 访问字典：x = mydict[‘a’] x = mydict.get(‘a’) 遍历字典：for eachkey in mydict: print(eachkey) # 打印的是键 字典的方法：mydict.keys = dict_keys[‘a’, ‘b’]；mydict.values = dict_values[1, 2]；mydict.items = dict_items([(‘a’, 1), (‘b’, 2)]) 注意：这些结果以特殊列表的形式存在，不能进行一般操作 返回字典长度：len(mydict) 删除字典键值: dict.pop(key) 添加项目：通过使用新的索引键并为其赋值，可以将项目添加到字典中。如mydict[‘c’]=3 哈希表举例：[leetcode136：只出现一次的数字。给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。] 12345678910def singleNumber(self, nums): hash = {} for i in range(len(nums)): hash[str(nums[i])] = 0 for i in range(len(nums)): hash[str(nums[i])] += 1 for keys in hash: if hash[keys] == 1: return int(keys) Collections模块​ Collections 是 python 的内置模块，提供了很多方便且高性能的关于集合的操作。是list tuple dict的扩展。采用Collections 模块可以简化代码。 1)namedtuple。namedtuple() 返回一个新的元组子类，且规定了元组的元素的个数，同时除了使用下标获取元素之外，还可以通过属性直接获取。输出为tuple。 相关方法：①._make(): 转换为新的tuple对象；②._asdict(): 返回一个dict 2)ChainMap。ChainMap() 可以将多个字典集合到一个字典中去，对外提供一个统一的视图。注意：该操作并是不将所有字典做了一次拷贝，实际上是在多个字典的上层又进行了一次封装而已。输出为dict。 相关方法：①.maps(): 输出字典组成的列表，如： user1 = {“name”:”admin”, “age”:”20”} user2 = {“name”:”root”, “weight”: 65} users = ChainMap(user1, user2) print(users.maps) # [{‘name’: ‘admin’, ‘age’: ‘20’}, {‘name’: ‘root’, ‘weight’: 65}] 3)deque。deque()是一种类似列表(list)的容器，实现了在两端快速添加(append)和弹出(pop)操作。大大加快了遍历速度。 相关方法：.append()；q.appendleft()；popleft()…字面意思理解 4)Counter。Counter 可以简单理解为一个计数器，可以统计每个元素出现的次数，同样 Counter() 是需要接受**一个可迭代的对象的(数组、字符串、字典…)**。输出为字典，键为每个对象，值为出现次数。如Counter({‘cat’: 3, ‘horse’: 2, ‘dog’: 1, ‘bird’: 1, ‘tiger’: 1}) 相关方法：①.most_common(n)，输出出现次数从高往低的前n项，如[(‘cat’, 3), (‘horse’, 2)]，通常用于求 Top k 问题。 注：Counter的运算满足’-‘运算，而字典不满足，如： Counter(‘aaaabbb’)-Counter(‘aaabbbbbb’)=Counter(‘a’:1)-&gt;满足True； Counter(‘aaabbb’)-Counter(‘aaabbbbbb’)=Counter()-&gt;满足False 5)OrderedDict。OrderedDict 是字典的子类，保证了元素的插入顺序。 相关方法：①.move_to_end(“name”, last = False) # last=True表示移动到开头，False为末尾。 6)defaultdict：defaultdict 是内置 dict 类的子类。它实现了当 key 不存在是返回默认值的功能，除此之外，与内置 dict 功能完全一样。 Collections模块应用举例：与2中例子相同。 12345def singleNumber(self, nums): freq = collections.Counter(nums) ans = [num for num, occ in freq.items() if occ == 1][0] return ans 位运算巧解​ 通过找到目标数据中与位运算有关的特殊关系，进而采用位运算进行巧妙解决。 位运算：具有交换性和结合性。优先级：**~** &gt; &lt;&lt;/&gt;&gt; &gt; &amp; &gt; ^ &gt; | &gt; **&amp;=/|=**… 1)按位与(&amp;)：1&amp;1=1，否则为0； 2)按位或(|)：0|0 = 0，否则为1； 3)按位异或(^)：1^1 = 0, 0^0 = 0, 1^0 = 1, 0^1 = 0; 4)按位取反(~): ~1 = 0， ~0 = 1; 5)左移(&lt;&lt;)：a &lt;&lt; b: 把a转为二进制后左移b位（在后面添b个0）; 6)右移(&gt;&gt;)：a &gt;&gt; b: 把a转化为二进制后右移b位（去掉末b位）； ​ 注意：对于部分语言（python），对「有符号整数类型」和「无符号整数类型」没有区分。如-5的二进制表示为1111 1011，用补码表示（即取反加一），而没有符号位。 ​ 位运算举例：[leetcode137：只出现一次的数字Ⅱ。给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现三次。找出那个只出现了一次的元素。] 12345678910def singleNumber(self, nums): m = 0 for i in range(32): # int total = sum((each_num &gt;&gt; i &amp; 1) for each_num in nums) # 求每一位的和 if i == 31: # 去掉符号位 m -= (total % 3) &lt;&lt; i else: m |= (total % 3) &lt;&lt; i return m 位运算某些巧解理论： Brian Kernighan 算法：对于任意整数 x，令 x=x &amp; (x−1)，该运算将 x的二进制表示的最后一个 1变成 0。该算法可以用来进行二进制1的统计 遍历子序列的方式示例：[a, b, c, d, e] 1)以不同开头节点进行遍历。遍历以某个节点为开头的所有子序列: 如 [a]，[a, b]，[ a, b, c] … 再从以 b 为开头的子序列开始遍历 [b] [b, c]…。 2)以不同子序列的长度进行遍历。根据子序列的长度为标杆，如先遍历出子序列长度为 1 的子序列[a], [b], …，在遍历出长度为 2 的…。 3)以不同结束节点进行遍历。以子序列的结束节点为基准，先遍历出以某个节点为结束的所有子序列，因为每个节点都可能会是子序列的结束节点，因此要遍历下整个序列，如: 以 b 为结束点的所有子序列: [a , b] [b] 以 c 为结束点的所有子序列: [a, b, c] [b, c] [ c ]。 应用： 第一种遍历方式通常用于暴力解法； 第二种遍历方式用于特殊情况，如 [leetcode5: 最长回文子串]; 第三种遍历方式因为可以产生递推关系, 通常用于动态规划。 动态规划将复杂的问题转化为多个简单的子问题进行求解。 关键一：理解题意 与时刻有关，只需要返回值等等的问题，可以看作动态规划问题。 关键二：定义子问题（定义状态） 设计状态思路：把不确定的因素确定下来，进而把子问题定义清楚，把子问题定义得简单。动态规划的思想通过解决了一个一个简单的问题，进而把简单的问题的解组成了复杂的问题的解。 dp[i]：表示第i时刻的状态，如表示以 nums[i] 结尾 的 连续 子数组的最大和。根据不同情况，还可以设置为dp[i][j]等。 关键三：设置状态转移方程 即得到dp[i]与之前时刻dp[i-1]或这一时刻值的关系，需要具体讨论每个状态之间的联系。如dp[i] = dp[i - 1] + nums[i]。 关键四：思考初始值 根据题意，设置dp[0]。 关键五：思考输出 根据题意，设置输出。注意，有时候状态的定义不是题目中的问题的定义，不能直接将最后一个状态返回。 无后效性：是动态规划中非常重要的概念。为了保证计算子问题能够按照顺序、不重复地进行，动态规划要求已经求解的子问题不受后续阶段的影响。这个条件也被叫做「无后效性」。换言之，动态规划对状态空间的遍历构成一张有向无环图，遍历就是该有向无环图的一个拓扑序。有向无环图中的节点对应问题中的「状态」，图中的边则对应状态之间的「转移」，转移的选取就是动态规划中的「决策」。 如果之前的阶段求解的子问题的结果包含了一些不确定的信息，导致了后面的阶段求解的子问题无法得到，或者很难得到，这叫「有后效性」。 解决「有后效性」的办法是固定住需要分类讨论的地方，记录下更多的结果。在代码层面上表现为：状态数组增加维度，例如：股票系列问题；把状态定义得更细致、准确，例如：[Leetcode124]：状态定义只解决路径来自左右子树的其中一个子树。 随想录总结： 动态规划五部曲：确定dp数组以及下标的含义-&gt;确定递推公式-&gt;dp数组如何初始化-&gt;确定遍历顺序-&gt;举例推导dp数组 调试三部曲：这道题目我举例推导状态转移公式了么？-&gt;我打印dp数组的日志了么？-&gt;打印出来了dp数组和我想的一样么？ 双指针遍历①指针向同侧移动，形成前后指针或快慢指针。常作用于两个排序好了的数组，分别指向最初的元素，然后依次右移，进行遍历[leetcode88: 最长回文子串; leetcode350: 最长回文子串] ② 指针向中间或两端移动，移动方向始终相对。常作用于交换和排序算法中。 优势：大大减小空间复杂度。 二分查找在升序数组 nums 中寻找目标值target，对于特定下标 i，比较nums[i] 和target 的大小： 如果 nums[i]=target，则下标 i即为要寻找的下标； 如果nums[i]&gt;target，则 target 只可能在下标 i 的左侧； 如果 nums[i]&lt;target，则target 只可能在下标 i 的右侧。 基于上述事实，可以在有序数组中使用二分查找寻找目标值。 二分查找的做法是，定义查找的范围 [left,right]，初始查找范围是整个数组。每次取查找范围中点mid，比较nums[mid] 和 target 的大小，如果相等则 mid 即为要寻找的下标，如果不相等则根据nums[mid] 和target 的大小关系将查找范围缩小一半。记住，左/右指针要在mid基础上+1/-1。 由于每次查找都会将查找范围缩小一半，因此二分查找的时间复杂度是O(logn)，其中 n是数组的长度。 二分查找的条件是查找范围不为空，即 left≤right。如果 target 在数组中，二分查找可以保证找到 target，返回target 在数组中的下标。如果 target 不在数组中，则当 left&gt;right 时结束查找，返回 -1。 贪心算法 贪心算法（又称贪婪算法）是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的是在某种意义上的局部最优解。 贪心选择是指所求问题的整体最优解可以通过一系列局部最优的选择，即贪心选择来达到。这是贪心算法可行的第一个基本要素。 当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构性质。运用贪心策略在每一次转化时都取得了最优解。问题的最优子结构性质是该问题可用贪心算法求解的关键特征。贪心算法的每一次操作都对结果产生直接影响。贪心算法对每个子问题的解决方案都做出选择，不能回退。 4)贪心算法的基本思路是从问题的某一个初始解出发一步一步地进行，根据某个优化测度，每一步都要确保能获得局部最优解。每一步只考虑一个数据，他的选取应该满足局部优化的条件。若下一个数据和部分最优解连在一起不再是可行解时，就不把该数据添加到部分解中，直到把所有数据枚举完，或者不能再添加算法停止。 5)实际上，贪心算法适用的情贪心算法(贪婪算法)况很少。一般对一个问题分析是否适用于贪心算法，可以先选择该问题下的几个实际数据进行分析，就可以做出判断。 该算法存在的问题： 1.不能保证求得的最后解是最佳的，计算过程不能代表实际过程 2.不能用来求最大值或最小值的问题 3.只能求满足某些约束条件的可行解的范围 应用：[仅列出贪心的思路] ①选择排序。贪心策略：每次从未排序的数据中选取最小值，并把最小值放在未排序数据的起始位置，直到未排序的数据为0，则结束排序。 ②平衡字符串。在一个 平衡字符串 中，‘L’ 和 ‘R’ 字符的数量是相同的。给你一个平衡字符串 s，请你将它分割成尽可能多的平衡字符串。贪心策略：不要有嵌套的平衡，只要达到平衡，就立即分割(贪心策略)。我们假设 ‘R’ == 1, ‘L’ == -1 .只要累加等于 0 就算分割一次. ③买卖股票的最佳时机。prices[i] 表示某支股票第 i 天的价格。在每一天，你可以决定是否购买和/或出售股票。你在任何时候 最多 只能持有一股股票。你也可以先购买，然后在同一天出售。返回你能获得的最大利润 。贪心策略：在连续的两日内，如果是上升趋势则前一天买入，后一天卖出，下降趋势则不进行操作。 数组reshape操作：将m*n的数组转化为r*c的数组 ① 将数组展开为一维： 对于一个行数为 m，列数为 n，行列下标都从 0 开始编号的二维数组，我们可以通过下面的方式，将其中的每个元素 (i, j)映射到整数域内，并且它们按照行优先的顺序一一对应着 [0, mn) 中的每一个整数。形象化地来说，我们把这个二维数组「排扁」成了一个一维数组。如果读者对机器学习有一定了解，可以知道这就是 flatten 操作。 这样的映射即为：(i, j) → i * n + j ② 将一维数组合并为二维： 与①同理，将整数 X 映射回其在矩阵中的下标，即：i = x / n ; j = x % n ; ③ 具体实现方法： 设nums 本身为 mm 行 nn 列，如果 mn ≠ rc，那么二者包含的元素个数不相同，因此无法进行重塑；否则，对于 x ∈ [0,mn)，第 x 个元素在 nums 中对应的下标为 (x / n,x % n)，而在新的重塑矩阵中对应的下标为 (x / c,x % c)。我们直接进行赋值即可。 ④代码：[Leetcode566: 重塑矩阵] def matrixReshape(self, mat, r, c) 123456789m, n = len(nums), len(nums[0])if m * n != r * c: return numsans = [[0] * c for _ in range(r)]for x in range(m * n): ans[x // c][x % c] = nums[x // n][x % n] return ans 递归一、运用递归解决树的问题 ①“自顶向下”： “自顶向下” 意味着在每个递归层级，我们将首先访问节点来计算一些值，并在递归调用函数时将这些值传递到子节点。 所以 “自顶向下” 的解决方案可以被认为是一种前序遍历。 具体来说，递归函数 top_down(root, params) 的原理是这样的： 当遇到树问题时，请先思考一下两个问题： 1)你能确定一些参数，从该节点自身解决出发寻找答案吗？ 2)你可以使用这些参数和节点本身的值来决定什么应该是传递给它子节点的参数吗？ 如果答案都是肯定的，那么请尝试使用 “自顶向下” 的递归来解决此问题。 例子：给定一个二叉树，请寻找它的最大深度。 “自顶向下”解决思想：我们知道根节点的深度是1。 对于每个节点，如果我们知道某节点的深度，那我们将知道它子节点的深度。 因此，在调用递归函数的时候，将节点的深度传递为一个参数，那么所有的节点都知道它们自身的深度。 而对于叶节点，我们可以通过更新深度从而获取最终答案。 这里是递归函数 maximum_depth(root, depth) 的伪代码： ②“自底向上”： 自底向上” 是另一种递归方法。 在每个递归层次上，我们首先对所有子节点递归地调用函数，然后根据返回值和根节点本身的值得到答案。 这个过程可以看作是后序遍历的一种。 通常，“自底向上” 的递归函数 bottom_up(root) 为如下所示： 例子：让我们继续讨论前面关于树的最大深度的问题，但是使用不同的思维方式：对于树的单个节点，以节点自身为根的子树的最大深度x是多少？ 如果我们知道一个根节点，以其左子节点为根的最大深度为l和以其右子节点为根的最大深度为r，我们是否可以回答前面的问题？ 当然可以，我们可以选择它们之间的最大值，再加上1来获得根节点所在的子树的最大深度。 那就是 x = max（l，r）+ 1。 这意味着对于每一个节点来说，我们都可以在解决它子节点的问题之后得到答案。 因此，我们可以使用“自底向上“的方法。下面是递归函数 maximum_depth(root) 的伪代码： 快速乘与快速幂用于防止数据超出范围，用加号，乘号替代乘号，幂运算。 一、快速乘[Leetcode29:两数相除] 1234567891011121314# 快速乘 计算x*y# 将y转化为二进制，取出每一位的值并变为加法运算def quickmod(x, y) -&gt; int:ans = 0; add = xwhile y&gt;0: # y为奇数(y最后一定会为奇数1),最后一次加上去 if y&amp;1 == 1: ans += add # 每次移位都要累加add,因为转化为2进制了 add += add # 右移一位 y &gt;&gt;= 1return ans 二、快速幂[Leetcode50:pow(x, n)] 12345678910111213# 快速幂，计算x^n# 将n转化为二进制，取出每一位的值并变为乘法运算def quickMul(x, n) -&gt; float: # 考虑n为正数 ans = 1.0; add = x while n &gt; 0: # 在奇数时刻进行操作 if n &amp; 1 == 1: ans *= add add *= add n &gt;&gt;= 1 return ans KMP算法用于字符串匹配，时间复杂度O(m+n) [Leetcode28 459:找出字符串中第一个匹配项的下标] 字符串的前缀和后缀： 如果字符串A和B，存在A=BS，其中S是任意的非空字符串，那就称B为A的前缀。例如，‘Harry’的前缀包括{”H”， ”Ha”， ”Har”, ”Harr”}，我们把所有前缀组成的集合，称为字符串的前缀集合。同样可以定义后缀A=SB，其中S是任意的非空字符串，那就称B为A的后缀，例如，”Potter”的后缀包括{”otter”,”tter”, ”ter”, ”er”, ”r”}，然后把所有后缀组成的集合，称为字符串的后缀集合。要注意的是，字符串本身并不是自己的后缀。 部分匹配表(Partial Match Table)： PMT中的值是字符串的前缀集合与后缀集合的交集中最长元素的长度。对于字符串”ababa”，它的前缀集合为{”a”, ”ab”, ”aba”, ”abab”}，它的后缀集合为{”baba”, ”aba”, ”ba”, ”a”}， 两个集合的交集为{”a”, ”aba”}，其中最长的元素为”aba”，长度为3。 匹配思路： 例如，要在主字符串”ababababca”中查找模式字符串”abababca”。如果在 j 处字符不匹配，那么由于前边所说的模式字符串 PMT 的性质，主字符串中 i 指针之前的 PMT[j −1] 位就一定与模式字符串的第 0 位至第 PMT[j−1] 位是相同的。这是因为主字符串在 i 位失配，也就意味着主字符串从 i−j 到 i 这一段是与模式字符串的 0 到 j 这一段是完全相同的。而我们上面也解释了，模式字符串从 0 到 j−1 ，在这个例子中就是”ababab”，其前缀集合与后缀集合的交集的最长元素为”abab”， 长度为4。所以就可以断言，主字符串中i指针之前的 4 位一定与模式字符串的第0位至第 4 位是相同的，即长度为 4 的后缀与前缀相同。这样一来，我们就可以将这些字符段的比较省略掉。具体做法是，保持i指针不动，然后将j指针指向模式字符串的PMT[j −1]位即可。 next数组： 在字符串的匹配中，如果是在 j 位失配，那么影响 j 指针回溯的位置的其实是第 j −1 位的 PMT 值，所以为了编程的方便， 我们不直接使用PMT数组，而是将PMT数组向后偏移一位。我们把新得到的这个数组称为next数组。 next数组生成程序： 123456789def getNext(self, s): i = 0; j = -1; next = [-1]*(len(s)+1) while i &lt; len(s): if j == -1 or p[i] == p[j]: # 匹配的情况 或者是刚退回到原位进行比较 i +=1; j+=1; next[i] = j else: # 不匹配，退回到模式串的上个相同位置处 j = next[j] return next 其中有一个技巧是，在把PMT进行向右偏移时，第0位的值，我们将其设成了-1，这只是为了编程的方便，并没有其他的意义。在本节的例子中，next数组如上表所示。在代码实现中，next相当于PMT右移了一位，故j从-1开始，next长度为len(s)+1，next[0]=-1。 字符串匹配程序： 123456789101112def KMP(self, haystack, needle): next = self.getNext(neddle) i = 0; j = 0; while i &lt; len(haystack): if j == -1 or haystack[i] == neddle[j]: i+=1; j+=1; else: j = next[j]; if j == len(neddle): eturn i - j return -1 回溯算法回溯法也可以叫做回溯搜索法，它是一种搜索的方式。回溯法解决的问题都可以抽象为树形结构，是的，我指的是所有回溯法的问题都可以抽象为树形结构！因为回溯法解决的都是在集合中递归查找子集，集合的大小就构成了树的宽度，递归的深度，都构成的树的深度。 回溯法一般可以解决如下几种问题： 组合问题：N个数里面按一定规则找出k个数的集合； 切割问题：一个字符串按一定规则有几种切割方式； 子集问题：一个N个数的集合里有多少符合条件的子集； 排列问题：N个数按一定规则全排列，有几种排列方式； 棋盘问题：N皇后，解数独等等。 回溯法模板： 12345678910111213void backtracking(参数) { if (终止条件) { 存放结果; return; } for (选择：本层集合中元素(树中节点孩子的数量就是集合的大小)) { 处理节点; backtracking(路径，选择列表); // 递归 回溯，撤销处理结果 } } 例如：Leetcode77：组合问题 123456789101112131415161718class Solution: def combine(self, n: int, k: int) -&gt; List[List[int]]: # 套用回溯算法经典模板 path = [] # 全局列表，存放路径和结果 result = [] def backtracking(n, k, index):** # index代表位置信息，从哪个位置开始 # 终止条 if len(path) == k: result.append(path[:]) # 深拷贝 return # index~n为本层节点 剪枝剪掉无用节点 for i in range(index, n-(k-len(path))+1+1): path.append(i) backtracking(n, k, i+1) #index+1代表不重复 下一层从后一个数开始 path.pop() # 以i开头的遍历完了，需要返回到上一层，即回溯 backtracking(n, k, 1) return result 背包问题0/1背包：有n件物品和一个最多能背重量为w 的背包。第i件物品的重量是weight[i]，得到的价值是value[i] 。每件物品只能用一次，求解将哪些物品装入背包里物品价值总和最大。 代码模板：（一维dp，滚动数组）此模板为让价值更高。 1234567891011121314151617# 初始化: 全为0dp = [0] * (bag_weight + 1)# 先遍历物品, 再遍历背包容量for i in range(len(weight)): # i代表每一个数据，故为0~len-1 for j in range(bag_weight, weight[i] - 1, -1): # j为dp的编号，要从大到小，避免内存重复，保证物品i只放入一次，且需先遍历i，再遍历j，保证每次背包有多个物品 # 递推公式 dp[j] = max(dp[j], dp[j - weight[i]] + value[i])# dp数组表示前i个物品中满足重量要求j的最高价值# 其中dp[j]为本次不进行操作的情况，则与上一个物品i时的情况一致；# dp[j - weight[i]] + value[i]为添加本次物品的情况，则为未添加的价值加上该物品价值# 此外还有判断类型之和的，如有多少种方法使得和为多少，此时：# dp[j] += dp[j - weight[i]]# dp数组表示前i个物品中重量和为j的集合个数 完全背包：有N件物品和一个最多能背重量为W的背包。第i件物品的重量是weight[i]，得到的价值是value[i] 。每件物品都有无限个（也就是可以放入背包多次），求解将哪些物品装入背包里物品价值总和最大。 完全背包和01背包问题唯一不同的地方就是，每种物品有无限件。 代码模板： 与0/1背包只有一个区别：for j in range(bag_weight, weight[i] - 1, -1)从后往前遍历变为从前往后，即for j in range(weight[i], bag_weight+1)，这样每个物品可以遍历多次，因为后一次的dp受到了前一次的影响。 有关最终的排列和组合，外层为物品，内层为重量—-&gt;对应组合；外层为重量，内层为物品—-&gt;对应排列，即每个顺序都考虑了，因为每一层都对各个物品进行了dp求解","link":"/2023/02/24/%E7%AE%97%E6%B3%95/"},{"title":"JVM","text":"本篇文章进行了java基础中jvm的介绍，jvm也是Java虚拟机。java虚拟机有自己完善的架构，如处理器、堆栈、寄存器等，还具有相应的指令系统。java虚拟机屏蔽了与具体操作系统平台相关的信息，使得java程序只需生成在java虚拟机上运行的目标代码，就可以在多种平台上不加修改地运行。本篇文章主要讲解：jvm的位置，体系结构以及垃圾回收机制。 1. 面试问题 请你谈谈你对jvm的理解？java8虚拟机和之前的变化更新？ 什么是oom，什么是栈溢出StackOverFlowError？怎么分析？ jvm的常用调优参数有哪些？ 内存快照如何抓取，怎么分析Dump文件？知道吗？ 谈谈jvm，类加载器你的认识？ 2. jvm的位置 在操作系统之上，包含在jre里。 3. jvm的体系结构体系结构示意图： 简化版： 对java文件，进行编译（javac），就得到类文件（class file）； 栈、本地方法栈、程序计数器不会发生gc（垃圾回收机制）； jvm调优主要在堆，方法区有一小部分。 4. 类加载器作用：加载.class文件。 新建的对象放入堆里面，引用（地址）放到栈，其中引用指向堆里面对应的对象。 四级加载器，从上到下依次为： 虚拟机自带的加载器； 启动类（根）加载器 Bootstrap ClassLoader，主要负责加载Java核心类库，%JRE_HOME%\\lib下的rt.jar、resources.jar、charsets.jar和class等； 扩展类加载器 Extension ClassLoader，主要负责加载目录%JRE_HOME%\\lib\\ext目录下的jar包和class文件； 应用程序（系统类）加载器 Application ClassLoader，主要负责加载当前应用的classpath下的所有类； 这四级是通过组合方式实现的，不是继承。 classLoader加载类的具体流程： 类加载器收到类加载的请求（创建完class就会发送请求了）； 将这个请求向上委托给父类加载器去完成（请求最开始在应用程序加载器Application ClassLoader，也就是自己编写的class的加载器），一直向上委托，直到启动类加载器（Bootstrap ClassLoader）； 启动类加载器检查是否能够加载当前这个类，能够加载就结束，并使用此加载器，否则，抛出异常，并通知子加载器进行加载； 重复步骤3，若所有加载器都没能加载此类，则会抛出异常：Class Not Found。 null的含义： 此类不存在； 此类java调用不到。（但C和C++能够调用，因此有些java调用不到的东西会用native关键字，让C++去调用） java实际上是C++–，去掉了C中的指针，和内存管理（java中全都交给了虚拟机jvm）。 双亲委派机制 检查顺序从下至上，加载顺序从上到下； 如果一个类加载器需要加载类，那么首先它会把这个类请求委派给父类加载器去完成，每一层都是如此； 一直递归到顶层，当父加载器无法完成这个请求时，子类才会尝试去加载。 例子：自定义java.lang.String类，并编写main方法，执行类的实例化并调用toString方法： 会出现报错：String类中无法执行main函数。 原因：编写了String.class后，执行的是Bootstrap根加载器，因为根加载器中有String类，能够加载，因此不会加载我们自己写的String.class（即Application ClassLoader）。 双亲委派机制的目的：为了安全，不让用户自行修改java默认的文件；同时避免类的重复加载。 通过委派的方式，可以避免类的重复加载，当父加载器已经加载过某一个类时，子加载器就不会再重新加载这个类； 通过双亲委派的方式，还保证了安全性。因为Bootstrap ClassLoader在加载的时候，只会加载JAVA_HOME中的jar包里面的类，如java.lang.String，那么这个类是不会被随意替换的，除非有人跑到你的机器上， 破坏你的JDK。那么，就可以避免有人自定义一个有破坏功能的java.lang.String被加载。这样可以有效的防止核心Java API被篡改。 沙箱安全机制 控制远程代码执行的权限； jdk1.6之后的域； 为了保证安全。 5. native 包含native关键字的方法，说明java的作用范围拿不到了，会去调用底层c语言的库； 会进入本地方法栈（native method stack），即会把该方法的地址放入栈中，程序运行到此方法时，找到对应地址，并调用本地方法的接口，进行方法的执行； 调用本地方法接口JNI（java native inferface）； JNI作用：扩展java的使用，融合不同的编程语言为java所用。 最初：c、c++盛行，java出现了必须要能够有调用c的接口才能被打架使用； 它在内存区域中专门开辟了一块标记区域（本地方法栈 native method stack），登记native方法； 在最终执行的时候，通过JNI加载本地方法库中的方法 6. pc寄存器线程私有，保证线程顺序。即每个线程会有各自的寄存器，并进行计数。 7. 方法区 方法区是被所有线程共享的，所有的字段和方法字节码，以及一些特殊方法，如构造函数，接口代码也在此定义，简单说，所有定义方法的信息都保存在该区域，此区域属于共享空间； 静态变量，常量，类信息（构造方法，接口定义），运行时的常量池都存在方法区中，但是实例变量都是在堆内存中，和方法区无关。 存储内容：static、final、.class、常量池 面试题：对象加载（实例化）的示意图。 要画出 堆 栈 方法区； 创建一个类的时候，会先在方法区中生成一个类的模板，同时将一些常量写进常量池中； 生成对象时，将引用存放在栈中，并将真实的地址（包括该对象的属性和方法）放入堆中； 通过引用指向真实的对象； 对象中的常量属性从常量池中获取（如果有的话）。 8. 栈 先进后出； 思考：为什么main先执行，最后结束： 每次调用方法，都会压栈，当超出了栈的内存时，就会栈溢出； 栈主管程序的运行，栈的生命周期和线程同步，线程结束了，栈就释放了； 栈不存在垃圾回收问题（如果有垃圾程序就都塞住了）； 存储：8大基本类型 + 对象引用（地址） + 实例的方法。 9. 堆Heap，一个JVM只有一个堆内存，堆内存的大小是可以调节的。 堆内存划分： 新生区 ：Eden（伊甸园区）、S0（幸存0区）、S1（幸存1区）。 对象在新生区诞生、成长、甚至死亡； Eden：所有对象都是在eden区new出来的。 老年区 永久区：这个区域是常驻内存的，用来存放jdk自身携带的class对象。 堆中存放的内容：具体的对象（包括属性，方法…） 如果堆的内存满了，会出现OOM（堆内存不够），java heap space 新生区，老年区 永久区 这个区域是常驻内存的；用来存放JDK自身携带的Class对象，Interface元数据，存储的是Java运行时的一些环境或类信息； 这个区域不存在垃圾回收！关闭VM虚拟就会释放这个区域的内存~ 若一个启动类加载了大量的第三方jar包，或Tomcat部署了太多的应用，或大量动态生成的反射类，不断的被加载，直到内存满，就会出现OOM; 演变： jdk1.6之前：有永久区，且常量池是在方法区； jdk1.7：有永久区，但是慢慢的退化了，常量池在堆中； jdk1.8之后：无永久区（改叫元空间），常量池在方法区，方法区在元空间。 堆内存调优出现了OOM溢出： 尝试扩大堆内存看结果；如-Xms1024m -Xmx1024m -XX:+PrintGCDetails 分析内存，看一下哪个地方出了问题； 扩大内存无果，分析排错：如-Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError，导出dump文件； 用jprofier工具看，是哪个文件太大导致的溢出，是哪一行的操作导致了溢出（点击Thread）； 进行修改。 在一个项目中，突然出现了OOM故障，那么该如何排除？研究为什么出错 能够看到代码第几行出错：内存快照分析工具：MAT，jprofier debug，一行一行看（不现实） MAT，jprofiler作用： 分析dump内存文件，快速定位内存溢出的位置； 获得堆中的数据； 获得大的对象。 调优指令： -Xms：设置初始化内存分配大小，默认为电脑内存的1/64； -Xmx：设置最大分配内存，默认为电脑内存的1/4； -XX:+PrintGCDetails：打印GC垃圾回收的相关信息； -XX:+HeapDumpOnOutOfMemoryError：导出dump文件，可以用jprofiler查看，快速定位内存溢出的位置。 如：-Xms1m -Xmx8m -XX:+PrintGCDetails 通常养老区的内存占堆中内存的2/3； 新生区占1/3，新生区中，Edan区占8成，为8：1：1。 10. GC 垃圾回收机制引用计数法记录每个对象的引用次数，长时间没有被引用的对象就被清除掉。 引用计数法一般很少用，因为太麻烦了，而且对象通常很多，影响效率。 复制算法GC时的新生区流程： 每次GC，都会将Eden区的幸存者（没有清除掉）会移动到幸存区，具体是移动到to区； （一旦Eden区被GC，Eden区就是空的；） from区的幸存者移动到to区； to区变成from区，from区变成to区；（to区要保证一定是空的） 当一个对象经过了15次GC后（默认是15，可以更改：–XX:MaxTenuringThreshold=进入老年代的时间）依然存活，则进入到养老区。 步骤3、4就是复制算法，即将from区的幸存者移动到to区，同时两个区交换。 复制算法的好处：没有内存碎片（就是指每次GC后，幸存者都在from区，Eden和to区都是空的，没有这里一点，那里一点）； 复制算法的坏处：浪费内存空间，多了一半的内存（to空间永远是空的）； 复制算法最佳使用场景：对象存活度较低的时候 -&gt; 也就是新生区。 标记清除算法 优点：不需要额外的空间。 缺点：两次扫描，严重浪费时间，会产生内存碎片。 改进： 标记压缩算法：再进行一次扫描，进行压缩，向一段移动活着的对象，防止内存碎片的产生； 但是会多出一次扫描，浪费时间； 三者结合，比如进行五次标记清除，再进行一次压缩，但本质上还是没有改变。 GC总结 内存效率：复制算法&gt;标记清除算法&gt;标记压缩算法(时间复杂度) 内存整齐度：复制算法=标记压缩算法&gt;标记清除算法 内存利用率：标记压缩算法=标记清除算法&gt;复制算法 思考一个问题:难道没有最优算法吗?答案：没有，没有最好的算法，只有最合适的算法—–&gt; GC:分代收集算法 年轻代： 存活率低； 考虑复制算法。 老年代： 区域大：存活率高； 考虑标记清除＋标记压缩混合实现。（这个比例可以通过调优得到最佳值） 11. JMM JMM：（Java Memory Model的缩写）指java内存模型； 作用：是缓存一致性协议，用于定义数据读写的规则，保证线程的安全； JMM定义了线程工作内存和主内存之间的抽象关系：线程之间的共享变量存储在主内存(Main Memory)中，每个线程都有一个私有的本地内存(Local Memory) 但是每一个线程更改变量（做出操作）是不可见的，因此要保证线程的一致性，也就是一旦执行了操作，就更新主内存： 解决共享对象可见性：volilate volilate：能够保证可见性和消除指令重排，但不会保证原子性。 具体的，JMM对制定了如下规则： 不允许read和load、store和write操作之一单独出现。即使用了read必须load，使用了store必须write； 允许线程丢弃他最近的assign操作，即工作变量的数据改变了之后，必须告知主存； 不允许一个线程将没有assign的数据从工作内存同步回主内存； 一个新的变量必须在主内存中诞生，不允许工作内存直接使用一个未被初始化的变量。就是对变量实施use.store操作之前，必须经过assign和load操作； 一个变量同一时间只有一个线程能对其进行lock。多次lock后，必须执行相同次数的unlock才能解锁，如果对一个变量进行lock操作，会清空所有工作内存中此变量的值，在执行引擎使用这个变量前，必须重新load或assign操作初始化变量的值； 如果一个变量没有被lock，就不能对其进行unlock操作。也不能unlock一个被其他线程锁住的变量对一个变量进行unlock操作之前，必须把此变量同步回主内存 JMM对这八种操作规则和对volatile的一些特殊规则就能确定哪里操作是线程安全，哪些操作是线程不安全的了。但是这些规则实在复杂，很难在实践中直接分析。所以一般我们也不会通过上述规则进行分析。更多的时候。使用java的happen-before规则来进行分析。","link":"/2023/02/27/JVM/"},{"title":"设计模式","text":"本篇文章主要进行设计模式的介绍，设计模式是前辈们对代码开发经验的总结, 是解决特定问题的一系列套路, 他不是语法规定, 而是一套用来提高代码可复用性、可维护性、可读性、稳健性以及安全性的解决方案。本文中简要列出了23中设计模式，以及OOP七大原则，并重点介绍了单例模式，工厂模式，抽象工厂模式，建造者模式，原型模式，适配器模式，桥接模式，代理模式和模板方法模式。 1. 设计模式概述设计模式是前辈们对代码开发经验的总结, 是解决特定问题的一系列套路, 他不是语法规定, 而是一套用来提高代码可复用性、可维护性、可读性、稳健性以及安全性的解决方案。 1.1 23种设计模式 创建型模式： 单例模式，工厂模式，抽象工厂模式，建造者模式，原型模式 结构型模式 适配器模式，桥接模式，装饰模式，组合模式，外观模式，享元模式，代理模式 行为型模式： 模板方法模式，命令模式，迭代器模式，观察者模式，中介者模式，备忘录模式，解释器模式，状态模式，策略模式，职责链模式，访问者模式 1.2 OOP七大原则 开闭原则（核心）：对扩展开放，对修改关闭。就是添加功能不能改变原有代码； 里氏替换原则：继承必须确保超类所拥有的性质在子类中仍然成立。就是子类不要重写父类的方法； 依赖倒置原则：要面向接口编程，不要面向实现编程。就是先写好接口，各个实现类去分别实现接口； 单一职责原则：控制类的粒度大小，将对象解耦，提高其内聚性。就是每一个类实现一个功能，要拆分彻底； 接口隔离原则：要为各个类建立他们需要的专用接口； 迪米特法则 ：只与你的直接朋友交谈，不跟陌生人说话。就是A要与C建立连接，最好找一个B，保证A和B，B和C之间都有连接； 合成复用原则：尽量先使用组合或者聚合等关联关系实现，其次再考虑使用继承关系。 2. 单例模式2.1 饿汉式12345678910111213141516//饿汉式单例public class Hungry { //私有化构造器，外部无法直接调用 private Hungry(){ } //一上来就加载了 private final static Hungry HUNGRY = new Hungry(); //类的实例化 public static Hungry getInstance(){ return HUNGRY; }} 饿汉式在类的创建时，就已经进行了实例化，创建好了静态的对象供系统使用，以后不再改变，因此是线程安全的； 但饿汉式需要消耗大量的内存，因为每次加载都会进行实例化，于是有了懒汉式，仅在需要实例时才创建。 2.2 DCL 懒汉式123456789101112131415161718192021222324252627282930313233343536//懒汉式单例模式public class LazyMan { //构造器私有化 private LazyMan(){ } //先声明，但没有使用 private volatile static LazyMan lazyMan; //双重检测锁模式的懒汉式单例 DCL懒汉式 public static LazyMan getInstance(){ if(lazyMan==null){ //加上同步锁，保证线程安全 synchronized (LazyMan.class){ //等到需要创建实例时，再进行实例化 if(lazyMan==null){ lazyMan = new LazyMan(); /** 1.分配内存空间 2.执行构造方法，初始化对象 3.把这个对象指向这个空间 正常流程：123 但有时候会出现指令重排，如132 --线程A 在这种情况下，如果出现了线程B，就会出现lazyMan!=null，但还没有完成构造的情况 因此要加上volatile */ } } } return lazyMan; }} 正常的懒汉式是线程不安全的，因为在多线程的情况下，无法保证每次的实例化对象是相同的，可能会出现多个对象； 于是添加了同步锁，进行双重检测锁模式，使得线程变为安全； 但由于lazyMan = new LazyMan()不是一个原子性操作，会受到指令重排的影响。在多线程情况下，会导致实例无法构造，于是需要添加volatile关键字，避免指令重排的情况； 补充：原子性操作：不会被线程调度机制打断的操作。这种操作一旦开始，就一直运行到结束，中间不会出现线程切换。也就是一定要按顺序执行完。 2.3 静态内部类1234567891011121314151617//静态内部类public class Holder { //构造器私有 private Holder(){ } public static Holder getInstance(){ return InnerClass.HOLDER; } //在内部类中实例化 public static class InnerClass{ private static final Holder HOLDER = new Holder(); }} 2.4 枚举由于反射的存在，可以将构造器，或者属性的私有性破坏，导致：这些单例模式都不安全！ 12345678910//enum 本身也是一个Class类public enum EnumSingle { INSTANCE; public EnumSingle getInstance(){ return INSTANCE; }} 枚举可以避免反射的发生。 2.5 单例模式总结 核心作用：保证一个类只有一个实例，并且提供一个访问实例的全局访问点。 常见场景： Windows的任务管理器，回收站； 读取配置文件的类，一般也只有一个对象； 网站的计数器一般也会采用单例模式，来保证同步； 数据库连接池的设计一般也算单例模式； Servlet编程中，每个Servlet也是单例的； 在Spring中，每个Bean默认就是单例的：这些Bean只能有一个实例，当spring创建applicationContext容器的时候，spring会初始化所有的该作用域实例； 此外，Spring中的Bean也可以设置为原型模式，每次通可以过getBean获取一个新实例，创建后spring将不再对其管理。 3. 工厂模式 作用：实现了创建者和调用者的分离 核心本质： 实例化对象不使用new，用工厂方法代替； 将选择实现类，创建对象统一管理和控制。从而将调用者跟我们的实现类解耦。 详细分类 简单工厂模式 ：用来生成同一等级结构中的任意产品（对于增加的新产品，需要覆盖已有代码）； 工厂方法模式：用来生产同一等级结构中的固定产品（支持增加任意产品）； 抽象工厂模式：围绕一个超级工厂创建其他工厂，该超级工厂称为其它工厂的工厂。 3.1 简单工厂模式 构建一个工厂，需要实例化类时，直接调用工厂的方法即可。在工厂中进行类的实例化； 简单工厂模式不满足开闭原则，当新增一个类时，需要改变CarFactory类的代码。 12345678910111213141516171819202122232425262728293031//简单工厂模式，也叫静态工厂//如果要新增功能，需要修改此类，不满足开闭原则public class CarFactory { //拿车 public static Car getCar(String car){ if(car.equals(&quot;五菱&quot;)) { return new WuLing(); } else if(car.equals(&quot;特斯拉&quot;)){ return new Tesla(); } else { return null; } }}public class Customer { public static void main(String[] args) { //1. 原始方式// Car car1 = new WuLing();// Car car2 = new Tesla();// car1.name();// car2.name(); //2.工厂模式，直接去工厂拿，要什么拿什么，不需要new对象了 Car car1 = CarFactory.getCar(&quot;五菱&quot;); car1.name(); }} 3.2 工厂方法模式 设计一个工厂的接口，每一个类都再编写一个对应的工厂类，并实现该接口； 需要实例化类时，直接实例化对应的工厂，并调用工厂接口中的方法; 当新增一个类时，直接再新增一个对应的工厂类，并实现工厂接口CarFactory，不需要修改原来的代码。 1234567891011121314151617181920//工厂方法模式，能够满足开闭原则public interface CarFactory { Car getCar();}public class WuLingFactory implements CarFactory{ @Override public Car getCar() { return new WuLing(); }}public class Customer { public static void main(String[] args) { Car car1 = new WuLingFactory().getCar(); Car car2 = new TeslaFactory().getCar(); car1.name(); car2.name(); }} 3.3 两种方式的比较 根据设计原则，工厂方法模式更优，因为满足开闭原则； 根据实际业务，简单工厂模式更优，业务复杂度低，且易于管理，就管理一个工厂类就行了。 3.4 工厂模式总结 简单工厂模式（静态工厂模式) 虽然某种程度上不符合设计原则，但实际使用最多！ 工厂方法模式 不修改已有类的前提下，通过增加新的工厂类实现扩展。 抽象工厂模式 不可以增加产品，可以增加产品族! 应用场景： JDK中Calendar的getlnstance方法； JDBC中的Connection对象的获取； Spring中IOC容器创建管理bean对象。IOC将多个Bean放在了工厂中，使用时，直接调用工厂的getBean方法，想要什么，就在参数中设置什么：getBean(要获取的Bean的id)； 在IOC容器中，通过静态工厂方法声明创建bean的步骤是： 首先在bean的class属性里指定静态工厂类的全类名; 同时在factory-method属性里指定工厂方法的名称; 最后使用&lt;constrctor-arg&gt;元素为该方法传递方法参数; 通过ioc容器的getBean()方法就可以获取到创建的bean对象 反射中Class对象的newInstance方法 4. 抽象工厂模式抽象工厂模式提供了一个创建一系列相关或者相互依赖对象的接口，无需指定它们具体的类 适用场景： 客户端（应用层）不依赖于产品类实例如何被创建、实现等细节； 强调一系列相关的产品对象（属于同一产品族）一起使用创建对象需要大量的重复代码； 提供一个产品类的库，所有的产品以同样的接口出现，从而使得客户端不依赖于具体的实现 优点：具体产品在应用层的代码隔离，无需关心创建的细节将一个系列的产品统一到一起创建 缺点：规定了所有可能被创建的产品集合，产品簇中扩展新的产品困难；加了系统的抽象性和理解难度 个人理解： 创建了一个抽象工厂的接口，里面包含了获取各种产品的方法（即规定了所有可能被创建的产品集合）； 每个子工厂都需要实现该抽象工厂接口，同时实现接口的方法，分别调用自己下面的产品； 客户端实例对象时，先实例化对应的工厂（该工厂实现了抽象工厂的接口），然后调用工厂的方法获取实例。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//抽象产品工厂public interface IProductFactory { //生产手机 IphoneProduct iphoneProduct(); //生产路由器 IRouterProduct iRouterProduct();}//子工厂类，实现抽象工厂接口，在其中实例化对象public class XiaoMiFactory implements IProductFactory{ @Override public IphoneProduct iphoneProduct() { return new XiaoMiPhone(); } @Override public IRouterProduct iRouterProduct() { return new XiaoMiRouter(); }}public class HuaWeiFactory implements IProductFactory{ @Override public IphoneProduct iphoneProduct() { return new HuaWeiPhone(); } @Override public IRouterProduct iRouterProduct() { return new HuaWeiRouter(); }}//用户public class Client { public static void main(String[] args) { System.out.println(&quot;-------------------小米系列---------------------&quot;); IProductFactory xiaomiFactory = new XiaoMiFactory(); IphoneProduct iphoneProduct = xiaomiFactory.iphoneProduct(); iphoneProduct.callUp(); IRouterProduct iRouterProduct = xiaomiFactory.iRouterProduct(); iRouterProduct.openWifi(); System.out.println(&quot;-------------------华为系列---------------------&quot;); IProductFactory huaWeiFactory = new HuaWeiFactory(); IphoneProduct iphoneProduct1 = huaWeiFactory.iphoneProduct(); IRouterProduct iRouterProduct1 = huaWeiFactory.iRouterProduct(); iphoneProduct1.callUp(); }} 类图： 5. 建造者模式 建造者模式也属于创建型模式，它提供了一种创建对象的最佳方式； 定义：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示； 主要作用：在用户不知道对象的建造过程和细节的情况下就可以直接创建复杂的对象； 用户只需要给出指定复杂对象的类型和内容，建造者模式负责按顺序创建复杂对象（把内部的建造过程和细节隐藏起来) 例子：工厂（建造者模式）︰负责制造汽车（组装过程和细节在工厂内）汽车购买者（用户）：只需要说出需要的型号（对象的类型和内容），然后直接购买就可以使用了（不需要知道汽车是怎么组装的（车轮、车门、发动机、方向盘等等））。 角色分析（以建房子为例）： 假设造房简化为如下步骤：(1）地基（2）钢筋工程（3）铺电线（4）粉刷； 如果要盖一座房子： 首先要找一个建筑公司或工程承包商（指挥者Director），用于选择具体的工人（具体建造者Builder）过来造房子（产品Product），同时指定建房子的顺序（上述四个步骤的顺序），最后验收； 具体建造者Builder负责完成建房子的四个步骤（没有顺序，就是说四个步骤都能做），建造者负责建成房子（Product）； 产品Product就是最终的结果，也包含了上述的四个部分。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374//抽象的建造者：方法public abstract class Builder { //四个步骤 abstract void buildA(); //铺地基 abstract void buildB(); //钢筋工程 abstract void buildC(); //铺电线 abstract void buildD(); //粉刷 //最终结果：得到了房子 abstract Product getProduct();}//具体的建造者：工人public class Worker extends Builder { private Product product; //工人负责创建产品！！很重要 public Worker(){ product = new Product(); } @Override void buildA() { product.setBuildA(&quot;地基&quot;); System.out.println(&quot;地基&quot;); } @Override void buildB() { product.setBuildB(&quot;钢筋工程&quot;); System.out.println(&quot;钢筋工程&quot;); } @Override void buildC() { product.setBuildC(&quot;铺电线&quot;); System.out.println(&quot;铺电线&quot;); } @Override void buildD() { product.setBuildD(&quot;粉刷&quot;); System.out.println(&quot;粉刷&quot;); } @Override Product getProduct() { return product; }}//指挥：核心，负责指挥构建一个工程，工程如何构建，由他决定public class Director { //指挥工人按照顺序建房子 public Product build(Builder builder){ builder.buildA(); builder.buildB(); builder.buildC(); builder.buildD(); return builder.getProduct(); }}public class Test { public static void main(String[] args) { //指挥 Director director = new Director(); //指挥 具体的工人完成 产品 //指挥：可以自己选取工人，还能选取建造顺序 Product build = director.build(new Worker()); System.out.println(build.toString()); //因此，对于消费者来说，只需要找到指挥就行了，剩下的全都无关，指挥者最后得到了产品，并交给消费者 }} 优点： 产品的建造和表示分离，实现了解耦（也就是结果和过程分开，交给别人做，自己拿结果就行，而不是自己创建一个对象）。使用建造者模式可以使客户端不必知道产品内部组成的细节； 将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰； 具体的建造者类之间是相互独立的，这有利于系统的扩展（因为有着共同的接口）。增加新的具体建造者无需修改原有类库的代码，符合“开闭原则“，客户可以选择任意的建造者。 缺点： 建造者模式所创建的产品一般具有较多的共同点，其组成部分相似（因为有一个抽象的接口）；如果产品之间的差异性很大（图纸都变了，那需要更多的接口了），则不适合使用建造者模式，因此其使用范围受到一定的限制； 如果产品的内部变化复杂，可能会导致需要定义很多具体建造者类来实现这种变化，导致系统变得很庞大。 应用场景： 需要生成的产品对象有复杂的内部结构，这些产品对象具备共性; 隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品； 适合于一个具有较多的零件（属性）的产品（对象）的创建过程。 建造者与抽象工厂模式的比较: 与抽象工厂模式相比，建造者模式返回一个组装好的完整产品，而抽象工厂模式返回一系列相关的产品，这些产品位于不同的产品等级结构，构成了一个产品族； 在抽象工厂模式中，客户端实例化工厂类，然后调用工厂方法获取所需产品对象，而在建造者模式中客户端可以不直接调用建造者的相关方法，而是通过指挥者类来指导如何生成对象，包括对象的组装过程和建造步骤，它侧重于一步步构造一个复杂对象，返回一个完整的对象； 如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装可以返回一辆完整的汽车！ 一个具体应用：lombok插件中的@Builder注解 Builder 使用创建者模式又叫建造者模式。简单来说，就是一步步创建一个对象，它对用户屏蔽了里面构建的细节，但却可以精细地控制对象的构造过程。 @Builder内部帮我们做了什么？能够帮助初始化你的实例对象。 创建一个名为ThisClassBuilder的内部静态类，并具有和实体类形同的属性（称为构建器）; 在实体类中：会创建一个build()方法，它的目的是用来创建构建器； 在构建器中：对于目标类中的所有的属性和未初始化的final字段，都会在构建器中创建对应属性； 在构建器中：创建一个无参的default构造函数； 在构建器中：对于实体类中的每个参数，都会对应创建类似于setter的方法，只不过方法名与该参数名相同。并且返回值是构建器本身（便于链式调用）； 在构建器中：一个build()方法，调用此方法，就会根据设置的值进行创建实体对象； 在构建器中：同时也会生成一个toString()方法。 6. 原型模式6.1 原型模式 原型模式可以理解为克隆，先创建（new）一个被克隆的对象，当需要创建和原对象相同的对象时，直接进行克隆即可； 浅克隆：克隆前后的对象指向同一个引用，即改变前对象的属性，克隆后的对象也会发生变化； 深克隆：克隆前后的对象都指向各自的引用，即改变前对象的属性，克隆后的对象保持不变。 被克隆的类需要：实现Cloneable接口，并重写clone方法 图解： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576//浅克隆//被克隆的类，也叫原型public class Video implements Cloneable{ private String name; private Date date; //能够被克隆 @Override protected Object clone() throws CloneNotSupportedException { return super.clone(); } public Video(String name, Date date) { this.name = name; this.date = date; } @Override public String toString() { return &quot;Video{&quot; + &quot;name='&quot; + name + '\\'' + &quot;, date=&quot; + date + '}'; }}//深克隆//被克隆的类，也叫原型public class Video implements Cloneable{ private String name; private Date date; //能够被克隆 @Override //修改克隆方法，使其成为深克隆 protected Object clone() throws CloneNotSupportedException { Object obj = super.clone(); //实现深克隆：将这个对象的属性也进行克隆 Video v = (Video) obj; v.date = (Date) this.date.clone(); return obj; } public Video(String name, Date date) { this.name = name; this.date = date; } @Override public String toString() { return &quot;Video{&quot; + &quot;name='&quot; + name + '\\'' + &quot;, date=&quot; + date + '}'; }}//实现克隆public class Bilibili { public static void main(String[] args) throws CloneNotSupportedException { Date date = new Date(); Video v1 = new Video(&quot;狂神说Java&quot;, date); Video v2 = (Video) v1.clone(); System.out.println(v1.toString()); System.out.println(v2.toString()); //浅克隆：克隆前后的对象指向同一个引用date，更改date会导致二者都发生变化 date.setTime(123123132); System.out.println(v1.toString()); System.out.println(v2.toString()); }} 一个具体的应用： spring容器管理bean的另一种方法：原型模式，实现创建好每个bean的实例，每次使用getBean时就克隆一份。 6.2 创造型模式总结 创建型模式的作用：帮我们new对象的（或者克隆对象），与对象的创建有关； 单例模式保证一个类只有一个实例； 工厂模式分为简单工厂和工厂方法，一般简单工厂模式就够了； 抽象工厂模式是生产一个大的产品族，而工厂模式是生产一个具体的产品； 建造者模式让对象的创建和使用分离，可以将一个个模块通过指挥者进行指挥拼装，可以创建复杂对象； 原型模式只需要new一个原型，后面的实例可以直接克隆原型，可以提高效率。对象复杂时，可以考虑使用原型模式。 7. 适配器模式结构型模式：从程序的结构上实现松耦合，从而可以扩大整体的类结构，用来解决更大的问题。 适配器模式： 将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类可以在一起工作； 角色分析： 目标接口：客户所期待的接口，目标可以是具体的或抽象的类，也可以是接口。（比如这里的电脑USB） 需要适配的类：需要适配的类或适配者类。（网线） 造配器：通过包装一个需要适配的对象，把原接口转换成目标对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//要被适配的类：网线public class Adaptee { public void request(){ System.out.println(&quot;连接网线上网&quot;); }}//接口转换器的抽象实现，用于造转换器public interface NetToUsb { //作用：处理请求，网线=&gt;usb void handleRequest();}//适配器//采用组合方式（对象适配器），也可以直接继承（类适配器）public class Adapter2 implements NetToUsb{ private Adaptee adaptee; //用有参构造器去包装被适配类（网线） public Adapter2(Adaptee adaptee){ this.adaptee = adaptee; } @Override public void handleRequest() { adaptee.request(); //可以上网了 }}//客户端类：电脑//想上网，但插不上网线public class Computer { //上网：电脑需要转接器才可以上网 public void net(NetToUsb adapter){ //找一个转接头 adapter.handleRequest(); } public static void main(String[] args) { //电脑，适配器，网线 Computer computer = new Computer(); Adaptee adaptee = new Adaptee(); Adapter2 adapter2 = new Adapter2(adaptee); computer.net(adapter2); }} 对象适配器优点： 一个对象适配器可以把多个不同的适配者适配到同一个目标； 可以适配一个适配者的子类，满足“里氏代换原则”； 类适配器缺点： 对于Java、C#等不支持多重类继承的语言，一次最多只能适配一个适配者类，不能同时适配多个适配者; 在Java、C#等语言中，类适配器模式中的目标抽象类只能为接口，不能为类，其使用有一定的局限性。 具体的应用： InputStreamReader(InputStream) //字符流转字节流 进行了转接； SpringMVC Dispachter中的处理器映射器，处理器适配器； SpringBoot中的AutoConfig类中有很多适配器。 8. 桥接模式 桥接模式是将抽象部分与它的实现部分分离，使它们都可以独立地变化。它是一种对象结构型模式，又称为柄体（Handle and Body）模式或接口（Interfce）模式； 适用于出现大量多继承的情况中，每个抽象部分（独立变化的维度）只负责对应的功能（如电脑品牌，电脑类型） 将复杂的多继承关系，按照独立的维度进行了转化，侧重点：找连接点（桥）。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960//品牌Brandpublic interface Brand { void info();}class Lenovo implements Brand{ @Override public void info() { System.out.print(&quot;联想&quot;); }}class Mac implements Brand{ @Override public void info() { System.out.print(&quot;苹果&quot;); }}//电脑类型Computer//抽象类，只能被继承public abstract class Computer { //组合，建桥（Brand和Computer的桥） private Brand brand; public Computer(Brand brand){ this.brand = brand; } public void info(){ brand.info(); }}class Laptop extends Computer{ public Laptop(Brand brand) { super(brand); } public void info(){ super.info(); System.out.print(&quot;手提电脑&quot;); }}class Book extends Computer{ public Book(Brand brand) { super(brand); } public void info(){ super.info(); System.out.print(&quot;笔记本&quot;); }}public class Test { public static void main(String[] args) { //联想笔记本 Book book = new Book(new Lenovo()); book.info(); //苹果手提电脑 Laptop laptop = new Laptop(new Mac()); laptop.info(); }} 好处分析： 桥接模式偶尔类似于多继承方案，但是多继承方案违背了类的单一职责原则，复用性比较差，类的个数也非常多，桥接模式是比多继承方案更好的解决方法，极大的减少了子类的个数，从而降低管理和维护的成本； 桥接模式提高了系统的可扩充性，在两个变化维度中任意扩展一个维度，都不需要修改原有系统。符合开闭原则，就像一座桥，可以把两个变化的维度连接起来。 劣势分析： 桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程； 桥接模式要求正确识别出系统中两个独立变化的维度，因此其使用范围具有一定的局限性。 场景： Java语言通过Java虚拟机实现了平台的无关性；（一个维度：java虚拟机功能程序；另一个维度：能够适用的系统：可以在Windows，Linux…上适用） AWT中的Peer架构； JDBC驱动程序也是桥接模式的应用之一。（一个维度：JDBC本身的功能实现；另一个维度：连接的数据库：可以连接Mysql，可以连接Oracle…） 9. 代理模式9.1 代理模式原理代理模式的定义：为其他对象提供一种代理以控制对这个对象的访问。在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。 代理设计模式的原理： 使用一个代理将对象包装起来，然后用该代理对象取代原始对象。任何对原始对象的调用都要通过代理。代理对象决定是否以及何时将方法调用转到原始对象上。 之前为大家讲解过代理机制的操作，属于静态代理，特征是代理类和目标对象的类都是在编译期间确定下来，不利于程序的扩展。同时，每一个代理类只能为一个接口服务，这样一来程序开发中必然产生过多的代理。最好可以通过一个代理类完成全部的代理功能； 动态代理是指客户通过代理类来调用其它对象的方法，并且是在程序运行时根据需要动态创建目标类的代理对象。动态代理使用场合：1.调试；2.远程方法调用； 动态代理相比于静态代理的优点：抽象角色中（接口）声明的所有方法都被转移到调用处理器一个集中的方法中处理，这样，我们可以更加灵活和统一的处理众多的方法。 9.2 静态代理角色分析： 抽象角色：一般会使用接口或者抽象类来解决； 真实角色：被代理的角色； 代理角色：代理真实角色，代理真实角色后，我们一般会做一些附属操作； 客户：访问代理对象的人。即main方法。 真实角色和代理角色都要实现抽象角色的接口，代理角色需要组合真实角色，实现代理，同时可以增加操作。 12345678910111213141516171819202122232425262728293031323334353637383940//抽象角色public interface IUserDAO { void save();}//真实角色public class UserDAO implements IUserDAO { @Override public void save() { System.out.println(&quot;UserDAO-插入/更新用户&quot;); }}//代理角色，可以相较原始角色，增加新的功能public class UserDAOTransactionProxy implements IUserDAO { private IUserDAO realMapper; public UserDAOTransactionProxy(IUserDAO realMapper) { this.realMapper = realMapper; } @Override public void save() { // 增强逻辑：执行前处理 System.out.println(&quot;proxy-开启事务&quot;); // 调用被代理对象的方法 realMapper.save(); // 增强逻辑：执行后处理 System.out.println(&quot;proxy-提交事务&quot;); }｝public static void main(String[] args) { // 真实对象（原对象） IUserDAO realMapper = new UserDAO(); // 代理对象 持有原对象 IUserDAO mapper = new UserDAOTransactionProxy(realMapper); // 执行IUserDAO接口对象的方法 mapper.save();} 代理模式（静态代理）的好处: 可以使真实角色的操作更加纯粹！不用去关注一些公共的业务； 公共业务就交给代理角色，实现了业务的分工； 公共业务发生扩展的时候，方便集中管理。 （静态代理）缺点: 一个真实角色就会产生一个代理角色； 代码量会翻倍，开发效率会变低。 9.3 动态代理动态代理标准格式： 两个重要类： InvocationHandler：调用处理程序（invoke）并返回结果； Proxy：提供了创建动态代理类和实例的静态方法，用于生成动态代理实例。 代理模式（动态代理）的好处: 可以使真实角色的操作更加纯粹！不用去关注一些公共的业务； 公共业务就交给代理角色，实现了业务的分工； 公共业务发生扩展的时候，方便集中管理； 一个动态代理类代理的是一个接口，一般就是对应的一类业务； 一个动态代理类可以代理多个类，只要是实现了同一个接口即可。 一个具体的例子：spring的AOP底层就是代理模式 基于切面编程，如果我们为Spring的某个bean配置了切面，那么Spring在创建这个bean的时候，实际上创建的是这个bean的一个代理对象，我们后续对bean中方法的调用，实际上调用的是代理类重写的代理方法。 将一些具体的业务交给底层去做，而将公共的业务交给代理，实现一个切面，在其中增加功能。 10. 模板方法模式行为型模式：适应行为的变化 ，强调父类调用子类的特性，用来识别类和对象之间的常用交流模式并加以实现。 模板方法模式： 是类的行为模式； 准备一个抽象类，将部分逻辑以具体方法以及具体构造函数的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。这就是模板方法模式的用意； 比如定义一个操作中的算法的骨架，将步骤延迟到子类中。模板方法使得子类能够不去改变一个算法的结构即可重定义算法的某些特定步骤； 核心：定义一个抽象类，在其中定义一个模板方法，在模板方法中加入一些抽象方法，让子类去继承并实现功能。 模式中的角色： AbstractClass 抽象类实现了模板方法（template），定义了算法的骨架，具体子类需要去实现其它的抽象方法ConcreteClass； 实现抽象方法 ，以完成模板算法中特定的步骤。 类图： 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445abstract class CodeAbstractClass { //定义的一个模板 public void template() { long start = System.currentTimeMillis(); if (callback()) method(); long end = System.currentTimeMillis(); System.out.println(&quot;当前方法执行时长：&quot; + (end - start)); } //子类必须重写的抽象方法 public abstract void method(); public boolean callback(){ //钩子函数，子类可以重写 return true; }} class ConcreteClassA extends CodeAbstractClass { @Override public void method() { for (int i = 0; i &lt; 1000; i++) { System.out.println(&quot;模拟耗时操作...&quot;); } System.out.print(&quot;检测ConcreteClassA.method方法运行的时长======&quot;); }} class ConcreteClassB extends CodeAbstractClass { @Override public void method() { for (int i = 0; i &lt; 20000; i++) { System.out.println(&quot;模拟耗时操作...&quot;); } System.out.print(&quot;ConcreteClassB.method方法运行的时长======&quot;); }} public class Client { public static void main(String[] args) { //检测ConcreteClassA.method方法运行的时长======当前方法执行时长： new ConcreteClassA().template(); //ConcreteClassB.method方法运行的时长======当前方法执行时长： new ConcreteClassB().template(); }} 注意事项和细节： 钩子函数在模板方法模式的父类中，我们可以定义一个方法，它默认不做任何事，子类可以视情况要不要覆盖它，该方法称为“钩子”； 算法只存在于一个地方，也就是在父类中，容易修改。需要修改算法时，只要修改父类的模板方法或者已经实现的某些步骤，子类就会继承这些修改； 一般模板方法都加上 final 关键字， 防止子类重写模板方法。 一个具体的例子：Spring中几乎所有的扩展都是用了模板方法模式，以SpringIOC为例简单说明一下。 首先定义一个接口ConfigurableApplicationContext，声明模板方法refresh； 抽象类AbstractApplicationContext实现了接口，实现了模板方法refresh（这个方法很重要，是各种IOC容器初始化的入口）的逻辑； AbstractRefreshableApplicationContext继承了AbstractApplicationContext，并获取BeanFactory容器； 客户访问时，直接调用ConfigurableApplicationContext，就可以实现BeanFactory容器的获取，之后在调用getBean来获取bean。","link":"/2023/02/27/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"java八股","text":"本篇文章为java后台开发的八股文，主要设计java基础和数据库基础，正在持续更新中，目前包括：java基础（java特性，java集合，java并发编程），数据库基础（MySQL，Redis），和计算机基础知识。 1. java基础1.1 java特性1.1.1 接口和抽象类的区别 相同点： 都不能被实例化； 接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化。 不同点： 抽象类可以有构造方法（构造器），而接口没有； 抽象类可以有抽象方法和具体方法，接口只能有抽象方法（也就是说，抽象类可以有方法的实现，接口没有）； 抽象类的成员可以用public protected default修饰，接口只能用public（不写就是public）。 1.1.2 重载和重写的区别 重载发生在同一个类中，方法名相同、参数列表、返回类型、权限修饰符可以不同； 重写发生在子类中，方法名、参数列表、返回类型都相同，权限修饰符要大于父类方法，声明异常范围要小于父类方法，但是final和private修饰的方法不可重写 1.1.3 ==和equals的区别 ==比较基本类型，比较的是值，==比较引用类型，比较的是内存地址； equals是Object类的方法，不能用于比较基本类型，如果没有对 equals 方法进行重写，则相当于==，比较的是引用类型的变量所指向的对象的地址值； 但是有些类重写了equals方法，就会比较两个对象的内容是否相等，比如String类中的equals()是被重写了，比较的是对象的值。 1.1.4 Exception 和 Error 的区别在 Java 中，所有的异常都有一个共同的祖先 java.lang 包中的 Throwable 类。Throwable 类有两个重要的子类: Exception ：程序本身可以处理的异常，可以通过 catch 来进行捕获。Exception 又可以分为 Checked Exception (受检查异常，必须处理) 和 Unchecked Exception (不受检查异常，可以不处理)。 Error ：**Error 属于程序无法处理的错误 ，不建议通过catch捕获 。**例如 Java 虚拟机运行错误（Virtual MachineError）、虚拟机内存不够错误(OutOfMemoryError)、类定义错误（NoClassDefFoundError）等 。这些异常发生时，Java 虚拟机（JVM）一般会选择线程终止。 1.1.5 异常处理机制 throws表明方法抛出异常，需要调用者来处理，如果不想处理就一直向外抛，最后会由jvm来处理； try-catch-finally：捕获别人抛出的异常，并进行处理： try： 用于捕获异常； catch：用于处理异常； finally：无论是否捕获或处理异常，finally块里的语句都会被执行。try-&gt;finally-&gt;return(finally/try中)； finally中不要放return，当try语句和finally语句中都有return语句时，try语句块中的return语句会被忽略。 finally中的语句不是一定执行的！就比如说 finally 之前虚拟机被终止运行的话，finally 中的代码就不会被执行。 1.1.6 自动拆装箱的原理java为每一种基本数据类型设计了对应的包装类，自动拆装箱反映的就是基本数据类型与其对应包装类的相互转换。 装箱：将基本类型用它们对应的引用类型包装起来； 拆箱：将包装类型转换为基本数据类型； 自动装箱其实就是调用了包装类的valueOf()方法，拆箱其实就是调用了 xxxValue()方法。 Integer i = 10 等价于 Integer i = Integer.valueOf(10) int n = i 等价于 int n = i.intValue(); 注意：如果频繁拆装箱的话，也会严重影响系统的性能。我们应该尽量避免不必要的拆装箱操作。 1.1.7 面向对象和面向过程的区别两者的主要区别在于解决问题的方式不同： 面向过程把解决问题的过程拆成一个个方法，通过一个个方法的执行解决问题； 面向对象会先抽象出对象，然后用对象执行方法的方式解决问题； 另外，面向对象开发的程序一般更易维护、易复用、易扩展。 面向过程一定比面向对象的性能要高吗？答案是否定的： 面向对象需要创建对象，类调用时需要实例化，开销比较大，比较消耗资源； 但这个并不是根本原因，面向过程也需要分配内存，计算内存偏移量，java性能差的主要原因并不是因为它是面向对象语言，而是java是半编译语言，最终的执行代码并不是可以直接被CPU执行的二进制机械码； 而面向过程语言大多都是直接编译成机械码在电脑上执行，并且其它一些面向过程的脚本语言性能也并不一定比java好。 1.1.8 String、StringBuffer、StringBuilder 的区别 可变性： String是不可变的（修改后指向了新的引用），StringBuffer和StringBuilder是可变的（在原对象上进行修改）； 解释：保存String字符串的数组被 final 修饰且为私有的，并且 String 类没有提供修改这个字符串的方法； String 类被 final 修饰导致其不能被继承，进而避免了子类破坏 String 不可变。 线程安全性： String对象不可变，可以理解为常量，线程安全； StringBuffer对一些字符串的操作添加了同步锁，线程安全； StringBuilder线程不安全，但性能相对于StringBuffer有着10-15%的提升。 补充：字符串拼接”+“的含义： 实质上是通过 StringBuilder 调用 append() 方法实现的，拼接完成之后调用 toString() 得到一个 String 对象 。 1.1.9 类的初始化顺序父类静态代码块和静态成员变量 =&gt; 子类静态代码块和静态成员变量 =&gt; 父类代码块和普通成员变量 =&gt; 父类构造方法 =&gt; 子类代码块和普成员变量 =&gt; 子类构造方法 1.2 java集合1.2.1 ArrayList和Vector的区别 ArrayList 是 List 的主要实现类，底层使用 Object[] 存储，适用于频繁的查找工作，线程不安全； Vector 是 List 的古老实现类，底层使用 Object[] 存储，线程安全的（方法之间线程同步，即多个线程访问时能保证同步）； ArrayList的默认扩容是扩容到原来的1.5倍，而Vector是扩容到原来的2倍，且Vector提供了扩容的方法。 1.2.2 ArrayList与LinkedList的区别 二者都不是线程安全的； ArrayList底层是 Object[] 数组存储，而LinkedList是双向链表存储； ArrayList 插入和删除元素的时间复杂度受元素位置的影响，且插入和删除时，需要移动元素的位置，而LinkedList不受影响，只需要移动指针就行。因此对于插入和删除操作来说，LinkedList要优于ArrayList； LinkedList不支持高效的随机元素访问，而 ArrayList（实现了RandomAccess接口） 支持。快速随机访问就是通过元素的序号快速获取元素对象（get 方法）。因此对于查找来说，ArrayList要优于LinkedList。 1.2.3 ArrayList与Array的区别 Array 可以包含基本数据类型和引用类型，ArrayList只能包含引用类型（包装类）； ArrayList是基于数组实现的，Array大小不可以调整大小，但ArrayList可以通过内部方法自动调整容量； ArrayList是List接口的实现类，相比Array支持更多的方法和特性。 1.2.4 ArrayList扩容机制ArrayList添加元素的操作add（JDK1.8之后）： 无参数构造方法创建ArrayList： 初始化了一个空数组 Object[] elementData； 当开始添加第一个元素时，将数组容量扩容到10（默认的初始容量），并进行元素的复制； 解释：此时elementData.length（容量）为0（因为还是一个空的list），而minCapacity为10 &gt; elementData.length，因此进入grow方法进行扩容，扩容到10； 添加第2…10个元素时，不会进行扩容； 解释：此时minCapacity为2…10 ≤ elementData.length（10）； 添加到第11个元素时，扩容到原来的1.5倍，并进行元素的复制； 解释：此时minCapacity为11 &gt; elementData.length（10）； int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1) 有参构造方法创建ArrayList(len)（构建指定长度的列表）： 初始化一个空数组 Object[len]； 当添加第len+1个元素时，开始扩容，扩容到原来的1.5倍； 其它与无参相同。 有参构造方法创建ArrayList（构建包含指定元素的列表）： 初始化一个包含这些元素的数组 Object[]； 当添加元素时，开始扩容，同上。 如果是JDK1.7之前： 会初始化一个容量为10的数组elementData[10]； 其余与JDK1.8相同。 1.2.5 如何保证ArrayList的线程安全 线程安全：指当多线程访问时，采用了加锁的机制；即当一个线程访问该类的某个数据时，会对这个数据进行保护，其他线程不能对其访问，直到该线程读取完之后，其他线程才可以使用。防止出现数据不一致或者数据被污染等意外情况。 使用Vector； 使用Collections.synchronizedList()方法为ArrayList加锁； 使用CopyOnWriteArrayList，基本原理还是和ArrayList一样，涉及线程安全的部分，是通过写时复制的方式来实现（从名字中就可以看出）。它内部有个volatile数组来保持数据。在“添加/修改/删除”数据时，会先获取互斥锁，再新建一个数组，并将更新后的数据拷贝到新建的数组中，最后再将该数组赋值给volatile数组，然后再释放互斥锁。因为通常需要复制整个基础数组，所以可变操作（add()、set() 和 remove() 等等）的开销很大。（锁释放了另外一个线程才能进入） 1.2.6 比较HashSet、LinkedHashSet和TreeSet三者的异同 HashSet、LinkedHashSet 和 TreeSet 都是 Set 接口的实现类，都能保证元素唯一（无序性和不可重复性），并且都不是线程安全的； HashSet、LinkedHashSet 和 TreeSet 的主要区别在于底层数据结构不同。HashSet 的底层数据结构是哈希表（基于 HashMap 实现，值为空）。LinkedHashSet 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。TreeSet 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序； 底层数据结构不同又导致这三者的应用场景不同。HashSet 用于不需要保证元素插入和取出顺序的场景，LinkedHashSet 用于保证元素的插入和取出顺序满足 FIFO 的场景，TreeSet 用于支持对元素自定义排序规则的场景。 1.2.7 HashSet 如何检查重复? 当你把对象加入HashSet时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置； 同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现，进行正常的添加操作；（hashcode不同，肯定不是一个元素） 但是如果发现有相同 hashcode 值的对象，这时会调用 equals() 方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。 1.2.8 HashMap 和 Hashtable 的区别 线程是否安全： HashMap 是非线程安全的，Hashtable 是线程安全的，因为 Hashtable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 效率： 因为线程安全的问题，HashMap 要比 Hashtable 效率高一点。另外，Hashtable 基本被淘汰，不要在代码中使用它； 对 Null key 和 Null value 的支持：HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；Hashtable 不允许有 null 键和 null 值，否则会抛出 NullPointerException。 初始容量大小和每次扩充容量大小的不同 ： 创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1； HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的 2 倍； 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小HashMap 总是使用 2 的幂作为哈希表的大小。（如果length是 2 的 n 次方，hash%length==hash&amp;(length-1)，而采用二进制位操作 &amp;，相对于 % 能够提高运算效率。） 底层数据结构： Hashtable 和 JDK1.8 之前的 HashMap底层结构都是数组+链表，且链表采用头插法； JDK1.8 以后的 HashMap 采用数组+链表+红黑树，链表采用尾插法，因为要统计长度，都需要遍历； 具体的，JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间（后文中我会结合源码对这一过程进行分析）。Hashtable 没有这样的机制。 1.2.9 HashMap的底层实现 JDK1.8 之前：数组+链表 HashMap map = new HashMap()：在实例化以后，底层了创建了一个长度是16（容量）的一维数组Entry[] table； 如果设置了初始值，则自动补充到2的幂次的容量大小； 某次执行了put(key, value)时： 将 key 的 hashcode 经过扰动函数处理过后得到 hash 值； 然后通过 (n - 1) &amp; hash 判断当前元素存放的位置（这里的 n 指的是数组的长度）； 如果当前位置没有元素，直接正常添加； 如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值，如果不同，则正常添加； 如果 hash 值相同的话，使用equals比较，如果相同，则直接替换，不相同就进行插入，并通过拉链法解决冲突。 添加键值对的过程中，会出现扩容问题，当元素个数超过了容量的0.75的时候，会进行扩容，扩容到原来容量的两倍，并将数据复制。 JDK1.8 之后：数组+链表+红黑树 new HashMap()：底层没有创建一个长度为16的数组； jdk 8底层的数组是：Node[]，而非Entry[]； 首次调用put()方法时，底层创建长度为16的数组； jdk7底层结构只有：数组+链表。jdk8中底层结构：数组+链表+红黑树； 当数组的某一个索引上的元素以链表形式存在的个数&gt;8，且当前数组的长度&gt;64时，此时此索引位置上的数据改为红黑树存储。 1.2.10 ConcurrentHashMap 是如何实现线程安全的 JDK 1.7 采用 Segment 分段锁来保证安全，Segment 是继承自 ReentrantLock； JDK1.8 放弃了 Segment 分段锁的设计，采用 Node + CAS + synchronized 保证线程安全，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点。 1.3 JUC并发编程1.3.1 线程和进程 进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。例如，从Windows任务管理器中可以看到当前运行的进程（.exe 文件的运行）； 在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程； 线程与进程相似，但线程是一个比进程更小的执行单位，是独立运行的最小单位，是进程的实体，多个线程可以共享同一进程内的系统资源。一个进程在其执行的过程中可以产生多个线程； 与进程不同的是，同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程 总结：线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。 1.3.2 线程的生命周期和状态Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态： NEW: 初始状态，线程被创建出来但没有被调用 start() 。 RUNNABLE: 运行状态，线程被调用了 start()等待运行的状态。 BLOCKED ：阻塞状态，需要等待锁释放。 WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。 TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。 TERMINATED：终止状态，表示该线程已经运行完毕。 线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。 1.3.3 什么是上下文切换?线程在执行过程中会有自己的运行条件和状态（也称上下文），当出现如下情况的时候，线程会从占用 CPU 状态中退出。 主动让出 CPU，比如调用了 sleep(), wait() 等。 时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。 调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。 被终止或结束运行 这其中前三种都会发生线程切换，线程切换意味着需要保存当前线程的上下文，等待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的上下文切换。 上下文切换是现代操作系统的基本功能，因其每次需要保存信息恢复信息，这将会占用 CPU，内存等系统资源进行处理，也就意味着效率会有一定损耗，如果频繁切换就会造成整体效率低下。 一句话：线程切换运行状态，从占用CPU到不占用，和从不占用CPU到占用的过程。 1.3.4 线程死锁线程死锁： 多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。 如：线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。 线程死锁的四个条件： 互斥条件：该资源任意一个时刻只由一个线程占用； 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放； 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源； 循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。 1.3.5 sleep() 方法和 wait() 方法对比共同点 ：两者都可以暂停线程的执行。 区别 ： sleep() 方法没有释放锁，而 wait() 方法释放了锁 。（wait了之后，其它线程可以占用此资源） wait() 通常被用于线程间交互/通信，sleep() 通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒，或者也可以使用 wait(long timeout) 超时后线程会自动苏醒。 sleep()是Thread类的静态方法，而wait()是Object类中的方法。 可以理解为：sleep就是线程睡一会，睡一会起来了接着执行；而wait就是等待状态，需要某些指令来唤醒。 1.3.6 yield() 方法和 join() 方法对比 yield()方法：让当前运行线程回到就绪状态，以允许具有相同优先级的其他线程获得运行机会。 join()方法：join()方法可以使得一个线程在另一个线程运行结束后再执行，在另一个线程结束前一直处于阻塞状态。如：如果在线程B中调用了线程A的join()方法，这时直到线程A执行完毕后，才会继续执行线程B。 1.3.7 可以直接调用 Thread 类的 run 方法吗？ new 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。； 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结： 调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。 1.3.8 JMM JMM （java内存模型）可以看作是 Java 定义的并发编程相关的一组规范； 抽象了线程和主内存之间的关系； 规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守的和并发相关的原则和规范； 其主要目的是为了简化多线程编程，增强程序的可移植性。 1.3.9 指令重排和volatile 为了提升执行速度/性能，计算机在执行程序代码的时候，会对指令进行重排序； 简单来说，就是系统在执行代码的时候并不一定是按照你写的代码的顺序依次执行； 指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致 ，所以在多线程下，指令重排序可能会导致一些问题； 在 Java 中，volatile 关键字可以禁止指令进行重排序优化。 volatile：保证变量的可见性。 如果我们将变量声明为 volatile ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主内存中进行读取。 volatile 关键字能保证数据的可见性，但不能保证数据的原子性，synchronized 关键字两者都能保证。 1.3.10 乐观锁和悲观锁 悲观锁： 总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题（比如共享数据被修改）； 所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放； 也就是说，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程； Java 中，synchronized 和 ReentrantLock 等独占锁就是悲观锁思想的实现； 悲观锁通常多用于写多比较多的情况下（多写场景），避免频繁失败和重试影响性能。 乐观锁： 乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题； 线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法）； 在 Java 中 java.util.concurrent.atomic 包下面的原子变量类就是使用了乐观锁的一种实现方式 CAS 实现的； 乐观锁通常多于写比较少的情况下（多读场景），避免频繁加锁影响性能，大大提升了系统的吞吐量。 1.3.11 乐观锁的实现——CAS算法 CAS（Compare And Swap）的思想很简单：就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。 CAS 是一个原子操作，即最小不可拆分的操作，也就是说操作一旦开始，就不能被打断，直到操作完成。 CAS 涉及到三个操作数： V ：要更新的变量值(Var) E ：预期值(Expected) N ：拟写入的新值(New) 当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。 举一个简单的例子 ：线程 A 要修改变量 i 的值为 6，i 原值为 1（V = 1，E=1，N=6，假设不存在 ABA 问题）。 i 与 1 进行比较，如果相等， 则说明没被其他线程修改，可以被设置为 6 。 i 与 1 进行比较，如果不相等，则说明被其他线程修改，当前线程放弃更新，CAS 操作失败。 当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败（因为要更新的值被一个线程已经改变了），但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。 1.3.12 乐观锁的问题——ABA问题 如果一个变量 V 初次读取的时候是 A 值，并且在准备赋值的时候检查到它仍然是 A 值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回 A，那 CAS 操作就会误认为它从来没有被修改过。这个问题被称为 CAS 操作的 ABA问题。 解决方法：在变量前面追加上版本号或者时间戳，需要更新变量时，检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 1.3.13 synchronized 和 volatile 的区别 synchronized 和 volatile 是互补的存在，而不是对立的存在； volatile 关键字是线程同步的轻量级实现，所以 volatile 性能肯定比 synchronized 关键字要好； volatile 关键字只能用于变量而 synchronized 关键字可以修饰方法以及代码块； volatile 关键字能保证数据的可见性，但不能保证数据的原子性，synchronized 关键字两者都能保证。 volatile 关键字主要用于解决变量在多个线程之间的可见性，而 synchronized 关键字解决的是多个线程之间访问资源的同步性。 1.3.14 Synchronized和Lock（ReentrantLock）的区别 synchronized是关键字，Lock是一个类； synchronized在发生异常时会自动释放锁，Lock需要手动释放锁； synchronized 依赖于 JVM（虚拟机层面，我们看不到方法的使用） 而 ReentrantLock 依赖于 API（也算jdk层面，需要使用 lock() 和 unlock() 方法来完成）； synchronized是可重入锁、非公平锁、不可中断锁，Lock是可重入锁，可中断锁，可以是公平锁； 可重入锁：也叫递归锁，指的是线程可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁； 公平锁：锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁； 可中断锁：获取锁的过程中可以被中断，不需要一直等到获取锁之后才能进行其他逻辑处理。 1.3.15 ThreadLocal原理 通常情况下，我们创建的变量是可以被任何一个线程访问并修改的，如果想实现每一个线程都有自己的专属本地变量，就需要ThreadLocal； ThreadLocal 类主要解决的就是让每个线程绑定自己的值，不同线程之间不可见，保证线程安全。可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据； 具体的，每个线程内部都维护了一个ThreadLocalMap，key为 ThreadLocal的实例，value为要保存的副本。 1.3.16 ThreadLocal的内存泄露问题是怎么导致的？ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉，从而产生内存泄漏。 1.3.17 线程池的参数有哪些？线程池：管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。 ThreadPoolExecutor 3 个最重要的参数： corePoolSize：任务队列未达到队列容量时，最大可以同时运行的线程数量，即核心线程数； maximumPoolSize：任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数； workQueue：新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 ThreadPoolExecutor 其他常见参数 : keepAliveTime：线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime 才会被回收销毁； unit：keepAliveTime 参数的时间单位。 threadFactory ：executor 创建新线程的时候会用到。 handler：饱和策略。关于饱和策略下面单独介绍一下。 1.4 设计模式1.5 JVM2. MySQL2.1 数据源2.1.1 MyISAM 和 InnoDB 有什么区别 MySQL 5.5 之前，MyISAM 引擎是 MySQL 的默认存储引擎，MySQL5.5 版本之后，InnoDB 是 MySQL 的默认存储引擎； MyISAM 只有表级锁，而 InnoDB 支持行级锁，也就是说，MyISAM 一锁就是锁住了整张表，而 InnoDB 可以只锁住某几行数据，并发时性能更好； MyISAM 不提供事务支持，InnoDB 提供事务支持； MyISAM 不支持外键，而 InnoDB 支持外键，外键对于维护数据一致性非常有帮助，但是对性能有一定的损耗； 数据库异常崩溃后，InnoDB 能够安全恢复，而MyISAM不能。使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态； MyISAM不支持MVCC，而InnoDB支持（MVVC是行级锁的优化）； MVCC是多版本并发控制，为每次事务生成一个新版本数据，每个事务都由自己的版本，从而不加锁就决绝读写冲突； 索引实现方式不同，虽然都是B+ Tree，但 InnoDB 引擎中，其数据文件本身就是索引文件，而 MyISAM 的索引文件和数据文件是分离的； InnoDB 的性能比 MyISAM 更强大。 2.2 MySQL索引2.2.1 MySQL索引介绍索引是一种用于快速查询和检索数据的数据结构，其本质可以看成是一种排序好的数据结构，Mysql中底层都为B+ Tree。 优点： 使用索引可以大大加快数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 缺点： 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率； 索引需要使用物理文件存储，也会耗费一定空间。 2.2.2 MySQL有哪些索引 主键索引：一张表只能有一个主键索引，主键索引列不能有空值和重复值 对于InnoDB：若没有设置主键索引，会自动找没有空值和重复值的列，作为主键索引； 若还是没有，则会自动创建一个6Byte的自增主键。 唯一索引：唯一索引不能有相同值，但允许为空 普通索引：允许出现重复值 组合索引：对多个字段建立一个联合索引，减少索引开销，遵循最左匹配原则 全文索引：myisam引擎支持，通过建立倒排索引提升检索效率，广泛用于搜索引擎 2.2.3 MySQL索引的数据结构 为什么不用hash表进行存储： hash表进行查找很快，但是： Hash 索引不支持顺序和范围查询。假如我们要对表中的数据进行排序或者进行范围查询，那 Hash 索引可就不行了。并且，每次 IO 只能取一个。 即：如果要查找一个范围，hash索引需要对范围内的每一个数进行hash地址计算，查找… 这一系列计算，效率较低； B+树和B树的对比： B（Balance） 树也称 B-树，全称为 多路平衡查找树 ，B+ 树是 B 树的一种变体。目前大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构； B 树的所有节点既存放键（key）也存放数据（data），而B+树只有叶子节点存放 key 和 data，其他节点只存放 key； B 树的叶子节点都是独立的，B+树的叶子节点有一条引用链指向与它相邻的叶子节点； B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。 2.2.4 聚簇索引和非聚簇索引的区别 聚簇索引（InnoDB中的索引）：将索引和值放在了一起，根据索引可以直接获取值，如果主键值很大的话，辅助索引也会变得很大 InnoDB 表数据文件本身就是主索引，而其余的索引都作为辅助索引 ，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引 非聚簇索引（MyISAM中的索引）：叶子节点存放的是数据行地址，先根据索引找到数据地址，再根据地址去找数据 在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。 二者底层都是B+ Tree。 2.2.5 索引什么时候会失效索引失效也是慢查询的主要原因之一，常见的导致索引失效的情况有下面这些： 使用 SELECT * 进行查询; 创建了组合索引，但查询条件未准守最左匹配原则; 在索引列上进行计算、函数、类型转换等操作; 以 % 开头的 LIKE 查询比如 like ‘%abc’; 查询条件中使用 or，且 or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到; 发生隐式转换 2.3 MySQL日志2.3.1 binlog 和 redolog 有什么区别？ binlog是一个二进制格式的文件，用于记录用户对数据库更新的SQL语句信息，例如更改数据库表和更改内容的SQL语句都会记录到binlog里，但是对库表等内容的查询不会记录。 即：只记录update/insert/delete/truncate，不记录select 作用：做数据恢复和主从复制 redolog是记录数据的变化，当执行update操作时，mysql底层会把这条数据所在的页加载到内存，然后在内存中将对应记录进行修改，内存写完之后其实会写redolog，这份redolog记录着这次在某个页上做了什么修改。 作用：我们修改数据，写完内存，但是数据还没有真正写到磁盘的时候，此时我们的数据库挂掉了，我们就可以根据redo log对数据进行恢复； binlog和redolog的对比： 存储的内容不同，binlog记录的是实实在在的sql语句（数据的逻辑变化），而redolog记录的是xx页做了xx修改（数据的物理变化）; 功能不同， binlog主要是为了数据的复制和恢复来使用，如果说整个数据库不小心被删除了，而binlog存储着所有数据的变更情况，这个时候其实是可以通过binlog来恢复数据的； redolog它的作用主要是用来恢复内存当中还没来得及刷入磁盘的数据，将redolog加载到内存里面，内存就能恢复到挂掉之前的数据； 那么redo log可以用来恢复数据库误删的数据吗？不可以，因为redolog它其实只是记录着物理数据的变化，如果内存中的数据已经刷入到磁盘，那其实redolog的数据就无效了，所以redo log其实并不会存储历史所有数据的变化，文件的内容会被覆盖的。 undolog： 存储的也是逻辑日志，比如说我们要insert一条语句，那么undolog就记录着一条delete语句，所以说它可以用来做回滚； 作用：用来回滚和mvcc多版本控制。 2.4 MySQL事务2.4.1 事务的特性事务是逻辑上的一组操作，要么都执行，要么都不执行 关系型数据库（例如：MySQL、SQL Server、Oracle等）事务都有 ACID 特性： 原子性（Atomicity） ：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 2.4.2 并发的事务会导致哪些问题？在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题: 脏读（Dirty read） 一个事务读取数据并且对数据进行了修改，这个修改对其他事务来说是可见的，即使当前事务没有提交。这时另外一个事务读取了这个还未提交的数据，但第一个事务突然回滚（出现故障），导致数据并没有被提交到数据库，那第二个事务读取到的就是脏数据，这也就是脏读的由来。 例如：事务 1 读取某表中的数据 A=20，事务 1 修改 A=A-1，事务 2 读取到 A=19，事务 1 回滚导致对 A 的修改并未提交到数据库， A 的值还是 20。 不可重复读（Unrepeatable read） 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 再次读取 A =19，此时读取的结果和第一次读取的结果不同。 幻读（Phantom read） 幻读与不可重复读类似。它发生在一个事务读取了几行数据，接着另一个并发事务插入了一些数据时。在随后的查询中，第一个事务就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 例如：事务 2 读取某个范围的数据，事务 1 在这个范围插入了新的数据，事务 2 再次读取这个范围的数据发现相比于第一次读取的结果多了新的数据。 2.4.3 不可重复读和幻读有什么区别？ 不可重复读的重点是内容修改或者记录减少，比如多次读取一条记录发现其中某些记录的值被修改； 幻读的重点在于记录新增，比如多次执行同一条查询语句（DQL）时，发现查到的记录增加了 2.5 MySQL锁2.5.1 Mysql锁的类型 基于粒度： 表级锁：对整张表加锁，粒度大并发小； 行级锁：对行加锁，粒度小并发大 间隙锁：间隙锁，锁住表的一个区间，间隙锁之间不会冲突只在可重复读下才生效，解决了幻读 基于属性： 共享锁：又称读锁，一个事务为表加了读锁，其它事务只能加读锁，不能加写锁 即：允许多个事务同时获取 排他锁：又称写锁，一个事务加写锁之后，其他事务不能再加任何锁，避免脏读问题 即：事务在修改记录的时候获取排他锁，不允许多个事务同时获取 MVCC：是多版本并发控制方法，即对一份数据会存储多个版本，通过事务的可见性来保证事务能看到自己应该看到的版本。通常会有一个全局的版本分配器来为每一行数据设置版本号，版本号是唯一的。MVCC可以理解为乐观锁，更新时与版本对应就能够完成更新。 2.5.2 InnoDB 有哪几类行锁？InnoDB 行锁是通过对索引数据页上的记录加锁实现的，MySQL InnoDB 支持三种行锁定方式： 记录锁（Record Lock） ：也被称为记录锁，属于单个行记录上的锁。 间隙锁（Gap Lock） ：锁定一个范围，不包括记录本身。 临键锁（Next-Key Lock） ：Record Lock+Gap Lock，锁定一个范围，包含记录本身，主要目的是为了解决幻读问题（MySQL 事务部分提到过）。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁。 在 InnoDB 行锁默认使用的是 Next-Key Lock。但是，如果操作的索引是唯一索引或主键，InnoDB 会对 Next-Key Lock 进行优化，将其降级为 Record Lock，即仅锁住索引本身，而不是范围。 2.6 MySQL调优2.6.1 MySQL有哪些调优方法 避免使用select *：select *会查询所有字段，实际业务场景中不需要所有的字段，可以不进行查询； 高效的分页：分页时找到上次分页最大id，并进行查找； 如：select id,name,age from user limit 10000, 20：mysql会查询10020条，然后丢弃前面10000条，这个比较浪费资源； 可以优化为：select id,name,age from user id&gt;10000 limit 20：找到上次分页最大id，并查询20条； 适当避免多表做join：join表不宜超过3个，如果join太多，MySQL在选择索引时会非常复杂，很容易选错索引； 尽量不要使用外键和级联； 选择合理的字段类型：能用数字类型就不用字符串，字符串处理速度比数字类型慢； 进行批量操作：当然一次插入量也不能太大，可以分批插入。 用union all 代替union：union会排重，排重过程需要遍历，排序，比较，更消耗cpu资源。在确定唯一，没有重复数据的情况下，尽量用union all。（union all就是一次执行多条语句） 2.6.2 如何优化慢查询？ 超过指定时间的SQL语句查询称为慢查询； 慢查询的优化方法： 分析sql语句，是否加载了不需要的数据列 分析sql执行计划，字段有没有索引，索引是否失效，是否用对索引 表中数据是否太大，是不是要分库分表 3. Redis3.1 与Mysql的对比3.1.1 Redis和Mysql的区别 mysql是关系型数据库，数据都存储在硬盘中，读取速度慢，但可以长期存放； redis是非关系型数据库，数据存储在缓存中，读取速度快，但保存时间有限； redis数据库性能更好，mysql数据库安全性更高，在实际开发中，经常会配合使用两种数据库。 补充： 关系型数据库：列+行（一对一，一对多，多对一），同一个表下数据的结构是一样的； 非关系型数据库：数据存储没有固定的格式，并且可以进行横向扩展； Redis的读写速度：2W/s，1s能读取上万条； MySql的读写速度：读5K/s，写3K/s 3.1.2 Redis和Mysql数据一致性问题 在满足实时性的条件下，不存在两者完全保存一致的方案，只有最终一致性方案； 先写Mysql，再写Redis：对于并发量、一致性要求不高的项目，可以这样做； 如果并发量大了，会出现一致性问题，如果数据更新了，多个线程读取的数据会不一样； 先写Mysql，再删除Redis：是实时性最好的方案，比较推荐； 在高并发的场景下，比较推荐，因为把缓存删掉了，不会出现不同步的问题； 会出现一次不同步的情况，就是在删除redis之前进行查询，因为没有对redis进行操作，因此如果是强一致性要求的业务，不建议使用。 延时双删：先删除缓存，再更新数据库，然后休眠1s（根据具体的业务合理设置，比如几百毫秒），再删除缓存，有可能第二次删除失败，还是会导致数据不一致； 延时会导致服务器阻塞，不适用于高并发场景； 先写 MySQL，通过 Binlog，异步更新 Redis：这种方案，主要是监听 MySQL 的 Binlog，然后通过异步的方式，将数据更新到 Redis。适用于高并发场景。 本质：设置一个消息队列，监听Mysql的更新变化，一旦更新，就更新redis 补充：面试时，就按加粗的方式说，可以补充说明延时双删，但都要指出缺点。 3.2 Redis的数据结构3.2.1 Redis 常用的数据结构有哪些 5 种基础数据结构 ：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。 3 种特殊数据结构 ：HyperLogLogs（基数统计）、Bitmap （位存储）、Geospatial (地理位置)。 3.2.2 Redis中String和Hash存放对象数据的区别 Redis hash 本质是一个string类型的field和value的映射表，类型也是String类型； String 存储的是序列化后的对象数据，存放的是整个对象；Hash 是对对象的每个字段单独存储，可以获取部分字段的信息； String 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半； 在绝大部分情况，我们建议使用 String 来存储对象数据即可。 3.3 Redis持久化机制3.3.1 怎么保证 Redis 挂掉之后再重启数据可以进行恢复？ 很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。 Redis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持两种不同的持久化操作。Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）。 3.3.2 什么是RDB持久化？ 在指定时间间隔后，将内存中的数据集快照写入数据库（RDB二进制文件，保存在硬盘中） ；在恢复的时候，直接读取快照文件，进行数据的恢复 ； 具体步骤： Redis 调用forks，同时拥有父进程和子进程； 子进程将数据集写入到一个临时 RDB 文件中； 当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。 3.3.3 什么是AOF持久化？ 将我们所有的命令都记录下来，history，恢复的时候就把这个文件全部再执行一遍； 以日志的形式来记录每个写的操作，将Redis执行过的所有指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据； 换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 3.3.4 如何选择使用哪种持久化方式？ 一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能； 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化； 有很多用户都只使用 AOF 持久化， 但并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。 3.4 Redis生产问题3.4.1 缓存穿透（查不到）缓存穿透说简单点就是大量请求的 key 是不合理的，根本不存在于缓存中，也不存在于数据库中 。这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。 解决方案 布隆过滤器 对所有可能查询的参数以Hash的形式存储，以便快速确定是否存在这个值，在控制层先进行拦截校验，校验不通过直接打回，减轻了存储系统的压力。 缓存空对象 一次请求若在缓存和数据库中都没找到，就在缓存中创建一个空对象用于处理后续这个请求。 3.4.2 缓存击穿（量太大，缓存过期） 缓存击穿中，请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期） 。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。 比如热搜排行上，一个热点新闻被同时大量访问就可能导致缓存击穿。 解决方案 设置热点数据永不过期 这样就不会出现热点数据过期的情况，但是当Redis内存空间满的时候也会清理部分数据，而且此种方案会占用空间，一旦热点数据多了起来，就会占用部分空间。 加互斥锁(分布式锁) 在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。保证同时刻只有一个线程访问。这样对锁的要求就十分高。（注意：这个也是Redis设计分布式锁的方法） 3.4.3 缓存雪崩大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时数据库请求量大、压力骤增，引起雪崩。 解决方案 redis高可用 这个思想的含义是，既然redis有可能挂掉，那我多增设几台redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群 限流降级 这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 数据预热 数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。 4. 计算机基础4.1 网络分层模型4.1.1 OSI七层模型OSI 七层模型 是国际标准化组织提出一个网络分层模型，其大体结构以及每一层提供的功能如下：（从高到低） 应用层：为计算机用户提供服务； 表示层：数据的处理，信息的语义转换； 会话层：管理程序间的通话； 传输层：为两台主机进程之间的通信提供数据传输服务； 网络层：控制子网的运行（路由和寻址）； 数据链路层：物理寻址，将比特流转换为逻辑传输线路； 物理层：原始比特流传输 4.1.2 TCP/IP四层模型TCP/IP 四层模型 是目前被广泛采用的一种模型，我们可以将 TCP / IP 模型看作是 OSI 七层模型的精简版本，由以下 4 层组成： 应用层：终端设备上的应用程序之间信息交换的服务——应用层，表示层，会话层 传输层：负责向两台终端设备进程之间的通信提供通用的数据传输服务——传输层 网络层：为分组交换网上的不同主机提供通信服务——网络层 网络接口层：提供网络接口——数据链路层，物理层 4.1.3 为什么要进行网络分层？ 各层相互独立； 提高整体灵活性； 每一层只专注于做一类事情，大事化小。 4.2 传输层协议——TCP和UDP4.2.1 TCP和UDP的区别 是否面向连接：UDP 在传送数据之前不需要先建立连接。TCP 在传送数据之前必须先建立连接，数据传送结束后要释放连接； 是否是可靠传输：远地主机在收到 UDP 报文后，不需要给出任何确认，并且不保证数据不丢失，不保证是否顺序到达。TCP 提供可靠的传输服务，TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。 是否有状态：TCP 传输是有状态的，这个有状态说的是 TCP 会去记录自己发送消息的状态比如消息是否发送了、是否被接收了等等。而 UDP 是无状态服务，简单来说就是不管发出去之后的事情了。 传输效率：由于使用 TCP 进行传输的时候多了连接、确认、重传等机制，所以 TCP 的传输效率要比 UDP 低很多。 传输形式： TCP 是面向字节流的，UDP 是面向报文的。 首部开销：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。 是否提供广播或多播服务：TCP 只支持点对点通信，UDP 支持一对一、一对多、多对一、多对多； 4.2.2 什么时候选择 TCP，什么时候选 UDP? UDP 一般用于即时通信，比如：语音、视频、直播等等。这些场景对传输数据的准确性要求不是特别高，比如你看视频即使少个一两帧，实际给人的感觉区别也不大； TCP 用于对传输准确性要求特别高的场景，比如文件传输、发送和接收邮件、远程登录等等。 4.2.3 TCP 三次握手建立一个 TCP 连接需要“三次握手”，缺一不可 ： 一次握手：客户端发送带有 SYN（SEQ=x） 标志的数据包 -&gt; 服务端，然后客户端进入 SYN_SEND 状态，等待服务器的确认； 二次握手：服务端发送带有 SYN+ACK（SEQ=y,ACK=x+1）标志的数据包 –&gt; 客户端,然后服务端进入 SYN_RECV 状态 三次握手：客户端发送带有 ACK（ACK=y+1）标志的数据包 –&gt; 服务端，然后客户端和服务器端都进入ESTABLISHED 状态，完成TCP三次握手。 当建立了 3 次握手之后，客户端和服务端就可以传输数据啦！ 三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。 第一次握手 ：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常 第二次握手 ：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常 第三次握手 ：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常 三次握手就能确认双方收发功能都正常，缺一不可。 4.2.4 TCP四次挥手断开一个 TCP 连接则需要“四次挥手”，缺一不可 ： 第一次挥手 ：客户端发送一个 FIN（SEQ=X）标志的数据包-&gt;服务端，用来关闭客户端到服务器的数据传送。然后，客户端进入 FIN-WAIT-1 状态。 第二次挥手 ：服务器收到这个 FIN（SEQ=X）标志的数据包，它发送一个 ACK（SEQ=X+1）标志的数据包-&gt;客户端 。然后，此时服务端进入CLOSE-WAIT状态，客户端进入FIN-WAIT-2状态。 第三次挥手 ：服务端关闭与客户端的连接并发送一个 FIN（SEQ=y）标志的数据包-&gt;客户端请求关闭连接，然后，服务端进入LAST-ACK状态。 第四次挥手 ：客户端发送 ACK （SEQ=y+1）标志的数据包-&gt;服务端并且进入TIME-WAIT状态，服务端在收到 ACK（SEQ=y+1）标志的数据包后进入 CLOSE 状态。此时，如果客户端等待 2MSL 后依然没有收到回复，就证明服务端已正常关闭，随后，客户端也可以关闭连接了。 只要四次挥手没有结束，客户端和服务端就可以继续传输数据！ TCP是全双工通信，可以双向传输数据。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。 举个例子：A 和 B 打电话，通话即将结束后。 第一次挥手 ： A 说“我没啥要说的了” 第二次挥手 ：B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话 第三次挥手 ：于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了” 第四次挥手 ：A 回答“知道了”，这样通话才算结束。 4.2.5 为什么不能把服务器发送的 ACK 和 FIN 合并起来，变成三次挥手？因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复 ACK，表示接收到了断开连接的请求。等到数据发完之后再发 FIN，断开服务器到客户端的数据传送。 4.2.6 如果第二次挥手时服务器的 ACK 没有送达客户端，会怎样？客户端没有收到 ACK 确认，会重新发送 FIN 请求。 4.2.7 为什么第四次挥手客户端需要等待 2*MSL（报文段最长寿命）时间后才进入 CLOSED 状态？第四次挥手时，客户端发送给服务器的 ACK 有可能丢失，如果服务端因为某些原因而没有收到 ACK 的话，服务端就会重发 FIN，如果客户端在 2*MSL 的时间内收到了 FIN，就会重新发送 ACK 并再次等待 2MSL，防止 Server 没有收到 ACK 而不断重发 FIN。 MSL(Maximum Segment Lifetime) : 一个片段在网络中最大的存活时间，2MSL 就是一个发送和一个回复所需的最大时间。如果直到 2MSL，Client 都没有再次收到 FIN，那么 Client 推断 ACK 已经被成功接收，则结束 TCP 连接。 4.3 网络层协议——HTTP4.3.1 从输入URL 到页面展示到底发生了什么？也即：打开一个网页，整个过程会使用哪些协议？ 上图有一个错误，请注意，是 OSPF 不是 OPSF。 OSPF（Open Shortest Path First，ospf）开放最短路径优先协议, 是由 Internet 工程任务组开发的路由选择协议 总体来说分为以下几个过程: DNS 解析 TCP 连接 发送 HTTP 请求 服务器处理请求并返回 HTTP 报文 浏览器解析渲染页面 连接结束 4.3.2 HTTP 和 HTTPS 有什么区别？ 端口号 ：HTTP 默认是 80，HTTPS 默认是 443； URL 前缀 ：HTTP 的 URL 前缀是 http://，HTTPS 的 URL 前缀是 https://； 安全性和资源消耗 ： HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 SSL/TLS 之上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。 HTTPS多了一层，执行了加密，所以更安全。 5. 操作系统6. Mybatis","link":"/2023/03/01/java%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"java","slug":"java","link":"/tags/java/"},{"name":"html","slug":"html","link":"/tags/html/"},{"name":"元学习","slug":"元学习","link":"/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"机器学习基础","slug":"机器学习基础","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"},{"name":"成员推断攻击","slug":"成员推断攻击","link":"/tags/%E6%88%90%E5%91%98%E6%8E%A8%E6%96%AD%E6%94%BB%E5%87%BB/"},{"name":"联邦学习","slug":"联邦学习","link":"/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"},{"name":"论文写作","slug":"论文写作","link":"/tags/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/"},{"name":"论文阅读笔记","slug":"论文阅读笔记","link":"/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"JDBC","slug":"JDBC","link":"/tags/JDBC/"},{"name":"MyBatis","slug":"MyBatis","link":"/tags/MyBatis/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","link":"/tags/SpringMVC/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"SpringCloud","slug":"SpringCloud","link":"/tags/SpringCloud/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"java","slug":"java","link":"/categories/java/"},{"name":"web基础","slug":"web基础","link":"/categories/web%E5%9F%BA%E7%A1%80/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"编程基础","slug":"编程基础","link":"/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"},{"name":"论文写作","slug":"论文写作","link":"/categories/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/"},{"name":"论文阅读笔记","slug":"论文阅读笔记","link":"/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"name":"MySQL","slug":"MySQL","link":"/categories/MySQL/"},{"name":"MyBatis","slug":"MyBatis","link":"/categories/MyBatis/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","link":"/categories/SpringMVC/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/categories/SpringBoot/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"SpringCloud","slug":"SpringCloud","link":"/categories/SpringCloud/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"pages":[]}